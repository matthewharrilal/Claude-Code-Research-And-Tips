<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta data-pagefind-meta="chapter" content="Journeys">
  <meta data-pagefind-meta="section" content="Mental Models">
  <title>Core Mental Models (1-10) - Claude Code Knowledge Base</title>
  <link rel="stylesheet" href="../../css/style.css">
  <link rel="stylesheet" href="../../css/sidebar.css">
</head>
<body>
  <div class="page-with-sidebar">
    <!-- Sidebar Navigation -->
    <nav class="sidebar">
      <button class="sidebar-close" aria-label="Close sidebar">&times;</button>
      <div class="sidebar-header">
        <h2 class="sidebar-title"><a href="../../index.html">Claude Code KB</a></h2>
      </div>
      <ul class="sidebar-nav">
        <li class="nav-section">
          <div class="nav-section-title">Start Here</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../../start-here/index.html">Overview</a></li>
            <li class="nav-page"><a href="../../start-here/master-playbook.html">Master Playbook</a></li>
            <li class="nav-page"><a href="../../start-here/judgment-guide.html">Judgment Guide</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Foundations</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../../foundations/index.html">Overview</a></li>
            <li class="nav-page"><a href="../../foundations/principles/core.html">Core Principles</a></li>
            <li class="nav-page"><a href="../../foundations/architecture/complexity-ladder.html">Complexity Ladder</a></li>
          </ul>
        </li>
        <li class="nav-section open">
          <div class="nav-section-title">Mental Models Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../mental-models/index.html">Overview</a></li>
            <li class="nav-page current"><a href="../mental-models/core-models.html">Core Models (1-10)</a></li>
            <li class="nav-page"><a href="../mental-models/advanced-models.html">Advanced Models (11-16)</a></li>
            <li class="nav-page"><a href="../mental-models/practice-heuristics.html">Practice &amp; Heuristics</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Architecture Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../architecture/index.html">Overview</a></li>
            <li class="nav-page"><a href="../architecture/decision-framework.html">Decision Framework</a></li>
            <li class="nav-page"><a href="../architecture/core-patterns.html">Core Patterns</a></li>
            <li class="nav-page"><a href="../architecture/enterprise-swarm.html">Enterprise &amp; Swarm</a></li>
            <li class="nav-page"><a href="../architecture/context-composition.html">Context &amp; Composition</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Implementation Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../implementation/index.html">Overview</a></li>
            <li class="nav-page"><a href="../implementation/context-state.html">Context &amp; State</a></li>
            <li class="nav-page"><a href="../implementation/ralph-production.html">Ralph Production</a></li>
            <li class="nav-page"><a href="../implementation/hooks-enterprise.html">Hooks &amp; Enterprise</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Operations Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../operations/index.html">Overview</a></li>
            <li class="nav-page"><a href="../operations/monitoring-cost.html">Monitoring &amp; Cost</a></li>
            <li class="nav-page"><a href="../operations/security-checklists.html">Security &amp; Checklists</a></li>
            <li class="nav-page"><a href="../operations/incident-response.html">Incident Response</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Reference</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../foundations/invariants-reference.html">Invariants Reference</a></li>
            <li class="nav-page"><a href="../../reference/index.html">Full Reference</a></li>
            <li class="nav-page"><a href="../../reference/cost-analysis.html">Cost Analysis</a></li>
          </ul>
        </li>
      </ul>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
      <div class="breadcrumb">
        <a href="../../index.html">Home</a>
        <span class="breadcrumb-separator">/</span>
        <a href="../index.html">Journeys</a>
        <span class="breadcrumb-separator">/</span>
        <a href="index.html">Mental Models</a>
        <span class="breadcrumb-separator">/</span>
        <span class="breadcrumb-current">Core Models (1-10)</span>
      </div>

      <div class="page-meta">
        <span class="page-meta-item">35 min read</span>
        <span class="page-meta-item">~1,050 lines</span>
      </div>

      <h1>Core Mental Models (1-10)</h1>

      <!-- You Are Here Context Box -->
      <div class="context-box you-are-here">
        <h3>You Are Here</h3>
        <p>This is the <strong>core mental models journey</strong> for developing staff-level intuition about AI agent systems. You will learn to THINK differently, not just DO differently. These 10 foundational models are prerequisites for the advanced models (11-16) and must be internalized before scaling to multi-agent orchestration.</p>
        <p><strong>Time Estimate:</strong> 35 min read | <strong>Prerequisites:</strong> Basic Claude Code familiarity</p>
      </div>

      <p class="lead">These are the fundamental patterns of thought that separate effective agent practitioners from those who struggle. Each model is a lens for viewing problems correctly.</p>

      <!-- Before You Start Section -->
      <section id="before-you-start" class="callout-insight">
        <h3>Before You Start: Self-Assessment</h3>
        <p>Rate yourself honestly (1 = never, 5 = always):</p>
        <table>
          <thead>
            <tr><th>Statement</th><th>Rating (1-5)</th></tr>
          </thead>
          <tbody>
            <tr><td>When Claude struggles, I add more explanation to the conversation</td><td></td></tr>
            <tr><td>I think longer sessions help Claude understand better</td><td></td></tr>
            <tr><td>I trust Claude when it says a task is complete</td><td></td></tr>
            <tr><td>I implement features myself when they seem complex</td><td></td></tr>
            <tr><td>I use the same model for every task</td><td></td></tr>
          </tbody>
        </table>
        <p><strong>Interpretation:</strong></p>
        <ul>
          <li><strong>15+ points:</strong> This journey will challenge many of your current assumptions. Perfect.</li>
          <li><strong>10-14 points:</strong> You've started developing agent intuition. This will sharpen it.</li>
          <li><strong>5-9 points:</strong> You may already think like a staff engineer. Use this as validation and gap-finding.</li>
        </ul>
      </section>

      <!-- Meta-Insight Section -->
      <section id="meta-insight" class="callout-warning">
        <div class="callout-title">The Meta-Insight: Why These Models Matter</div>
        <blockquote>
          <strong>AI agents are capable but unreliable, fast but stateless.</strong>
        </blockquote>
        <p>Every mental model in this journey compensates for one of these limitations. The shift you're making is from "fixing the agent" to "designing the system."</p>
        <div class="ascii-diagram">
<strong>Before these mental models:</strong>
- "How do I prompt the agent better?"
- "How do I make the agent smarter?"
- "Why doesn't the agent understand?"

<strong>After these mental models:</strong>
- "How do I design around agent limitations?"
- "How do I build systems that compensate?"
- "How do I structure work for agent success?"
        </div>
      </section>

      <div class="toc">
        <div class="toc-title">On This Page</div>
        <ul>
          <li><a href="#model-1">Model 1: Context-First Paradigm</a></li>
          <li><a href="#model-2">Model 2: External State Over Internal Memory</a></li>
          <li><a href="#model-3">Model 3: Fresh Context Beats Extended Sessions</a></li>
          <li><a href="#model-4">Model 4: Verification as Trust Boundary</a></li>
          <li><a href="#model-5">Model 5: Parallelization Over Single-Agent Optimization</a></li>
          <li><a href="#model-6">Model 6: Human as Orchestrator, Not Implementer</a></li>
          <li><a href="#model-7">Model 7: Atomic Tasks with Clear Completion Criteria</a></li>
          <li><a href="#model-8">Model 8: Model Tiering and Cost Optimization</a></li>
          <li><a href="#model-9">Model 9: Learning Must Compound</a></li>
          <li><a href="#model-10">Model 10: Simplicity Compensates for Non-Determinism</a></li>
        </ul>
      </div>

      <hr class="section-divider">

      <!-- Model 1 -->
      <section id="model-1">
        <h2>Mental Model 1: Context-First Paradigm</h2>

        <h3>The Core Insight</h3>
        <p><strong>Context is the constraint, not capability.</strong></p>
        <p>You do not optimize agent prompts. You do not make agents smarter. You design systems that work AROUND context limits, not through them.</p>

        <h3>How to Think</h3>
        <p>When you catch yourself asking "How do I make the agent understand more?" you are thinking wrong. The correct question is "How do I structure work so the agent needs to understand less at once?"</p>

        <h3>The Mental Shift</h3>
        <div class="ascii-diagram">
WRONG: "My agent can't handle this complex task"
RIGHT: "I've asked too much for one context window"

WRONG: "The agent keeps forgetting earlier instructions"
RIGHT: "I need external state to persist what matters"

WRONG: "Extended conversation will help the agent understand better"
RIGHT: "Fresh context with the right information beats stale context with everything"
        </div>

        <h3>The Numbers That Matter</h3>
        <table>
          <thead>
            <tr>
              <th>Fill Level</th>
              <th>Effect</th>
              <th>Action</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>0-50%</td><td>Full capability</td><td>Continue normally</td></tr>
            <tr><td>50-70%</td><td>Slight degradation begins</td><td>Monitor quality</td></tr>
            <tr><td>70-85%</td><td>Noticeable quality loss</td><td>Reset recommended</td></tr>
            <tr><td>85%+</td><td>Hallucination probability spikes</td><td>Reset required</td></tr>
          </tbody>
        </table>

        <h3>Evidence Across Practitioners</h3>
        <table>
          <thead>
            <tr>
              <th>Source</th>
              <th>Evidence</th>
              <th>Quote/Pattern</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Jaana Dogan</td><td>Conservative threshold</td><td>"Fill past 40% and expect problems"</td></tr>
            <tr><td>Steve Yegge</td><td>Parallel architecture</td><td>"20-30 short sessions, not one long one"</td></tr>
            <tr><td>All Ralph variants</td><td>Universal fresh context</td><td>"Files carry state, not context. Each iteration is fresh."</td></tr>
            <tr><td>12-factor-agents</td><td>Factor 3 explicit</td><td>"Fresh context > extended sessions"</td></tr>
          </tbody>
        </table>

        <p><strong>Production Validation:</strong> All 15+ implementations that touch context management enforce fresh context per iteration. No production system attempts extended context as primary mode. Zero counterexamples found.</p>

        <h3>The 12-Factor Perspective</h3>
        <p>Dexter Horthy's 12-Factor Agents framework provides the philosophical foundation:</p>

        <blockquote>
          "The contents of your context window are the ONLY lever you have to affect the quality of your output."
          <cite>-- Factor 3: Own Your Context Window</cite>
        </blockquote>

        <p>The "Dumb Zone" discovery from analyzing 100,000 developer sessions:</p>
        <ul>
          <li><strong>0-40%:</strong> Good performance, full capability</li>
          <li><strong>40-60%:</strong> The "dumb zone" - recall degrades, reasoning falters</li>
          <li><strong>60-100%:</strong> Diminishing returns accelerate rapidly</li>
        </ul>

        <details class="troubleshoot">
          <summary>Agent mentions files that don't exist</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Context overflow causing hallucination</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Start a fresh session immediately. Save current state to external files first. This symptom indicates you are past 70% context usage.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Agent ignores earlier instructions</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Instructions pushed out of effective context</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Reset and re-inject critical instructions at the start of a fresh session. Add the most important instructions to CLAUDE.md so they are always loaded first.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 2 -->
      <section id="model-2">
        <h2>Mental Model 2: External State Over Internal Memory</h2>

        <h3>The Core Insight</h3>
        <p><strong>Context windows die. Files and git survive.</strong></p>
        <p>This is the single most universally agreed-upon principle across ALL practitioners. No exceptions. No debates. 100% adoption.</p>

        <h3>How to Think</h3>
        <p>Treat every piece of information that matters as if the agent will have complete amnesia in 30 seconds. Because effectively, it will. The agent does not remember yesterday. It does not remember the last conversation. It does not even reliably remember what you told it 10,000 tokens ago.</p>

        <h3>The Mental Shift</h3>
        <div class="ascii-diagram">
WRONG: "I told the agent this earlier, it should remember"
RIGHT: "If it's not in a file, it doesn't exist"

WRONG: "Let me explain the context to the agent"
RIGHT: "Let me write the context to CLAUDE.md so every future session has it"

WRONG: "The agent learned this pattern"
RIGHT: "I documented this pattern so agents can rediscover it"
        </div>

        <h3>Manifestations Across Practitioners</h3>
        <table>
          <thead>
            <tr>
              <th>Practitioner</th>
              <th>What They Call It</th>
              <th>Implementation</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Boris Cherny</td><td>CLAUDE.md</td><td>External project context</td></tr>
            <tr><td>Ralph Pattern</td><td>prd.json + progress.txt</td><td>External task state</td></tr>
            <tr><td>Steve Yegge</td><td>Beads</td><td>SQLite + JSONL structured database</td></tr>
            <tr><td>Molly Cantillon</td><td>Domain filesystems</td><td>External domain isolation</td></tr>
            <tr><td>Reuven Cohen</td><td>AgentDB (SQLite)</td><td>External coordination state</td></tr>
            <tr><td>Dan Shipper</td><td>.claude/learnings/</td><td>External learning repository</td></tr>
          </tbody>
        </table>

        <h3>The State Persistence Spectrum</h3>
        <ol>
          <li><strong>Simple (trilogy):</strong> prd.json + progress.txt + git</li>
          <li><strong>Intermediate:</strong> Git + SQLite for agent coordination</li>
          <li><strong>Enterprise:</strong> Full DB + Git for audit requirements</li>
        </ol>
        <p>All share the core principle: nothing in context only.</p>

        <h3>The 12-Factor Perspective</h3>
        <ul>
          <li><strong>Factor 5 - Unify Execution &amp; Business State:</strong> Agent state and application state must align. External storage that both agent and application can access.</li>
          <li><strong>Factor 6 - Launch/Pause/Resume APIs:</strong> If state lives in context, you cannot pause. If state lives externally, pause/resume becomes trivial.</li>
          <li><strong>Factor 12 - Stateless Reducer:</strong> Agents are pure functions: <code>(state, input) -> (state, output)</code>. All state is external by definition.</li>
        </ul>

        <details class="troubleshoot">
          <summary>Agent asks same questions repeatedly across sessions</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No external memory between sessions</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Create CLAUDE.md with key decisions. Add a section documenting the answers to repeated questions. The agent reads this file at session start.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Progress lost between sessions</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">State only in context, not files</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Implement the progress.txt pattern. Before ending any session, ask Claude to append current status. Before starting, read and continue from last checkpoint.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 3 -->
      <section id="model-3">
        <h2>Mental Model 3: Fresh Context Beats Extended Sessions</h2>

        <h3>The Core Insight</h3>
        <p><strong>Quality degrades with context usage. Fresh starts restore peak capability.</strong></p>
        <p>This seems counterintuitive. Should giving the agent MORE context not help it understand better? No. Context is not free. Each token of context costs capability.</p>

        <h3>The Math</h3>
        <div class="ascii-diagram">
Single long session quality: Q(t) = Q_max * decay(context_usage)

Multiple fresh sessions quality: Q(t) = Q_max per iteration

As context fills, quality decays. Fresh context resets to maximum quality.
Twenty 5-minute sessions produce better results than one 100-minute session.
        </div>

        <h3>How to Think</h3>
        <p>Think of context like RAM in an old computer. The more you load, the slower everything gets. Except unlike RAM, you cannot just close programs. Once context is used, quality degrades. The only solution is a fresh start.</p>

        <h3>The Mental Shift</h3>
        <div class="ascii-diagram">
WRONG: "Let me continue this session, the agent has context now"
RIGHT: "Fresh context with external state beats stale context with history"

WRONG: "I'll keep going until the agent loses track"
RIGHT: "I'll restart proactively before quality degrades"

WRONG: "Starting over loses all the work we did"
RIGHT: "Starting over with external state preserves all meaningful work"
        </div>

        <h3>Evidence Across Practitioners</h3>
        <table>
          <thead>
            <tr>
              <th>Source</th>
              <th>Implementation</th>
              <th>Pattern</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Steve Yegge</td><td>20-30 parallel sessions</td><td>"Everyone is making their ant run longer when nature prefers colonies"</td></tr>
            <tr><td>snarktank/ralph</td><td>Bounded loop (10 iter)</td><td>Each iteration clean slate</td></tr>
            <tr><td>frankbria/ralph</td><td>Circuit breaker reset</td><td>Forces fresh on stuck detection</td></tr>
            <tr><td>HumanLayer FIC</td><td>Phase compaction</td><td>Research/Plan/Implement isolated</td></tr>
          </tbody>
        </table>

        <p><strong>Decision Rule:</strong> When in doubt, start a new session rather than extending. The exception: quick follow-ups within 15-30 minutes of completing work.</p>

        <h3>The FIC Methodology (HumanLayer)</h3>
        <p>Frequent Intentional Compaction structures work into isolated phases:</p>
        <div class="ascii-diagram">
PHASE 1: RESEARCH (30-40% context)
  -> Compact findings to file

PHASE 2: PLANNING (20-30% context)
  -> Compact plan to file

PHASE 3: IMPLEMENTATION (60-70% context)
  -> Fresh context with only implementation needs
        </div>

        <details class="troubleshoot">
          <summary>Quality noticeably worse than at session start</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Context degradation</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Save state externally (CLAUDE.md, progress.txt), start a fresh session. Load only the essential context needed for the next task.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Agent doing circular work (undo/redo cycles)</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Agent lost track of progress</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Externalize progress to a file, restart with clear state. The fresh context plus documented progress breaks the cycle.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 4 -->
      <section id="model-4">
        <h2>Mental Model 4: Verification as Trust Boundary</h2>

        <h3>The Core Insight</h3>
        <p><strong>Verification does not catch errors. Verification is the foundation of trust.</strong></p>
        <p>Practitioners report 2-3x quality improvement with proper testing loops. But that is not because verification catches 2-3x more bugs. It is because the existence of verification changes the entire relationship.</p>

        <h3>How to Think</h3>
        <p>Think of verification like a contract. The agent knows what "done" looks like because there is a programmatic definition. Without verification, "done" means "the agent said so." With verification, "done" means "the tests pass."</p>

        <h3>The Trust Architecture</h3>
        <div class="ascii-diagram">
                    TRUST LEVEL
                         |
    "Agent said so" -----+---- LOW TRUST
                         |
   "It compiles" --------+---- MODERATE TRUST
                         |
  "Tests pass" ----------+---- HIGH TRUST
                         |
 "Tests + lint + type" --+---- PRODUCTION TRUST
                         |
 "LSP grounded" ---------+---- KILLER FEATURE
                         |
        </div>

        <h3>The Mental Shift</h3>
        <div class="ascii-diagram">
WRONG: "I'll verify after the agent finishes"
RIGHT: "Verification IS how the agent knows it's finished"

WRONG: "Testing is for catching mistakes"
RIGHT: "Testing defines what success looks like"

WRONG: "The bottleneck is agent capability"
RIGHT: "The bottleneck is trust. Verification creates trust."
        </div>

        <h3>Evidence Across Practitioners</h3>
        <table>
          <thead>
            <tr>
              <th>Source</th>
              <th>Verification Mechanism</th>
              <th>Trust Level</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Boris Cherny</td><td><code>npm run typecheck &amp;&amp; npm test</code> hook</td><td>Production trust</td></tr>
            <tr><td>OpenCode</td><td>LSP Grounding</td><td>Killer feature</td></tr>
            <tr><td>BMAD-METHOD</td><td>21-agent QA loop</td><td>Enterprise trust</td></tr>
            <tr><td>covibes/zeroshot</td><td>Validator consensus</td><td>Security trust</td></tr>
          </tbody>
        </table>

        <h3>Boris Cherny's Hook</h3>
        <div class="code-block">
          <button class="copy-btn">Copy</button>
          <pre><code>{
  "event": "PostToolUse",
  "command": "npm run typecheck && npm test",
  "timeout": 30000
}</code></pre>
        </div>
        <p>This runs after EVERY code change. Not as a safety net. As the definition of success.</p>

        <details class="troubleshoot">
          <summary>"It works" but actually does not</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No programmatic verification</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add test first, then implementation. The workflow becomes: write test that fails, implement until test passes, only then mark complete.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Repeated breakages of previously working code</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No regression tests</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Build a test suite that runs automatically after every change. Add Boris's PostToolUse hook to enforce this.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 5 -->
      <section id="model-5">
        <h2>Mental Model 5: Parallelization Over Single-Agent Optimization</h2>

        <h3>The Core Insight</h3>
        <p><strong>Build colonies, not super-workers.</strong></p>
        <p>When you hit limitations with one agent, the instinct is to make that agent better. Better prompts. Longer context. More capabilities. This is wrong. The solution is more agents, not better agents.</p>

        <h3>How to Think</h3>
        <p>Think of a factory. If one assembly line cannot keep up with demand, you do not make that line work harder. You build more lines. Each line does its job at sustainable pace. Together, they achieve throughput no single line could.</p>

        <h3>The Colony Architecture</h3>
        <div class="ascii-diagram">
WRONG ARCHITECTURE (Single Super-Agent):
+-------------------------------------+
|          SUPER AGENT                |
|   Everything in one context         |
|   Quality degrades over time        |
|   Single point of failure           |
|   Maximum capability: 1x            |
+-------------------------------------+

RIGHT ARCHITECTURE (Colony):
+--------+ +--------+ +--------+ +--------+ +--------+
| Agent  | | Agent  | | Agent  | | Agent  | | Agent  |
|   1    | |   2    | |   3    | |   4    | |   5    |
| Fresh  | | Fresh  | | Fresh  | | Fresh  | | Fresh  |
|context | |context | |context | |context | |context |
+--------+ +--------+ +--------+ +--------+ +--------+
    |          |          |          |          |
    +----------+----------+----------+----------+
                       |
               Shared external state
               (Git, files, databases)
        </div>

        <h3>Benefits of Colony Model</h3>
        <ol>
          <li><strong>Isolated failures</strong> - One agent going wrong does not corrupt others</li>
          <li><strong>Peak quality</strong> - Each agent operates at fresh context quality</li>
          <li><strong>Parallelization</strong> - 5 agents = 5x throughput (not 5x capability, but 5x work)</li>
          <li><strong>Specialization</strong> - Different agents for different task types</li>
        </ol>

        <h3>Scale Tiers Validated</h3>
        <table>
          <thead>
            <tr>
              <th>Tier</th>
              <th>Scale</th>
              <th>Example</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1 (Solo)</td><td>1-2 agents</td><td>Single Claude session</td></tr>
            <tr><td>2 (Ralph)</td><td>1 active + spawned</td><td>Autonomous loop</td></tr>
            <tr><td>3 (Team)</td><td>5-20 agents</td><td>CC Mirror hub-and-spoke</td></tr>
            <tr><td>4 (Enterprise)</td><td>20-50 agents</td><td>Gas Town factory</td></tr>
            <tr><td>5 (Factory)</td><td>50-100+ agents</td><td>SONA swarm</td></tr>
          </tbody>
        </table>

        <details class="troubleshoot">
          <summary>Agents doing conflicting work</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No coordination mechanism</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add claims-based coordination (see Model 14 in Advanced Models). Each agent claims files before editing, others see and avoid claimed files.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Hard to synthesize results from multiple agents</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No standard output format</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Define an output schema all agents follow. JSON or markdown with consistent structure makes aggregation straightforward.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 6 -->
      <section id="model-6">
        <h2>Mental Model 6: Human as Orchestrator, Not Implementer</h2>

        <h3>The Core Insight</h3>
        <p><strong>Your role has inverted. You no longer write code. You conduct agents who write code.</strong></p>
        <p>This is perhaps the hardest mental shift. If you have spent years building expertise as an implementer, you must now apply that expertise differently. You are not typing code. You are specifying what code should exist, verifying it is correct, and handling the exceptions that require judgment.</p>

        <h3>The Role Inversion</h3>
        <div class="ascii-diagram">
OLD MODEL:
Human -> thinks -> types -> compiles -> tests -> deploys

NEW MODEL:
Human -> specifies -> agent implements -> human verifies -> human judges
        </div>

        <h3>How to Think</h3>
        <p>Think like an engineering manager, not a senior developer. A great engineering manager does not write the code. They:</p>
        <ul>
          <li>Decompose large problems into clear tasks</li>
          <li>Specify acceptance criteria</li>
          <li>Review the work product</li>
          <li>Make judgment calls on edge cases</li>
          <li>Handle exceptions and escalations</li>
        </ul>
        <p>That is your job now. The agents are your team.</p>

        <h3>Key Quotes</h3>
        <blockquote>
          "Think like an engineering manager, not a coder."
          <cite>-- Dan Shipper</cite>
        </blockquote>

        <blockquote>
          "You do not write code. Claude writes code. You orchestrate and verify."
          <cite>-- CC Mirror's Iron Law</cite>
        </blockquote>

        <h3>What Humans Still Do Best</h3>
        <ul>
          <li><strong>Judgment calls</strong> - Should we do this at all?</li>
          <li><strong>Edge case reasoning</strong> - What happens in weird situations?</li>
          <li><strong>Domain expertise</strong> - Does this make sense for our users?</li>
          <li><strong>Verification design</strong> - How do we know this works?</li>
          <li><strong>Exception handling</strong> - What do we do when things go wrong?</li>
        </ul>

        <details class="troubleshoot">
          <summary>Taking over implementation yourself</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Old habits</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Pause. Specify what you want instead. Let the agent implement. Your expertise now applies to judging the output, not producing it.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Feeling slow or unproductive</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Judging yourself by lines typed</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Measure by features shipped, not code written. Your productivity is now measured in outcomes, not keystrokes.</p>
            </div>
          </div>
        </details>

        <!-- Capability Taxonomy Expansion -->
        <h3>The Capability Taxonomy Mental Model (from wshobson/agents)</h3>
        <p>Think of orchestration through the lens of <strong>capability taxonomy</strong>. The wshobson/agents repository demonstrates this with 100+ agents and 110 accumulated skills - not as a monolith, but as a structured ecosystem:</p>

        <div class="ascii-diagram">
ORCHESTRATOR THINKING (Capability Taxonomy):

Instead of: "I need to implement feature X"
Think:      "What capabilities does feature X require?"

Capability Categories (from wshobson/agents 110 skills):
- File Operations     -> Which agents have file skills?
- Code Analysis       -> Which agents have analysis skills?
- Testing             -> Which agents have verification skills?
- Documentation       -> Which agents have writing skills?

Your Role: Map requirements to capabilities, not tasks to agents
        </div>

        <p><strong>The 110 Skills as Ecosystem Thinking:</strong> When wshobson/agents accumulated 110 skills across 100 agents, it wasn't about building super-agents. It was about creating a <strong>capability ecosystem</strong> where:</p>
        <ul>
          <li>Skills are reusable across agents</li>
          <li>New agents can compose existing skills</li>
          <li>Capability gaps become visible and fillable</li>
          <li>The ecosystem grows through accumulation, not replacement</li>
        </ul>

        <p><strong>Skill Registration Pattern (wshobson/agents):</strong></p>
        <div class="code-block">
          <button class="copy-btn">Copy</button>
          <pre><code class="language-yaml"># skills/file-operations.yaml
skill:
  name: file_operations
  version: "1.2.0"
  capabilities:
    - read_file
    - write_file
    - glob_search
    - directory_traverse

  # Skills are composable - this skill builds on base_io
  extends: base_io

  # Required tools (Claude Code tools this skill needs)
  tools_required:
    - Read
    - Write
    - Glob
    - Bash

  # Usage constraints
  constraints:
    max_file_size: "10MB"
    allowed_extensions: ["*"]
    sandbox_required: true</code></pre>
        </div>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>Planning multi-agent workflows (map capabilities first)</li>
          <li>Designing new agents (what skills does it need?)</li>
          <li>Scaling teams (what capability gaps exist?)</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Model 7 -->
      <section id="model-7">
        <h2>Mental Model 7: Atomic Tasks with Clear Completion Criteria</h2>

        <h3>The Core Insight</h3>
        <p><strong>If you cannot describe it in 2-3 sentences, it is too big.</strong></p>
        <p>Tasks that overflow context windows produce cascading failures. Tasks that compound misunderstandings produce wrong work. Small, atomic tasks with clear "done" definitions are the only reliable unit of work.</p>

        <h3>The Task Sizing Rule</h3>
        <table>
          <thead>
            <tr>
              <th>Metric</th>
              <th>Target</th>
              <th>Why</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Description length</td><td>2-3 sentences</td><td>Forces clarity</td></tr>
            <tr><td>Lines of code</td><td>~100-500</td><td>Fits in context with room</td></tr>
            <tr><td>Files affected</td><td>1-3</td><td>Limits complexity</td></tr>
            <tr><td>Human equivalent time</td><td>15-60 minutes</td><td>Appropriate scope</td></tr>
            <tr><td>Verification</td><td>Must be programmatic</td><td>Defines "done"</td></tr>
          </tbody>
        </table>

        <h3>How to Think</h3>
        <p>Think of tasks like LEGO instructions. Each step is one action. "Put red 2x4 brick on blue baseplate." Not "Build a house." The agent executes one step, verifies, then moves to the next.</p>

        <h3>The Mental Shift</h3>
        <div class="ascii-diagram">
WRONG: "Implement user authentication"
RIGHT: "Create user model with email and hashed password fields"
       "Add login endpoint that returns JWT on valid credentials"
       "Add middleware that validates JWT on protected routes"
       (Three atomic tasks, not one big task)

WRONG: "Fix the broken tests"
RIGHT: "Fix the specific test failure in auth.test.ts line 42"

WRONG: "Make the dashboard faster"
RIGHT: "Add pagination to the users list, 50 per page"
       "Add caching to the stats endpoint, 5 minute TTL"
        </div>

        <h3>Signs Your Task Is Too Big</h3>
        <ul>
          <li>You need more than 2-3 sentences to describe it</li>
          <li>You cannot name a single verification command</li>
          <li>It affects more than 3 files</li>
          <li>It would take a human more than an hour</li>
          <li>The acceptance criteria are fuzzy</li>
        </ul>

        <details class="troubleshoot">
          <summary>Agent seems lost or confused</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Task too complex for context</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Decompose into smaller tasks. If the agent cannot hold the entire task in context, it will lose track. Break it down until each piece passes the 2-3 sentence test.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>"Done" but does not work</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No verification criteria</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add explicit verification command to the task definition. "Verify: npm test passes" or "Verify: GET /api/users returns 200"</p>
            </div>
          </div>
        </details>

        <!-- Concurrent Dispatch Expansion -->
        <h3>The Concurrent Dispatch Mental Model (from swarms)</h3>
        <p>Atomic tasks enable a powerful scale pattern: <strong>concurrent dispatch</strong>. The swarms library demonstrates thinking about agent work not as sequential steps but as a DAG (Directed Acyclic Graph) of parallel streams:</p>

        <div class="ascii-diagram">
CONCURRENT DISPATCH THINKING:

Sequential (Wrong):
  Task A -> Task B -> Task C -> Task D
  Total time: T(A) + T(B) + T(C) + T(D)

Concurrent (Right):
  Task A ----+
  Task B ----+---> Synchronization Point -> Final Task
  Task C ----+
  Total time: max(T(A), T(B), T(C)) + T(Final)

The swarms Pattern:
1. Identify independent tasks (no dependencies)
2. Spawn agents for ALL independent tasks simultaneously
3. Results converge at synchronization points
4. Failure in one stream doesn't block others
        </div>

        <p><strong>The swarms Topologies:</strong> The swarms library provides 10+ coordination patterns, each suited to different task structures:</p>
        <table>
          <thead>
            <tr>
              <th>Topology</th>
              <th>When to Use</th>
              <th>Atomic Task Requirement</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Sequential</td><td>Dependent steps</td><td>Each step atomic</td></tr>
            <tr><td>Concurrent</td><td>Independent subtasks</td><td>All tasks atomic, no deps</td></tr>
            <tr><td>Hierarchical</td><td>Complex decomposition</td><td>Parent/child atomic</td></tr>
            <tr><td>Graph</td><td>Complex dependencies</td><td>Nodes atomic, edges define deps</td></tr>
          </tbody>
        </table>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>You have 3+ independent subtasks (use concurrent)</li>
          <li>Tasks have clear dependency graphs (use graph topology)</li>
          <li>You want to minimize wall-clock time (parallelize atomics)</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Model 8 -->
      <section id="model-8">
        <h2>Mental Model 8: Model Tiering and Cost Optimization</h2>

        <h3>The Core Insight</h3>
        <p><strong>Right model for the right job. But model selection is only Layer 1 of cost optimization.</strong></p>
        <p>Using Opus for everything is like using a sledgehammer for every task, including turning screws. But there is more to cost optimization than just picking the right model.</p>

        <h3>The Three-Layer Cost Stack</h3>
        <div class="ascii-diagram">
+----------------------------------------------------------+
| LAYER 1: MODEL TIERING (Traditional)                      |
|   Haiku: Lookups, file fetches, simple transforms        |
|   Sonnet: Implementation, pattern following              |
|   Opus: Architecture, complex judgment                   |
|   -> 10-50% savings                                      |
+----------------------------------------------------------+
| LAYER 2: LLM BYPASS (from claude-flow)                   |
|   Use WASM/deterministic code for:                       |
|   - Simple file transformations                          |
|   - Predictable edits                                    |
|   - Template expansion                                   |
|   -> "85% API cost savings" for deterministic ops        |
+----------------------------------------------------------+
| LAYER 3: SEMANTIC CACHING (from LiteLLM)                 |
|   Proxy layer caches similar queries                     |
|   - "What does this function do?" cached across agents   |
|   - Same file analysis not repeated                      |
|   -> "250% extension of usage"                           |
+----------------------------------------------------------+

Application Order: Layer 2 -> Layer 3 -> Layer 1
(Try bypass first, then cache, then select model)
        </div>

        <h3>Model Tiering Framework</h3>
        <table>
          <thead>
            <tr>
              <th>Model</th>
              <th>Cost</th>
              <th>Strength</th>
              <th>Use For</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Haiku</td><td>1x</td><td>Fast, cheap</td><td>Lookups, file fetches</td></tr>
            <tr><td>Sonnet</td><td>12x</td><td>Balanced</td><td>Implementation</td></tr>
            <tr><td>Opus</td><td>60x</td><td>Deep reasoning</td><td>Architecture decisions</td></tr>
          </tbody>
        </table>

        <h3>Boris Cherny's Insight</h3>
        <blockquote>
          "Opus: higher generation, MUCH lower correction = faster overall."
        </blockquote>
        <p>The counterintuitive truth: Opus can be cheaper in total time. If Sonnet requires 3 iterations to get something right, and Opus gets it right in 1, Opus wins despite higher per-token cost.</p>

        <h3>Decision Matrix</h3>
        <table>
          <thead>
            <tr>
              <th>Task Type</th>
              <th>Model</th>
              <th>Reason</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Fetch file contents</td><td>Haiku</td><td>No reasoning needed</td></tr>
            <tr><td>Run grep/search</td><td>Haiku</td><td>Simple execution</td></tr>
            <tr><td>Standard CRUD</td><td>Sonnet</td><td>Pattern following</td></tr>
            <tr><td>Refactoring</td><td>Sonnet</td><td>Some reasoning</td></tr>
            <tr><td>Architecture decision</td><td>Opus</td><td>Deep reasoning</td></tr>
            <tr><td>Complex debugging</td><td>Opus</td><td>Multi-step reasoning</td></tr>
          </tbody>
        </table>

        <details class="troubleshoot">
          <summary>High API costs</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Using Opus for everything</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Apply the three-layer decision tree. First: can you bypass the LLM? Second: is this cached? Third: match model to task type.</p>
            </div>
          </div>
        </details>

        <!-- LLM Bypass Expansion -->
        <h3>The LLM Bypass Mental Model (from claude-flow)</h3>
        <p>The claude-flow architecture demonstrates a powerful cost optimization: <strong>deterministic bypass</strong>. Not every operation needs an LLM:</p>

        <div class="ascii-diagram">
CLAUDE-FLOW'S THREE-TIER EXECUTION:

Tier 1: LLM Required (Reasoning)
  - Architecture decisions
  - Novel implementations
  - Complex debugging
  -> Route to Claude with appropriate model tier

Tier 2: WASM/Code (Deterministic)
  - File transformations
  - Template expansion
  - JSON manipulation
  - Regex operations
  -> Execute with WASM, skip LLM entirely
  -> "85% API cost savings" for these operations

Tier 3: Cached (Previously Computed)
  - Similar queries seen before
  - Same file analysis repeated
  -> Return cached result
  -> "250% extension of usage"
        </div>

        <p><strong>The Anthropic Cookbook Canonical Patterns:</strong> Use the anthropic-cookbook as your baseline for deciding what needs reasoning vs what's deterministic:</p>
        <table>
          <thead>
            <tr>
              <th>Cookbook Pattern</th>
              <th>LLM Required?</th>
              <th>Why</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Text Classification</td><td>Yes</td><td>Semantic understanding</td></tr>
            <tr><td>JSON Extraction</td><td>Sometimes</td><td>Structured if schema clear, LLM if ambiguous</td></tr>
            <tr><td>Code Generation</td><td>Yes</td><td>Creative reasoning</td></tr>
            <tr><td>File Reading</td><td>No</td><td>Deterministic operation</td></tr>
            <tr><td>Search/Retrieval</td><td>No</td><td>Index lookup</td></tr>
            <tr><td>Summarization</td><td>Yes</td><td>Comprehension required</td></tr>
          </tbody>
        </table>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>You find yourself using LLM for file operations (stop - use tools)</li>
          <li>You're repeating similar queries (implement caching)</li>
          <li>You have predictable transformations (use WASM/code)</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Model 9 -->
      <section id="model-9">
        <h2>Mental Model 9: Learning Must Compound</h2>

        <h3>The Core Insight</h3>
        <p><strong>Every mistake becomes permanent context. Without compounding, progress is linear. With compounding, progress is exponential.</strong></p>
        <p>Agents do not learn across sessions. They have no memory of yesterday's mistakes. But YOU can create a system where learnings persist and compound, so every session starts with the wisdom of all previous sessions.</p>

        <h3>The Compounding Architecture</h3>
        <div class="ascii-diagram">
Session 1: Discovers pattern A -> Writes to CLAUDE.md
Session 2: Reads CLAUDE.md -> Has pattern A -> Discovers pattern B -> Writes both
Session 3: Reads CLAUDE.md -> Has A+B -> Discovers C -> Writes all three
...
Session N: Starts with accumulated wisdom of all previous sessions
        </div>

        <h3>Evidence Across Practitioners</h3>
        <table>
          <thead>
            <tr>
              <th>Source</th>
              <th>Compounding Mechanism</th>
              <th>Pattern</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Ryan Carson</td><td>progress.txt</td><td>"Every time I run Ralph, it gets better"</td></tr>
            <tr><td>All Ralph variants</td><td>Append-only log</td><td>Each iteration updates progress.txt</td></tr>
            <tr><td>BMAD-METHOD</td><td>Structured story files</td><td>"Every mistake becomes an instruction"</td></tr>
            <tr><td>agentic-flow</td><td>ReasoningBank</td><td>"Pre-Task: Search for similar past solutions"</td></tr>
            <tr><td>wshobson/agents</td><td>Skills repository</td><td>110 skills accumulated</td></tr>
          </tbody>
        </table>

        <h3>The Compounding Checklist</h3>
        <ul>
          <li>When agent makes a mistake, update CLAUDE.md with the anti-pattern</li>
          <li>When agent finds a successful pattern, update CLAUDE.md with the pattern</li>
          <li>When verification fails, document why and how to prevent</li>
          <li>Archive completed work with learnings for future reference</li>
          <li>Periodically review CLAUDE.md to promote patterns and prune noise</li>
        </ul>

        <details class="troubleshoot">
          <summary>Same mistakes repeating</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Anti-patterns not documented</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Document EVERY mistake as an anti-pattern in CLAUDE.md. Include the wrong approach and the correct alternative. The 5 minutes documenting saves 45 minutes in future sessions.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>CLAUDE.md too noisy</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Not pruning outdated learnings</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Quarterly review. Promote valuable patterns to permanent sections, prune stale or irrelevant entries. Keep CLAUDE.md focused on current project needs.</p>
            </div>
          </div>
        </details>

        <!-- Skills Repository Expansion -->
        <h3>The Skills Repository Mental Model (from wshobson/agents)</h3>
        <p>The wshobson/agents repository demonstrates compounding at scale: <strong>110 accumulated skills</strong> that grow the ecosystem's capability over time:</p>

        <div class="ascii-diagram">
SKILLS COMPOUNDING ARCHITECTURE:

Traditional (Linear):
  Session 1: Learn skill A -> Forget
  Session 2: Learn skill A again -> Forget
  Session 3: Learn skill A again -> No progress

Skills Repository (Exponential):
  Session 1: Learn skill A -> Document in skills/
  Session 2: Has A, learns B -> Document both
  Session N: Has 110 skills -> New agent starts with ALL of them

The wshobson/agents Evidence:
- 100+ agents created
- 110 skills accumulated
- New agents compose existing skills
- Capability ecosystem grows, never shrinks
        </div>

        <p><strong>Three Levels of Compounding:</strong></p>
        <table>
          <thead>
            <tr>
              <th>Level</th>
              <th>Mechanism</th>
              <th>Scale</th>
              <th>Example</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1. Project</td><td>CLAUDE.md</td><td>Single project</td><td>Anti-patterns for this codebase</td></tr>
            <tr><td>2. Organization</td><td>Skills repository</td><td>Multi-project</td><td>wshobson/agents 110 skills</td></tr>
            <tr><td>3. Swarm</td><td>ReasoningBank (claude-flow)</td><td>Cross-agent</td><td>Patterns indexed by similarity</td></tr>
          </tbody>
        </table>

        <p><strong>The claude-flow ReasoningBank Integration:</strong></p>
        <div class="ascii-diagram">
claude-flow's SONA (Self-Organizing Neural Architecture):
1. Pre-Task Query: "Find patterns similar to this task"
2. Context Injection: Load relevant patterns into agent
3. Post-Task Store: Save successful patterns with metadata
4. Reward Scoring: Track which patterns lead to success
        </div>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>Building multi-project agent systems (use skills repository)</li>
          <li>Running repeated similar tasks (use ReasoningBank)</li>
          <li>Creating organizational knowledge (structure compounding intentionally)</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Model 10 -->
      <section id="model-10">
        <h2>Mental Model 10: Simplicity Compensates for Non-Determinism</h2>

        <h3>The Core Insight</h3>
        <p><strong>Complex architectures fail catastrophically with probabilistic AI. Simplicity is a design goal, not a compromise.</strong></p>
        <p>AI agents are non-deterministic. The same prompt might produce different results. When you build complex architectures on top of non-deterministic foundations, small variations compound into large failures.</p>

        <h3>The Simplicity Principle</h3>
        <blockquote>
          "My setup might be surprisingly vanilla."
          <cite>-- Boris Cherny (Creator of Claude Code)</cite>
        </blockquote>
        <p>Translation: The creator of Claude Code uses CLAUDE.md for context, Plan mode for thinking, auto-accept for execution, and basic verification hooks. No fancy frameworks. No complex orchestration. Vanilla.</p>

        <h3>Why Simplicity Wins</h3>
        <ol>
          <li><strong>Debuggability</strong> - When something goes wrong, you can understand why</li>
          <li><strong>Predictability</strong> - Fewer moving parts = fewer unexpected interactions</li>
          <li><strong>Resilience</strong> - Simple systems degrade gracefully, complex systems fail catastrophically</li>
          <li><strong>Composability</strong> - Simple pieces combine better than complex frameworks</li>
        </ol>

        <h3>Evidence Across Practitioners</h3>
        <table>
          <thead>
            <tr>
              <th>Source</th>
              <th>Simplicity Evidence</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Boris Cherny</td><td>"My setup might be surprisingly vanilla"</td></tr>
            <tr><td>12-factor-agents</td><td>"Roll your own stack rather than LangChain/CrewAI"</td></tr>
            <tr><td>ccswarm</td><td>"Channel-based coordination: No shared memory, no race conditions"</td></tr>
            <tr><td>Canonical Ralph</td><td>Just bash + files + loop</td></tr>
            <tr><td>All production stacks</td><td>Files, SQLite, Git, shell - nothing exotic</td></tr>
          </tbody>
        </table>

        <h3>The Simplicity Stack (in order of preference)</h3>
        <ol>
          <li>CLAUDE.md (markdown file)</li>
          <li>SQLite (simple database)</li>
          <li>Git (version control as state)</li>
          <li>Shell scripts (basic orchestration)</li>
          <li>Custom Go/Python (only when needed)</li>
        </ol>
        <p><strong>Not in the stack:</strong> Vector databases, LangChain, CrewAI, complex graph stores, ML-based routing</p>

        <!-- Cookbook Baseline Expansion -->
        <h3>The Anthropic Cookbook as Canonical Baseline</h3>
        <p>When deciding between complex and simple, use the anthropic-cookbook as your reference for "how Anthropic intended it":</p>

        <div class="ascii-diagram">
CANONICAL SIMPLICITY (from anthropic-cookbook):

For prompting: Direct prompting > Complex chain patterns
For memory: Files and context > Vector stores
For tools: Native tool use > Framework abstractions
For agents: Claude Code patterns > Multi-framework orchestration

The cookbook demonstrates that sophisticated results
come from understanding fundamentals deeply,
not from adding more layers.
        </div>

        <p><strong>Cookbook Patterns to Default To:</strong></p>
        <table>
          <thead>
            <tr>
              <th>Task</th>
              <th>Cookbook Approach</th>
              <th>Avoid</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Conversation</td><td>Direct Claude API</td><td>Multi-layer chat frameworks</td></tr>
            <tr><td>Tool Use</td><td>Native function calling</td><td>LangChain tool abstractions</td></tr>
            <tr><td>Retrieval</td><td>Simple chunking + context</td><td>Complex RAG pipelines first</td></tr>
            <tr><td>Agents</td><td>Claude Code patterns</td><td>AutoGPT-style autonomous loops</td></tr>
          </tbody>
        </table>

        <p><strong>The Simplicity Test (Cookbook-Informed):</strong></p>
        <p>Before adding complexity, ask:</p>
        <ol>
          <li>Does the anthropic-cookbook show a simpler pattern?</li>
          <li>Can I achieve this with native Claude capabilities?</li>
          <li>What am I gaining that justifies the complexity?</li>
        </ol>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>Evaluating frameworks (check cookbook for native alternative first)</li>
          <li>Designing agent systems (start with cookbook patterns)</li>
          <li>Debugging complex failures (simplify to cookbook baseline)</li>
        </ul>

        <details class="troubleshoot">
          <summary>Cannot debug agent failures</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Too many layers of abstraction</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Remove abstractions until you can see what is happening. Replace framework calls with explicit code. Simplify until debugging is possible.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>"It worked yesterday" - intermittent failures</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Non-determinism + complexity</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Reduce complexity, add verification. Non-determinism cannot be eliminated, but its impact can be contained through simpler architectures with strong verification gates.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Navigation -->
      <div class="footer-nav">
        <a href="index.html" class="nav-prev">
          <span class="nav-direction">Previous</span>
          <span class="nav-title">Mental Models Overview</span>
        </a>
        <a href="advanced-models.html" class="nav-next">
          <span class="nav-direction">Next</span>
          <span class="nav-title">Advanced Models (11-16)</span>
        </a>
      </div>

      <!-- Woven Summaries Section -->
      <section id="go-deeper" class="callout-insight">
        <h2>Go Deeper: Full Guides</h2>
        <p>These core mental models are distilled from comprehensive synthesis documents. Explore the full guides for deeper context, worked examples, and practitioner evidence.</p>

        <div class="summary-card" style="background: #f0ebe3; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; border-left: 4px solid #2a7d7d;">
          <h3 style="margin-top: 0; color: #5c4b3a;">Core Principles: The 8 WHYs</h3>
          <p>The philosophical foundation behind every mental model. Understand WHY context is the primary constraint, WHY external state beats internal memory, and WHY fresh context outperforms extended sessions. These principles are the "physics" from which all patterns derive.</p>
          <p><strong>Key insight:</strong> <em>"Context rot: LLMs get stupider with more tokens"</em> - Every pattern compensates for this fundamental limitation.</p>
          <p><a href="../../synthesis/principles-core.html">Read the Full Core Principles Guide</a></p>
        </div>

        <div class="summary-card" style="background: #f0ebe3; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; border-left: 4px solid #6b9b7a;">
          <h3 style="margin-top: 0; color: #5c4b3a;">Staff Engineer Mental Model</h3>
          <p>Frontier thinking from practitioners building at the cutting edge. Covers Steve Yegge's Six Waves Framework (5x productivity multiplier per wave), the Gas Town agent factory architecture, and Beads for solving the "50 First Dates" problem with agent memory.</p>
          <p><strong>Key insight:</strong> <em>"The industry is chasing the 2025 CLI form factor while the frontier has moved to multi-agent orchestration."</em></p>
          <p><a href="../../synthesis/staff-engineer-mental-model.html">Read the Full Staff Engineer Guide</a></p>
        </div>

        <div class="summary-card" style="background: #f0ebe3; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; border-left: 4px solid #c49052;">
          <h3 style="margin-top: 0; color: #5c4b3a;">Boris Cherny's Complete 13-Point Workflow</h3>
          <p>The canonical workflow from the creator of Claude Code. Boris treats Claude not as a tool you use, but as capacity you schedule - 10-15 concurrent sessions across terminal, browser, and mobile. His complete system covers fresh context, CLAUDE.md foundation, task scoping, Plan Mode, verification hooks, and session closure.</p>
          <p><strong>Key insight:</strong> <em>"A wrong fast answer is slower than a right slow answer."</em> - Cost-per-reliable-outcome beats cost-per-token.</p>
          <p><a href="../../synthesis/boris-workflow-complete.html">Read Boris's Complete Workflow</a></p>
        </div>
      </section>

      <hr class="section-divider">

      <div class="related-pages">
        <h3>Related Content</h3>
        <ul>
          <li><a href="advanced-models.html">Advanced Mental Models (11-16)</a> - Scale evolution and orchestration thinking</li>
          <li><a href="practice-heuristics.html">Practice and Heuristics</a> - Anti-patterns and quick decision rules</li>
          <li><a href="../foundations/invariants-reference.html">Invariants Reference</a> - The 9 universal truths</li>
          <li><a href="../../foundations/principles/core.html">Core Principles</a> - The WHYs behind every pattern</li>
        </ul>
      </div>
    </main>
  </div>

  <!-- Mobile sidebar toggle -->
  <button class="sidebar-toggle" aria-label="Open navigation">Menu</button>
  <div class="sidebar-overlay"></div>

  <script src="../../js/sidebar.js"></script>
</body>
</html>
