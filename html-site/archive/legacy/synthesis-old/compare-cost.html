<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta data-pagefind-meta="section" content="Synthesis">
  <meta data-pagefind-meta="category" content="Comparisons">
  <title>Cost-Optimized Architecture Design - Claude Code Knowledge Base</title>
  <link rel="stylesheet" href="../css/style.css">
  <link rel="stylesheet" href="../css/sidebar.css">
  <link rel="stylesheet" href="../css/search.css">
</head>
<body>
  <!-- Search Modal -->
  <div class="search-modal" id="searchModal" aria-hidden="true">
    <div class="search-overlay" onclick="closeSearch()"></div>
    <div class="search-content">
      <div class="search-header">
        <div class="search-input-wrapper">
          <span class="search-icon-input">&#128269;</span>
          <input type="text" id="searchInput" placeholder="Search documentation..." autocomplete="off" />
          <kbd class="search-kbd">ESC</kbd>
        </div>
      </div>
      <div class="search-filters">
        <button class="filter-btn active" data-filter="all">All</button>
        <button class="filter-btn" data-filter="synthesis">Synthesis</button>
        <button class="filter-btn" data-filter="extractions">Extractions</button>
        <button class="filter-btn" data-filter="journeys">Journeys</button>
      </div>
      <div class="search-results" id="searchResults">
        <div class="search-empty"><p>Start typing to search... (Press Cmd+K anytime)</p></div>
      </div>
      <div class="search-footer">
        <span>Up/Down Navigate</span><span>Enter Select</span><span>ESC Close</span>
      </div>
    </div>
  </div>

  <button class="search-trigger" onclick="openSearch()" aria-label="Search" style="float: right; margin-bottom: 1rem;">
    <span class="search-icon">Cmd+K</span>
    <span class="search-text">Search</span>
  </button>

  <div class="wide-container">
    <!-- Breadcrumb Navigation -->
    <nav class="nav-breadcrumb">
      <a href="../index.html">Home</a>
      <span>/</span>
      <a href="synthesis-index.html">Synthesis</a>
      <span>/</span>
      <a href="compare-master.html">Comparisons</a>
      <span>/</span>
      <span>Cost Optimization</span>
    </nav>

    <!-- You Are Here Context Box -->
    <div class="you-are-here" style="background: linear-gradient(135deg, #f0ebe3 0%, #fefcf3 100%); border-left: 4px solid #2a7d7d; border-radius: 8px; padding: 1.5rem; margin-bottom: 2rem;">
      <h3 style="color: #2a7d7d; margin-top: 0; font-size: 0.9em; text-transform: uppercase; letter-spacing: 0.5px;">You Are Here</h3>
      <p style="margin-bottom: 0;"><strong><span class="b">Cost</span>-Optimized <span class="b">Arch</span>itecture <span class="b">Des</span>ign</strong> - A comprehensive guide to balancing cost versus capability when building AI agent systems with Claude Code. Use this when API costs are becoming a concern or when planning budget for autonomous workflows.</p>
    </div>

    <h1><span class="b">Cost</span>-Optimized <span class="b">Arch</span>itecture <span class="b">Des</span>ign</h1>

    <!-- Table of Contents -->
    <div class="toc">
      <div class="toc-title">Contents</div>
      <ul>
        <li><a href="#cost-factors">Cost Factors</a></li>
        <li><a href="#model-selection">Model Selection Strategy</a></li>
        <li><a href="#cost-saving-patterns">Cost-Saving Patterns</a></li>
        <li><a href="#per-pattern-cost">Per-Pattern Cost Analysis</a></li>
        <li><a href="#cost-calculator">Cost Calculator</a></li>
        <li><a href="#budget-engineering">Budget Engineering</a></li>
        <li><a href="#roi-analysis">ROI Analysis</a></li>
        <li><a href="#real-world-costs">Real-World Cost Reports</a></li>
        <li><a href="#optimization-checklists">Cost Optimization Checklists</a></li>
        <li><a href="#advanced-strategies">Advanced Strategies</a></li>
        <li><a href="#troubleshooting">Troubleshooting</a></li>
      </ul>
    </div>

    <hr class="section-divider">

    <!-- Cost Factors -->
    <section id="cost-factors">
      <h2><span class="b">Cost</span> <span class="b">Fac</span>tors</h2>

      <p>Understanding the four primary cost vectors is essential for optimization:</p>

      <h3>1. Model Selection</h3>
      <p>The most impactful cost lever. Price differential is dramatic:</p>

      <div class="table-responsive">
        <table class="comparison-table">
          <thead>
            <tr>
              <th>Model</th>
              <th>Input (per 1M tokens)</th>
              <th>Output (per 1M tokens)</th>
              <th>Cost Multiplier</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><strong>Claude 3.5 Haiku</strong></td><td>$0.25</td><td>$1.25</td><td>1x (baseline)</td></tr>
            <tr><td><strong>Claude Sonnet 4</strong></td><td>$3.00</td><td>$15.00</td><td>12x</td></tr>
            <tr><td><strong>Claude Opus 4.5</strong></td><td>$15.00</td><td>$75.00</td><td>60x</td></tr>
          </tbody>
        </table>
      </div>

      <div class="callout callout-warning">
        <div class="callout-title">Key Insight</div>
        <p>Opus output is <strong>60x more expensive</strong> than Haiku output. A 1000-token response costs $0.00125 with Haiku vs $0.075 with Opus.</p>
      </div>

      <h3>2. Token Usage (Context Size)</h3>
      <p>Context accumulation is the silent cost killer:</p>

      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Context State</th><th>Token Range</th><th>Cost Implication</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Fresh context</strong></td><td>0-20K</td><td>Optimal efficiency</td></tr>
            <tr><td><strong>Working context</strong></td><td>20K-100K</td><td>Normal operation</td></tr>
            <tr><td><strong>Heavy context</strong></td><td>100K-150K</td><td>Diminishing returns</td></tr>
            <tr><td><strong>Context rot zone</strong></td><td>150K-200K</td><td>Quality degrades, waste increases</td></tr>
          </tbody>
        </table>
      </div>

      <h3>3. Iteration Count</h3>
      <p>More iterations = more cost, but relationship isn't linear:</p>

      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Iterations</th><th>Typical Use Case</th><th>Cost Curve</th></tr>
          </thead>
          <tbody>
            <tr><td>1-5</td><td>Simple features</td><td>Linear</td></tr>
            <tr><td>5-15</td><td>Standard features</td><td>Linear + overhead</td></tr>
            <tr><td>15-30</td><td>Complex features</td><td>Sublinear (learning compounds)</td></tr>
            <tr><td>30-50+</td><td>Large systems</td><td>Variable (depends on verification)</td></tr>
          </tbody>
        </table>
      </div>

      <p><strong>Insight:</strong> Good planning upfront reduces iterations by 50-80%.</p>

      <h3>4. Parallelism</h3>
      <p>Parallel agents multiply costs but can reduce calendar time:</p>

      <div class="ascii-diagram">
Sequential (1 agent, 10 tasks):
Time: 10 hours | Cost: 10 agent-hours

Parallel (5 agents, 10 tasks):
Time: 2 hours | Cost: 10 agent-hours (same total)

BUT: Parallel often requires coordination overhead (+10-20%)</div>
    </section>

    <hr class="section-divider">

    <!-- Model Selection Strategy -->
    <section id="model-selection">
      <h2><span class="b">Mod</span>el <span class="b">Sel</span>ection <span class="b">Strat</span>egy</h2>

      <h3>When to Use Opus 4.5</h3>
      <p><strong>Opus is the premium tier ($15/$75 per 1M tokens)</strong></p>

      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Use Case</th><th>Why Opus</th><th>Cost Justification</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Complex reasoning</strong></td><td>Multi-step logic, nuanced decisions</td><td>Fewer retries save money</td></tr>
            <tr><td><strong>Orchestration decisions</strong></td><td>Task decomposition, dependency planning</td><td>Architecture errors expensive to fix</td></tr>
            <tr><td><strong>Architecture planning</strong></td><td>System design, technology choices</td><td>Bad architecture = massive rework</td></tr>
            <tr><td><strong>Quality-critical work</strong></td><td>Security review, production debugging</td><td>Bugs in production cost more than Opus</td></tr>
            <tr><td><strong>Ambiguous requirements</strong></td><td>Clarifying vague specs</td><td>Misunderstanding wastes entire iterations</td></tr>
          </tbody>
        </table>
      </div>

      <p><strong>Rule of Thumb:</strong> If a mistake at this step would cascade into expensive rework, use Opus.</p>

      <h3>When to Use Sonnet</h3>
      <p><strong>Sonnet is the workhorse tier ($3/$15 per 1M tokens)</strong></p>

      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Use Case</th><th>Why Sonnet</th><th>Cost Justification</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>General implementation</strong></td><td>Writing code to spec</td><td>Fast, capable, cost-effective</td></tr>
            <tr><td><strong>Worker tasks</strong></td><td>Following established patterns</td><td>Clear instructions don't need Opus</td></tr>
            <tr><td><strong>Most coding work</strong></td><td>Features, bug fixes, refactoring</td><td>Sweet spot of capability/cost</td></tr>
            <tr><td><strong>Test generation</strong></td><td>Writing test cases</td><td>Pattern-following task</td></tr>
            <tr><td><strong>Code review</strong></td><td>Reviewing PRs, suggesting improvements</td><td>Good judgment, not maximum reasoning</td></tr>
          </tbody>
        </table>
      </div>

      <p><strong>Default Choice:</strong> Start with Sonnet. Only upgrade to Opus if Sonnet fails or task requires complex reasoning.</p>

      <h3>When to Use Haiku</h3>
      <p><strong>Haiku is the efficiency tier ($0.25/$1.25 per 1M tokens)</strong></p>

      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Use Case</th><th>Why Haiku</th><th>Cost Justification</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Simple tasks</strong></td><td>File lookups, greps, formatting</td><td>No reasoning required</td></tr>
            <tr><td><strong>Testing/verification</strong></td><td>Running tests, checking status</td><td>Pass/fail determination</td></tr>
            <tr><td><strong>High-volume work</strong></td><td>Bulk operations, repetitive tasks</td><td>Volume makes cost critical</td></tr>
            <tr><td><strong>Errand running</strong></td><td>Fetch files, simple transformations</td><td>CC Mirror's "spawn 5-10 in parallel"</td></tr>
            <tr><td><strong>Health checks</strong></td><td>Monitoring, status polling</td><td>Simple queries</td></tr>
          </tbody>
        </table>
      </div>

      <div class="callout callout-insight">
        <div class="callout-title">The Haiku Army</div>
        <p>For embarrassingly parallel tasks, <strong>10 Haiku workers often outperform 1 Opus</strong> at 1/60th the cost.</p>
      </div>

      <h3>Model Selection by Role (Gas Town Framework)</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Role</th><th>Recommended Model</th><th>Hourly Cost Est.</th><th>Rationale</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Mayor</strong> (coordination)</td><td>Opus 4.5</td><td>$15-20</td><td>Complex cross-rig decisions</td></tr>
            <tr><td><strong>Refinery</strong> (decomposition)</td><td>Opus 4.5</td><td>$15-20</td><td>Task breakdown is architectural</td></tr>
            <tr><td><strong>Dogs</strong> (quality gates)</td><td>Sonnet</td><td>$5-8</td><td>Review requires judgment</td></tr>
            <tr><td><strong>Polecat</strong> (named workers)</td><td>Sonnet</td><td>$5-10</td><td>Implementation work</td></tr>
            <tr><td><strong>Witness</strong> (observation)</td><td>Haiku</td><td>$1-3</td><td>Logging, status tracking</td></tr>
            <tr><td><strong>Deacon</strong> (health checks)</td><td>Haiku</td><td>$1-2</td><td>Simple monitoring</td></tr>
            <tr><td><strong>Crew</strong> (ephemeral)</td><td>Haiku</td><td>$0.50-2</td><td>Quick, isolated tasks</td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <hr class="section-divider">

    <!-- Checkpoint -->
    <div class="checkpoint" style="background: #f0ebe3; border-left: 4px solid #6b9b7a; border-radius: 8px; padding: 1.5rem; margin: 2rem 0;">
      <div class="checkpoint-header" style="color: #6b9b7a; font-weight: 600;">Checkpoint: Cost Factors</div>
      <p><strong>You should now understand:</strong></p>
      <ul>
        <li>The four primary cost factors (Model, Tokens, Iterations, Parallelism)</li>
        <li>The dramatic price differences between Haiku, Sonnet, and Opus</li>
        <li>When to use each model tier based on task requirements</li>
        <li>The "context rot" problem and why fresh context saves money</li>
      </ul>
      <p><strong>If unclear:</strong> Re-read the Model Selection Strategy section, especially the tables showing when to use each model.</p>
    </div>

    <hr class="section-divider">

    <!-- Cost-Saving Patterns -->
    <section id="cost-saving-patterns">
      <h2><span class="b">Cost</span>-Saving <span class="b">Pat</span>terns</h2>

      <h3>Pattern 1: Fresh Context (Ralph Wiggum)</h3>
      <p>The Ralph pattern uses fresh context per iteration rather than growing conversations.</p>

      <div class="ascii-diagram">
Traditional long session:
+-- Iteration 1: 10K context
+-- Iteration 5: 50K context (5x input cost)
+-- Iteration 10: 100K context (10x input cost)
+-- Quality degrading, more retries needed

Ralph fresh context:
+-- Iteration 1: 10K context
+-- Iteration 5: 10K context (same cost)
+-- Iteration 10: 10K context (same cost)
+-- Quality maintained, fewer retries</div>

      <p><strong>Cost Math:</strong></p>
      <ul>
        <li>Long session (10 iterations, growing context): ~$5-10</li>
        <li>Ralph (10 iterations, fresh context): ~$2-4</li>
        <li><strong>Savings: 50-60%</strong></li>
      </ul>

      <h3>Pattern 2: Worker Model Selection</h3>
      <p>Tiered model selection for orchestrated systems:</p>

      <div class="ascii-diagram">
orchestrator: opus (planning, coordination)
    +-- workers: sonnet (implementation)
            +-- verification: haiku (testing)</div>

      <p><strong>Cost comparison:</strong></p>
      <ul>
        <li>All-Opus workflow: $100 (baseline)</li>
        <li>Tiered workflow: $35 (-65%)</li>
        <li>Aggressive Haiku use: $20 (-80%)</li>
      </ul>

      <h3>Pattern 3: Early Exit (Promise Pattern)</h3>
      <p>Stop when done, don't iterate unnecessarily:</p>
      <div class="code-block">
        <button class="copy-btn" onclick="copyCode(this)">Copy</button>
        <pre><code>if grep -q "&lt;promise&gt;COMPLETE&lt;/promise&gt;" output.txt; then
  echo "Done early!"
  break
fi</code></pre>
      </div>

      <p><strong>Cost impact:</strong></p>
      <ul>
        <li>Without early exit: Always runs MAX_ITERATIONS</li>
        <li>With early exit: Average 60-70% of MAX_ITERATIONS</li>
        <li><strong>Savings: 30-40% on iteration costs</strong></li>
      </ul>

      <h3>Pattern 4: Prompt Caching</h3>
      <p>Anthropic's prompt caching provides 90% discount on cached content:</p>

      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Model</th><th>Cache Write (per 1M)</th><th>Cache Read (per 1M)</th><th>Savings</th></tr>
          </thead>
          <tbody>
            <tr><td>Haiku</td><td>$0.30</td><td>$0.03</td><td>90%</td></tr>
            <tr><td>Sonnet</td><td>$3.75</td><td>$0.30</td><td>90%</td></tr>
            <tr><td>Opus</td><td>$18.75</td><td>$1.50</td><td>90%</td></tr>
          </tbody>
        </table>
      </div>

      <h3>Pattern 5: Batches API</h3>
      <p>50% discount for non-urgent workloads. Best for bulk document processing, overnight analysis, test generation at scale.</p>

      <h3>Pattern 6: Subagent Token Isolation</h3>
      <p>Protect main context from expensive operations:</p>

      <div class="ascii-diagram">
Main Agent (lean)
    |
    +-- Subagent: Browser Automation
        +-- (High token cost stays isolated)
        +-- Returns: Summary only</div>

      <blockquote>
        <p>"The feedback loop is everything, but put costly tools like browser control in subagents to protect your main context window tokens"</p>
        <cite>-- @TendiesOfWisdom</cite>
      </blockquote>

      <p><strong>Savings:</strong> 50-70% for browser/MCP-heavy workflows</p>

      <h3>Pattern 7: Output Length Control</h3>
      <p>Output tokens cost 5x more than input for most models. Use max_tokens limits and request concise responses.</p>
      <p><strong>Savings:</strong> 50-80% on output tokens</p>
    </section>

    <hr class="section-divider">

    <!-- Per-Pattern Cost Analysis -->
    <section id="per-pattern-cost">
      <h2><span class="b">Per</span>-Pattern <span class="b">Cost</span> Analysis</h2>

      <div class="table-responsive">
        <table class="comparison-table">
          <thead>
            <tr>
              <th>Pattern</th>
              <th>Typical Cost</th>
              <th>Duration</th>
              <th>Token Usage</th>
              <th>Best For</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><strong>Basic Ralph (10 iter)</strong></td><td>$2-5</td><td>30-60 min</td><td>30K-100K/iter</td><td>Single features</td></tr>
            <tr><td><strong>Extended Ralph (25 iter)</strong></td><td>$8-15</td><td>2-4 hours</td><td>75K-375K total</td><td>Complex features</td></tr>
            <tr><td><strong>Overnight Ralph (50 iter)</strong></td><td>$20-50</td><td>6-12 hours</td><td>150K-750K total</td><td>Full components</td></tr>
            <tr><td><strong>CC Mirror (5 workers)</strong></td><td>$5-15</td><td>30-60 min</td><td>Parallel execution</td><td>Team coordination</td></tr>
            <tr><td><strong>CC Mirror (full team)</strong></td><td>$15-40</td><td>1-3 hours</td><td>Heavy parallel</td><td>Complex projects</td></tr>
            <tr><td><strong>Gas Town (minimal)</strong></td><td>$50-100/day</td><td>Continuous</td><td>Multiple accounts</td><td>Solo founder</td></tr>
            <tr><td><strong>Gas Town (full)</strong></td><td>$200-500/day</td><td>Continuous</td><td>Heavy multi-agent</td><td>Teams, agencies</td></tr>
          </tbody>
        </table>
      </div>

      <h3>Cost by Orchestration Pattern</h3>
      <div class="ascii-diagram">
+-------------------------------------------------------------------+
|                    COST vs COMPLEXITY                              |
+-------------------------------------------------------------------+
|                                                                    |
|  $$$$$       +---------------------------------------+             |
|              |                        Gas Town       |             |
|  $$$$        |                        (Full)         |             |
|              |                                       |             |
|  $$$         |              Gas Town                 |             |
|              |              (Minimal)   Orchestra    |             |
|  $$          |    CC Mirror            /             |             |
|              |    (Full)    /                        |             |
|  $           |    CC Mirror/    Ralph (Extended)     |             |
|              |    (3-cmd)       /                    |             |
|  c           |  Ralph (Basic)  /                     |             |
|              +---------------------------------------+             |
|              SIMPLE -------------------------------- COMPLEX       |
|                                                                    |
+-------------------------------------------------------------------+</div>
    </section>

    <hr class="section-divider">

    <!-- Cost Calculator -->
    <section id="cost-calculator">
      <h2><span class="b">Cost</span> <span class="b">Cal</span>culator</h2>

      <h3>Formula</h3>
      <div class="ascii-diagram">
Total Cost = Context Cost + Iteration Cost + Parallelism Overhead

Where:
  Context Cost = tokens_per_iteration x model_rate x iterations
  Iteration Cost = (setup_tokens + task_tokens + verification_tokens) x model_rate
  Parallelism Overhead = worker_count x coordination_tokens x model_rate</div>

      <h3>Quick Estimation Table</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Variable</th><th>Haiku</th><th>Sonnet</th><th>Opus</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Cost per 1K input tokens</strong></td><td>$0.00025</td><td>$0.003</td><td>$0.015</td></tr>
            <tr><td><strong>Cost per 1K output tokens</strong></td><td>$0.00125</td><td>$0.015</td><td>$0.075</td></tr>
            <tr><td><strong>Typical iteration cost</strong></td><td>$0.05-0.20</td><td>$0.50-2.00</td><td>$2.00-5.00</td></tr>
            <tr><td><strong>Worker-hour estimate</strong></td><td>$1-3</td><td>$5-10</td><td>$15-20</td></tr>
          </tbody>
        </table>
      </div>

      <h3>Worked Example: 10-Iteration Ralph Loop</h3>
      <p><strong>Scenario:</strong> Building a REST API feature</p>

      <div class="ascii-diagram">
Per iteration:
- Input: 8K tokens (prd.json, progress.txt, code context)
- Output: 2K tokens (implementation, commit)
- Model: Sonnet

Cost per iteration:
- Input: 8K x $0.003/1K = $0.024
- Output: 2K x $0.015/1K = $0.030
- Total: $0.054

10 iterations: $0.54

With overhead (tools, verification): ~$1-2 total</div>

      <p><strong>Comparison by model:</strong></p>
      <ul>
        <li>Haiku: ~$0.15-0.30</li>
        <li>Sonnet: ~$1-2</li>
        <li>Opus: ~$6-10</li>
      </ul>
    </section>

    <hr class="section-divider">

    <!-- Budget Engineering -->
    <section id="budget-engineering">
      <h2><span class="b">Bud</span>get <span class="b">Eng</span>ineering</h2>

      <h3>Setting Limits</h3>

      <h4>Max Iterations</h4>
      <div class="code-block">
        <button class="copy-btn" onclick="copyCode(this)">Copy</button>
        <pre><code># Always set a safety backstop
MAX_ITERATIONS=25  # Never more than this
./ralph.sh $MAX_ITERATIONS</code></pre>
      </div>

      <h3>Alert Thresholds</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Level</th><th>Trigger</th><th>Action</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Warning</strong></td><td>50% of daily budget</td><td>Log, continue</td></tr>
            <tr><td><strong>Critical</strong></td><td>80% of daily budget</td><td>Alert (Slack/email)</td></tr>
            <tr><td><strong>Pause</strong></td><td>95% of daily budget</td><td>Pause non-critical work</td></tr>
            <tr><td><strong>Shutdown</strong></td><td>100% of daily budget</td><td>Stop all work</td></tr>
          </tbody>
        </table>
      </div>

      <h3>Budget Tiers by Use Case</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>User Type</th><th>Monthly Budget</th><th>Recommended Setup</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Hobbyist</strong></td><td>$20-50</td><td>Pro subscription, occasional API</td></tr>
            <tr><td><strong>Solo dev</strong></td><td>$100-300</td><td>Ralph loops, Sonnet-heavy</td></tr>
            <tr><td><strong>Power user</strong></td><td>$500-1000</td><td>CC Mirror, tiered models</td></tr>
            <tr><td><strong>Team</strong></td><td>$1000-3000</td><td>Gas Town minimal, shared infra</td></tr>
            <tr><td><strong>Agency</strong></td><td>$3000-10000</td><td>Gas Town full, multi-project</td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <hr class="section-divider">

    <!-- ROI Analysis -->
    <section id="roi-analysis">
      <h2><span class="b">ROI</span> <span class="b">Ana</span>lysis</h2>

      <h3>Investment vs Return</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Investment</th><th>Setup Cost</th><th>Ongoing Cost</th><th>Return</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Ralph setup</strong></td><td>1 hour</td><td>~$2-10/feature</td><td>Overnight shipping capability</td></tr>
            <tr><td><strong>CC Mirror</strong></td><td>5 minutes</td><td>~$5-20/session</td><td>3-5x parallelism</td></tr>
            <tr><td><strong>Gas Town</strong></td><td>Hours/days</td><td>$200-500/day</td><td>10+ agent orchestration</td></tr>
            <tr><td><strong>Claude HUD</strong></td><td>5 minutes</td><td>Free</td><td>Context awareness</td></tr>
            <tr><td><strong>Prompt caching</strong></td><td>30 minutes</td><td>-90% on cached</td><td>Major savings at scale</td></tr>
          </tbody>
        </table>
      </div>

      <h3>Value Multiplication</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Pattern</th><th>Cost</th><th>Developer Time Saved</th><th>Value Multiplier</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>Ralph overnight</strong></td><td>$20</td><td>8 hours</td><td>40x at $100/hr</td></tr>
            <tr><td><strong>CC Mirror parallel</strong></td><td>$15</td><td>4 hours</td><td>27x at $100/hr</td></tr>
            <tr><td><strong>Haiku army for bulk</strong></td><td>$5</td><td>2 hours</td><td>40x at $100/hr</td></tr>
          </tbody>
        </table>
      </div>

      <div class="callout callout-insight">
        <div class="callout-title">The Fundamental Equation</div>
        <p><code>If AI_cost < (Developer_hourly_rate x Hours_saved x Quality_factor)</code></p>
        <p><code>Then: Use AI</code></p>
      </div>
    </section>

    <hr class="section-divider">

    <!-- Real-World Cost Reports -->
    <section id="real-world-costs">
      <h2><span class="b">Real</span>-World <span class="b">Cost</span> Reports</h2>

      <h3>Community Data Points</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Source</th><th>Setup</th><th>Usage</th><th>Reported Cost</th></tr>
          </thead>
          <tbody>
            <tr><td><strong>@arvidkahl</strong></td><td>Ralph loops</td><td>50 iterations</td><td>$50-100+</td></tr>
            <tr><td><strong>@dabit3</strong></td><td>Cloud VM + API</td><td>Mobile setup</td><td>~$7/day (VM) + API</td></tr>
            <tr><td><strong>@steve_yegge</strong></td><td>Gas Town</td><td>Production</td><td>"Multiple Claude accounts"</td></tr>
            <tr><td><strong>Pro subscription</strong></td><td>Claude.ai</td><td>Interactive</td><td>$20/month</td></tr>
            <tr><td><strong>Max subscription</strong></td><td>Claude.ai</td><td>Heavy use</td><td>$100/month (est.)</td></tr>
          </tbody>
        </table>
      </div>

      <h3>Monthly Cost by Usage Pattern</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Usage Pattern</th><th>Model Mix</th><th>Estimated Monthly Cost</th></tr>
          </thead>
          <tbody>
            <tr><td>Light (1-2 hrs/day)</td><td>Sonnet-heavy</td><td>$20-50</td></tr>
            <tr><td>Moderate (4-6 hrs/day)</td><td>Mixed</td><td>$100-200</td></tr>
            <tr><td>Heavy (8+ hrs/day)</td><td>Opus-heavy</td><td>$300-500+</td></tr>
            <tr><td>Power user (loops)</td><td>Mixed + automation</td><td>$500-1000+</td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <hr class="section-divider">

    <!-- Optimization Checklists -->
    <section id="optimization-checklists">
      <h2><span class="b">Cost</span> <span class="b">Opt</span>imization <span class="b">Check</span>lists</h2>

      <h3>Daily Optimization Checklist</h3>
      <ul>
        <li>Start with correct model for task (default: Sonnet, upgrade if needed)</li>
        <li>Use Claude HUD to monitor context usage</li>
        <li>Compact or reset before hitting 80% context</li>
        <li>Keep responses concise (set max_tokens limits)</li>
        <li>Stop VMs when not in use</li>
        <li>Check for early exit conditions (promise complete)</li>
      </ul>

      <h3>Weekly Optimization Review</h3>
      <ul>
        <li>Review Anthropic Console usage dashboard</li>
        <li>Identify most expensive sessions/tasks</li>
        <li>Consider batching for bulk work done this week</li>
        <li>Update CLAUDE.md with learned patterns (reduces re-explaining)</li>
        <li>Evaluate if subscription tier is appropriate</li>
        <li>Archive completed PRD files for future learning</li>
      </ul>

      <h3>Before Starting Expensive Work</h3>
      <ul>
        <li>Is this the right model tier? (Haiku -> Sonnet -> Opus)</li>
        <li>Can this be parallelized with cheaper models?</li>
        <li>Is the task well-defined? (vague = expensive)</li>
        <li>Are verification steps in place? (catch failures early)</li>
        <li>Is there an early exit condition?</li>
        <li>Has similar work been cached?</li>
      </ul>
    </section>

    <hr class="section-divider">

    <!-- Advanced Strategies -->
    <section id="advanced-strategies">
      <h2><span class="b">Adv</span>anced <span class="b">Strat</span>egies</h2>

      <h3>Dynamic Model Routing</h3>
      <p>Automatically select model based on task complexity. Use pattern matching to identify simple queries (Haiku), complex reasoning (Opus), or default to Sonnet.</p>

      <h3>Fallback Cascade</h3>
      <p>Start cheap, escalate on failure:</p>
      <ol>
        <li>Try Haiku first</li>
        <li>If response quality low, retry with Sonnet</li>
        <li>Only escalate to Opus if Sonnet fails</li>
      </ol>

      <h3>Semantic Caching</h3>
      <p>Cache semantically similar queries, not just exact matches. Use embeddings to find similar previously-answered questions.</p>

      <h3>Token Compression</h3>
      <p>Reduce input tokens for data-heavy prompts by using JSON instead of prose. Example: 89 tokens of prose becomes 47 tokens of JSON (47% savings).</p>

      <h3>Top 10 Cost Optimization Strategies</h3>
      <div class="table-responsive">
        <table>
          <thead>
            <tr><th>Rank</th><th>Strategy</th><th>Potential Savings</th><th>Effort</th></tr>
          </thead>
          <tbody>
            <tr><td>1</td><td><strong>Model selection</strong> (Haiku/Sonnet over Opus)</td><td>60-95%</td><td>Low</td></tr>
            <tr><td>2</td><td><strong>Prompt caching</strong> for large system prompts</td><td>90% on cached</td><td>Low</td></tr>
            <tr><td>3</td><td><strong>Batches API</strong> for bulk work</td><td>50%</td><td>Medium</td></tr>
            <tr><td>4</td><td><strong>Output length limits</strong></td><td>50-80%</td><td>Low</td></tr>
            <tr><td>5</td><td><strong>Subagent delegation</strong> for expensive tools</td><td>50-70%</td><td>Medium</td></tr>
            <tr><td>6</td><td><strong>Fresh context</strong> (Ralph pattern)</td><td>60-80%</td><td>Medium</td></tr>
            <tr><td>7</td><td><strong>Early exit conditions</strong></td><td>30-40%</td><td>Low</td></tr>
            <tr><td>8</td><td><strong>Concise prompts</strong></td><td>10-50%</td><td>Low</td></tr>
            <tr><td>9</td><td><strong>Context monitoring</strong> (Claude HUD)</td><td>20-30%</td><td>Low</td></tr>
            <tr><td>10</td><td><strong>Model fallback cascade</strong></td><td>40-60%</td><td>Medium</td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <hr class="section-divider">

    <!-- Troubleshooting -->
    <section id="troubleshooting">
      <h2><span class="b">Trou</span>bleshooting</h2>

      <details class="troubleshoot">
        <summary>Unexpected High Costs</summary>
        <div>
          <p><strong>Symptom:</strong> API bill much higher than estimated; daily budget exceeded quickly.</p>
          <p><strong>Cause:</strong> Using Opus for simple tasks, context accumulation, or workers spawning sub-workers.</p>
          <p><strong>Fix:</strong> Audit your model selection. Check Claude HUD for context percentage. Review worker preambles.</p>
          <div class="code-block">
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
            <pre><code># Check Anthropic Console for usage breakdown
# https://console.anthropic.com/settings/usage

# Quick local cost estimation (if tracking)
cat ~/.claude/cost-log.csv | tail -20</code></pre>
          </div>
        </div>
      </details>

      <details class="troubleshoot">
        <summary>Ralph Loop Costs More Than Expected</summary>
        <div>
          <p><strong>Symptom:</strong> 25-iteration loop costs $50+ instead of expected $10-20.</p>
          <p><strong>Cause:</strong> Context not actually resetting between iterations; large progress.txt being loaded.</p>
          <p><strong>Fix:</strong> Verify loop script starts fresh Claude instance each iteration. Prune progress.txt regularly.</p>
          <div class="code-block">
            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
            <pre><code># Check progress.txt size
wc -l scripts/ralph/progress.txt

# If too large, archive and reset
mv scripts/ralph/progress.txt scripts/ralph/progress-archive-$(date +%Y%m%d).txt
echo "# Progress" > scripts/ralph/progress.txt</code></pre>
          </div>
        </div>
      </details>

      <details class="troubleshoot">
        <summary>Model Tier Confusion</summary>
        <div>
          <p><strong>Symptom:</strong> Tasks failing with Haiku that should work; overspending on Opus for simple tasks.</p>
          <p><strong>Cause:</strong> Incorrect task-to-model matching; not testing with cheaper models first.</p>
          <p><strong>Fix:</strong> Default to Sonnet. Only use Haiku for truly simple tasks (lookups, status checks). Only use Opus for complex reasoning or architecture decisions.</p>
        </div>
      </details>

      <details class="troubleshoot">
        <summary>Prompt Caching Not Working</summary>
        <div>
          <p><strong>Symptom:</strong> Expecting 90% savings but seeing full prices.</p>
          <p><strong>Cause:</strong> Cache control not properly configured; prompts too small to cache; TTL expired.</p>
          <p><strong>Fix:</strong> Verify <code>cache_control</code> is set on system prompts. Ensure prompts are > 1024 tokens. Check cache hit rates in API response.</p>
        </div>
      </details>

      <details class="troubleshoot">
        <summary>Budget Alerts Not Firing</summary>
        <div>
          <p><strong>Symptom:</strong> Exceeded budget without notification; discovered overspend days later.</p>
          <p><strong>Cause:</strong> No monitoring in place; Anthropic Console alerts not configured.</p>
          <p><strong>Fix:</strong> Set up Anthropic Console budget alerts. Add local tracking to your workflow.</p>
        </div>
      </details>
    </section>

    <hr class="section-divider">

    <!-- Philosophy Section -->
    <section id="philosophy">
      <h2><span class="b">The</span> Philosophy: <span class="b">Cost</span> as a <span class="b">Fea</span>ture</h2>

      <p>Steve Yegge's warning about Gas Town applies broadly:</p>

      <blockquote>
        <p>"If you care about costs, don't use this."</p>
      </blockquote>

      <p>But for most of us, cost matters. The key is <strong>intentional spending</strong>:</p>

      <ol>
        <li><strong>Know your break-even:</strong> Developer time saved vs API cost</li>
        <li><strong>Right-size models:</strong> Don't use Opus where Haiku suffices</li>
        <li><strong>Invest in infrastructure:</strong> Caching, monitoring, batching pay dividends</li>
        <li><strong>Accept imperfection:</strong> Some rework is cheaper than over-engineering</li>
        <li><strong>Measure and iterate:</strong> Track costs, optimize what matters</li>
      </ol>

      <div class="callout callout-insight">
        <div class="callout-title">The Winning Formula</div>
        <p><strong>Fresh context + Tiered models + Early exit + Verification = Maximum value per dollar</strong></p>
      </div>
    </section>

    <hr class="section-divider">

    <!-- Related Pages -->
    <div class="related-pages">
      <h3>Related Pages</h3>
      <ul>
        <li><a href="compare-memory.html">Memory Approaches Compared</a> - Managing external state cost-effectively</li>
        <li><a href="compare-observability.html">Observability Compared</a> - Monitoring cost and performance</li>
        <li><a href="../journeys/operations/monitoring-cost.html">Cost Monitoring Journey</a> - Hands-on implementation</li>
      </ul>
    </div>

    <!-- Footer Navigation -->
    <nav class="footer-nav">
      <a href="compare-memory.html" class="nav-prev">
        <span class="nav-direction">Previous</span>
        <span class="nav-title">Memory Compared</span>
      </a>
      <a href="compare-observability.html" class="nav-next">
        <span class="nav-direction">Next</span>
        <span class="nav-title">Observability Compared</span>
      </a>
    </nav>

  </div>

  <nav class="left-nav" id="leftNav">
    <div class="px-4 mb-4">
      <a href="../index.html" class="text-xs font-semibold text-accent hover:text-accent-light uppercase tracking-wider">Claude Code KB</a>
    </div>
    <div class="nav-content"></div>
  </nav>

  <script src="../js/search.js"></script>
  <script src="../js/sidebar.js"></script>
  <script src="../js/global-nav.js"></script>
  <script>
    function copyCode(button) {
      const codeBlock = button.parentElement.querySelector('code');
      navigator.clipboard.writeText(codeBlock.textContent);
      button.textContent = 'Copied!';
      button.classList.add('copied');
      setTimeout(() => {
        button.textContent = 'Copy';
        button.classList.remove('copied');
      }, 2000);
    }
  </script>
</body>
</html>
