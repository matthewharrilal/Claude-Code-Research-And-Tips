<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta data-pagefind-meta="chapter" content="Journeys">
  <meta data-pagefind-meta="section" content="Mental Models">
  <title>Practice and Heuristics - Claude Code Knowledge Base</title>
  <link rel="stylesheet" href="../../css/style.css">
  <link rel="stylesheet" href="../../css/sidebar.css">
</head>
<body>
  <div class="page-with-sidebar">
    <!-- Sidebar Navigation -->
    <nav class="sidebar">
      <button class="sidebar-close" aria-label="Close sidebar">&times;</button>
      <div class="sidebar-header">
        <h2 class="sidebar-title"><a href="../../index.html">Claude Code KB</a></h2>
      </div>
      <ul class="sidebar-nav">
        <li class="nav-section">
          <div class="nav-section-title">Start Here</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../../start-here/index.html">Overview</a></li>
            <li class="nav-page"><a href="../../start-here/master-playbook.html">Master Playbook</a></li>
            <li class="nav-page"><a href="../../start-here/judgment-guide.html">Judgment Guide</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Foundations</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../../foundations/index.html">Overview</a></li>
            <li class="nav-page"><a href="../../foundations/principles/core.html">Core Principles</a></li>
            <li class="nav-page"><a href="../../foundations/architecture/complexity-ladder.html">Complexity Ladder</a></li>
          </ul>
        </li>
        <li class="nav-section open">
          <div class="nav-section-title">Mental Models Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="core-models.html">Core Models (1-10)</a></li>
            <li class="nav-page"><a href="advanced-models.html">Advanced Models (11-16)</a></li>
            <li class="nav-page current"><a href="practice-heuristics.html">Practice &amp; Heuristics</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Architecture Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../architecture/index.html">Decision Trees</a></li>
            <li class="nav-page"><a href="../architecture/core-patterns.html">Core Patterns</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Implementation Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../implementation/index.html">Getting Started</a></li>
            <li class="nav-page"><a href="../implementation/ralph.html">Ralph Pattern</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Reference</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../foundations/invariants-reference.html">Invariants Reference</a></li>
            <li class="nav-page"><a href="../../reference/cost-analysis.html">Cost Analysis</a></li>
          </ul>
        </li>
      </ul>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
      <div class="breadcrumb">
        <a href="../../index.html">Home</a>
        <span class="breadcrumb-separator">/</span>
        <a href="../index.html">Journeys</a>
        <span class="breadcrumb-separator">/</span>
        <a href="index.html">Mental Models</a>
        <span class="breadcrumb-separator">/</span>
        <span class="breadcrumb-current">Practice &amp; Heuristics</span>
      </div>

      <div class="page-meta">
        <span class="page-meta-item">20 min read</span>
        <span class="page-meta-item">~600 lines</span>
      </div>

      <h1>Practice and Heuristics</h1>

      <!-- You Are Here Context Box -->
      <div class="context-box you-are-here">
        <h3>You Are Here</h3>
        <p>This is the <strong>practical application</strong> of the 16 mental models. Here you will find anti-patterns to avoid, quick decision rules for common situations, and scenario practice to test your understanding. This section transforms theoretical knowledge into daily habits.</p>
        <p><strong>Prerequisites:</strong> You should have read <a href="core-models.html">Core Models (1-10)</a> and at least skimmed <a href="advanced-models.html">Advanced Models (11-16)</a>.</p>
      </div>

      <p class="lead">Anti-patterns to avoid and quick decision rules for common situations. This is the practical application of mental models to daily work.</p>

      <div class="toc">
        <div class="toc-title">On This Page</div>
        <ul>
          <li><a href="#anti-patterns">The 12 Anti-Patterns</a></li>
          <li><a href="#warning-signs">Warning Signs of Wrong-Stage Thinking</a></li>
          <li><a href="#heuristics">Decision Heuristics</a></li>
          <li><a href="#divergences">Practitioner Divergences</a></li>
          <li><a href="#trust-gradient">The Trust Gradient</a></li>
        </ul>
      </div>

      <hr class="section-divider">

      <!-- Anti-Patterns Section -->
      <section id="anti-patterns">
        <h2>The 12 Anti-Patterns</h2>

        <p>These are the common mistakes that signal wrong-stage thinking or fundamental misunderstanding of agent systems.</p>

        <h3>Anti-Pattern 1: The Super-Agent Fallacy</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "I will make one really smart agent that handles everything."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Context fills with accumulated state</li>
            <li>Quality degrades over time</li>
            <li>Single point of failure</li>
            <li>No parallelization possible</li>
          </ul>
          <p><strong>The Correction:</strong> Build colonies, not super-workers (Model 5).</p>
        </div>

        <h3>Anti-Pattern 2: Extended Context Optimism</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "Extended context windows solve everything. Just keep the conversation going."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Quality degrades past 40-70%</li>
            <li>Each token costs capability</li>
            <li>No production system uses this approach</li>
          </ul>
          <p><strong>The Correction:</strong> Fresh context beats extended sessions (Model 3).</p>
        </div>

        <h3>Anti-Pattern 3: Trust Without Verification</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "The agent said it is done, so it must be done."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Agents can hallucinate success</li>
            <li>"It compiles" is not "It works"</li>
            <li>No trust boundary established</li>
          </ul>
          <p><strong>The Correction:</strong> Verification as trust boundary (Model 4).</p>
        </div>

        <h3>Anti-Pattern 4: Framework Enchantment</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "LangChain/CrewAI will solve the hard problems for me."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Frameworks abstract away the levers that matter</li>
            <li>Complexity interacts unpredictably with non-determinism</li>
            <li>Debugging becomes impossible</li>
          </ul>
          <p><strong>The Correction:</strong> Simplicity compensates for non-determinism (Model 10).</p>
        </div>

        <h3>Anti-Pattern 5: Memory in Context</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "The agent will remember what I told it."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Context windows die</li>
            <li>No cross-session memory exists</li>
            <li>Information decays with distance</li>
          </ul>
          <p><strong>The Correction:</strong> External state over internal memory (Model 2).</p>
        </div>

        <h3>Anti-Pattern 6: Big Task Syndrome</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "Implement the entire feature in one request."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Tasks overflow context</li>
            <li>Misunderstandings compound</li>
            <li>No verification checkpoints</li>
          </ul>
          <p><strong>The Correction:</strong> Atomic tasks with clear completion criteria (Model 7).</p>
        </div>

        <h3>Anti-Pattern 7: Cost Myopia</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "Always use the cheapest model to save money."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Cheap models need more iterations</li>
            <li>Total cost = per-token x iterations</li>
            <li>Opus often cheaper in total time</li>
          </ul>
          <p><strong>The Correction:</strong> Model tiering by task type (Model 8, Layer 1).</p>
        </div>

        <h3>Anti-Pattern 8: LLM-Everything</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "Use the LLM for every operation."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Deterministic operations do not need LLMs</li>
            <li>Unnecessary cost for file transformations</li>
            <li>No caching possible</li>
          </ul>
          <p><strong>The Correction:</strong> Three-layer cost optimization (Model 8, Layers 2-3).</p>
        </div>

        <h3>Anti-Pattern 9: One-Shot Learning</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "We solved this once, we will not hit it again."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Agents do not learn across sessions</li>
            <li>Same mistakes repeat forever</li>
            <li>No compound progress</li>
          </ul>
          <p><strong>The Correction:</strong> Learning must compound (Model 9).</p>
        </div>

        <h3>Anti-Pattern 10: Scale Without Coordination</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "I will just run more Ralph loops in parallel. They do not need coordination."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>File conflicts</li>
            <li>Duplicate work</li>
            <li>Merge disasters</li>
          </ul>
          <p><strong>The Correction:</strong> Claims-based coordination (Model 14) at 5+ agents.</p>
        </div>

        <h3>Anti-Pattern 11: Research Pollution</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "I will research, plan, and implement in one session."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>Research context pollutes implementation</li>
            <li>Less context available for actual code</li>
            <li>Quality drops in later phases</li>
          </ul>
          <p><strong>The Correction:</strong> Phase isolation mindset (Model 12).</p>
        </div>

        <h3>Anti-Pattern 12: Vanilla at Scale</h3>
        <div class="gotcha-block">
          <p><strong>The Wrong Thinking:</strong> "Vanilla works, I will just add more agents."</p>
          <p><strong>Why It Fails:</strong></p>
          <ul>
            <li>No observability at 20+ agents</li>
            <li>No cost controls</li>
            <li>No coordination infrastructure</li>
          </ul>
          <p><strong>The Correction:</strong> Enterprise mindset (Model 16) when scale exceeds 10 agents.</p>
        </div>
      </section>

      <hr class="section-divider">

      <!-- Warning Signs Section -->
      <section id="warning-signs">
        <h2>Warning Signs of Wrong-Stage Thinking</h2>

        <h3>Beginner Trying to Scale</h3>
        <ul>
          <li>"I will add more context to help the agent understand"</li>
          <li>"Maybe a longer session will work better"</li>
          <li>"The agent should learn from this conversation"</li>
        </ul>

        <h3>Ralph Practitioner Hitting Orchestration Problems</h3>
        <ul>
          <li>"I will just run more Ralph loops in parallel"</li>
          <li>"Each loop is independent, they do not need coordination"</li>
          <li>"File conflicts? I will just retry"</li>
        </ul>

        <h3>Team Practitioner Hitting Enterprise Problems</h3>
        <ul>
          <li>"Hub-and-spoke is enough, I will just add more workers"</li>
          <li>"Observability is overhead we do not need"</li>
          <li>"Budget control can wait until later"</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Heuristics Section -->
      <section id="heuristics">
        <h2>Decision Heuristics</h2>

        <p>Quick rules for common decisions.</p>

        <h3>When to Reset Context</h3>
        <p><strong>Rule:</strong> Reset at 70% context usage OR when quality degrades OR at phase boundaries.</p>
        <p><strong>Triggers:</strong></p>
        <ul>
          <li>Context fill > 70% (check with /cost or context indicator)</li>
          <li>Agent ignores directives it previously followed</li>
          <li>Output quality noticeably declining</li>
          <li>Agent starts hallucinating or making up information</li>
          <li>Same error repeated despite correction</li>
          <li>Phase boundary reached (Research -> Planning -> Implementation)</li>
        </ul>
        <p><strong>Procedure:</strong></p>
        <ol>
          <li>Save critical state to external files (CLAUDE.md, progress.txt)</li>
          <li>Run <code>/clear</code> or start new session</li>
          <li>Inject essential context from external state</li>
          <li>Continue work with fresh context</li>
        </ol>

        <h3>When to Spawn Subagent vs Use Tool</h3>
        <p><strong>Spawn Subagent When:</strong></p>
        <ul>
          <li>Task requires multi-step reasoning in isolation</li>
          <li>Work would pollute orchestrator's context</li>
          <li>Task is parallelizable with independent subtasks</li>
          <li>Context isolation prevents cross-contamination</li>
        </ul>
        <p><strong>Use Tool When:</strong></p>
        <ul>
          <li>Simple lookup or file operation</li>
          <li>Result needed immediately in current context</li>
          <li>Single-step operation with clear output</li>
          <li>No reasoning required, just execution</li>
        </ul>
        <p><strong>The Test:</strong> Does this task need to "think," or does it just need to "do"?</p>
        <ul>
          <li>Thinking -> Subagent</li>
          <li>Doing -> Tool</li>
        </ul>

        <h3>When to Stop a Run (Stuck Detection)</h3>
        <p><strong>Stop When:</strong></p>
        <ul>
          <li>Same file edited 5+ times without progress</li>
          <li>Circular patterns detected (undo/redo cycles)</li>
          <li>Context usage > 90%</li>
          <li>3 iterations with no commits</li>
          <li>Agent explicitly states it is stuck or confused</li>
          <li>Cost exceeds per-task budget</li>
        </ul>

        <h3>Task Sizing Quick Test</h3>
        <p><strong>The 2-3 Sentence Rule:</strong></p>
        <p>Can you describe the task in 2-3 sentences with:</p>
        <ol>
          <li>Clear action (what to do)</li>
          <li>Clear scope (which files/components)</li>
          <li>Clear verification (how to know it is done)</li>
        </ol>
        <p><strong>If yes:</strong> Task is appropriately sized</p>
        <p><strong>If no:</strong> Decompose into smaller tasks</p>

        <div class="ascii-diagram">
TOO BIG: "Implement user authentication"

RIGHT SIZE:
- "Add User model to database/models/user.ts with email, passwordHash fields"
- "Create POST /api/auth/login that returns JWT for valid credentials"
- "Add authMiddleware that validates JWT and rejects invalid tokens"
        </div>

        <h3>Model Selection Quick Guide</h3>
        <table>
          <thead>
            <tr>
              <th>What You Are Doing</th>
              <th>Model</th>
              <th>Why</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Fetching file contents</td><td>Haiku</td><td>Zero reasoning</td></tr>
            <tr><td>Running searches</td><td>Haiku</td><td>Execution only</td></tr>
            <tr><td>Standard implementation</td><td>Sonnet</td><td>Pattern following</td></tr>
            <tr><td>Refactoring code</td><td>Sonnet</td><td>Some judgment</td></tr>
            <tr><td>Debugging complex issue</td><td>Opus</td><td>Multi-step reasoning</td></tr>
            <tr><td>Architecture decision</td><td>Opus</td><td>Deep analysis</td></tr>
            <tr><td>Novel algorithm</td><td>Opus</td><td>Creative reasoning</td></tr>
            <tr><td>Code review</td><td>Opus</td><td>Judgment-heavy</td></tr>
          </tbody>
        </table>

        <h3>Cost Optimization Decision Tree</h3>
        <div class="ascii-diagram">
Is operation deterministic (file transform, template expansion)?
  YES -> LLM Bypass (Layer 2)
  NO  |
      v
Is this similar to a recent query?
  YES -> Check Semantic Cache (Layer 3)
  NO  |
      v
Select Model (Layer 1):
  Just lookup/fetch? -> Haiku
  Standard implementation? -> Sonnet
  Deep reasoning needed? -> Opus
        </div>

        <h3>Coordination Pattern Selection</h3>
        <div class="ascii-diagram">
How many agents?

1-2 agents -> Solo
  - Single Claude session, basic subagents
  - No coordination needed

3-10 agents -> Hub-and-Spoke
  - Central orchestrator with specialized workers
  - Claims-based coordination optional

10-50 agents -> Platform Orchestration
  - MCP-based enterprise coordination
  - Claims-based coordination required
  - Observability required

50-100+ agents -> Bootstrap Factory or Gas Town
  - Auto-configured agent management
  - Full enterprise infrastructure required
        </div>

        <h3>Exit Detection Strategy Selection</h3>
        <table>
          <thead>
            <tr>
              <th>Situation</th>
              <th>Strategy</th>
              <th>Implementation</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Learning/simple tasks</td><td>Simple grep</td><td><code>grep -q "&lt;promise&gt;COMPLETE&lt;/promise&gt;"</code></td></tr>
            <tr><td>Production/long-running</td><td>Dual-condition gate</td><td>Heuristic count + explicit confirmation</td></tr>
            <tr><td>Security-critical</td><td>Validator consensus</td><td>All validators must approve</td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- Divergences Section -->
      <section id="divergences">
        <h2>Practitioner Divergences</h2>

        <p>Where practitioners legitimately differ - both positions are valid for different contexts.</p>

        <h3>Divergence 1: Cost Model</h3>
        <table>
          <thead>
            <tr>
              <th>Camp</th>
              <th>Philosophy</th>
              <th>When Valid</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Opus-First (Boris Cherny)</strong></td>
              <td>Higher generation cost, lower correction cost. Get it right the first time.</td>
              <td>Small team, quality-sensitive</td>
            </tr>
            <tr>
              <td><strong>Haiku-Swarm (Steve Yegge)</strong></td>
              <td>Cheap agents in parallel. Iterate quickly, discard failures. $300/day budget.</td>
              <td>Scaling throughput, cost-tolerant</td>
            </tr>
          </tbody>
        </table>

        <h3>Divergence 2: Autonomy Level</h3>
        <table>
          <thead>
            <tr>
              <th>Camp</th>
              <th>Philosophy</th>
              <th>When Valid</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Human Checkpoint (Boris, Dogan)</strong></td>
              <td>Plan Mode required. Human approves plans before execution. Conservative, deliberate.</td>
              <td>High-stakes, regulated, public-facing</td>
            </tr>
            <tr>
              <td><strong>Autonomous Until Complete (Yegge, Ralph)</strong></td>
              <td>Auto-accept everything. Human reviews results, not process. Aggressive, throughput-oriented.</td>
              <td>Internal, recoverable, iteration-friendly</td>
            </tr>
          </tbody>
        </table>

        <h3>Divergence 3: Infrastructure Complexity</h3>
        <table>
          <thead>
            <tr>
              <th>Camp</th>
              <th>Philosophy</th>
              <th>When Valid</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Vanilla (Boris Cherny)</strong></td>
              <td>CLAUDE.md, Plan Mode, basic hooks. Minimal dependencies. Works today.</td>
              <td>Solo/small team</td>
            </tr>
            <tr>
              <td><strong>Heavy Infrastructure (Steve Yegge)</strong></td>
              <td>Gas Town factory: Mayor, Deacon, Dogs, Refinery. Significant setup, significant capability.</td>
              <td>Team/enterprise with known scale needs</td>
            </tr>
          </tbody>
        </table>

        <div class="callout-insight">
          <div class="callout-title">Both Are Valid</div>
          <p>These are not "right vs wrong" - they are "optimized for different constraints." Boris optimizes for correctness-per-attempt. Yegge optimizes for throughput-at-scale. Both succeed in their contexts.</p>
        </div>
      </section>

      <hr class="section-divider">

      <!-- Trust Gradient Section -->
      <section id="trust-gradient">
        <h2>The Trust Gradient</h2>

        <p>All practitioners share a graduated trust model for agent autonomy.</p>

        <div class="ascii-diagram">
MANUAL VERIFICATION (Trust Level 1)
|
|   Human reviews every change before acceptance
|   Appropriate for: New setups, unfamiliar domains
|
+--> SUPERVISED EXECUTION (Trust Level 2)
|
|   Human monitors but does not block
|   Auto-accept with notification
|   Appropriate for: Established patterns
|
+--> ASYNC NOTIFICATION (Trust Level 3)
|
|   Human notified of completion only
|   No real-time monitoring
|   Appropriate for: Known reliable workflows
|
+--> OVERNIGHT AUTONOMOUS (Trust Level 4)

    Human reviews in morning
    Agents work unattended
    Appropriate for: Battle-tested systems
        </div>

        <p><strong>The Rule:</strong> Trust is earned through consistent verification. You move up the gradient by demonstrating reliability. You move down when things break.</p>

        <h3>Trust Level Decision Factors</h3>
        <table>
          <thead>
            <tr>
              <th>Factor</th>
              <th>Low Trust</th>
              <th>High Trust</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Domain familiarity</td><td>New/unfamiliar</td><td>Well understood</td></tr>
            <tr><td>Test coverage</td><td>Low/none</td><td>High, comprehensive</td></tr>
            <tr><td>Reversibility</td><td>Hard to undo</td><td>Easy rollback</td></tr>
            <tr><td>Impact scope</td><td>Production, public</td><td>Internal, recoverable</td></tr>
            <tr><td>Track record</td><td>New workflow</td><td>Proven reliable</td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- The 9 Invariants Section -->
      <section id="invariants">
        <h2>The 9 Invariants</h2>
        <p>These patterns appeared in EVERY practitioner studied, regardless of use case, scale, or personal style. 100% agreement across 47 repositories and 20+ practitioners.</p>

        <ol>
          <li><strong>Context Is The Constraint:</strong> Every practitioner designs around context limits. No one tries to fight them. All architecture decisions flow from accepting this constraint.</li>
          <li><strong>Fresh Beats Extended:</strong> No practitioner uses long sessions as their primary mode. All prefer multiple short iterations with fresh context.</li>
          <li><strong>External Memory Required:</strong> Files, databases, git - the specific mechanism varies, but the pattern is universal. All persistent state lives outside the agent.</li>
          <li><strong>Verification Non-Negotiable:</strong> No practitioner trusts "it compiles" as "it works." All have verification gates.</li>
          <li><strong>Parallelization Essential:</strong> All practitioners who work at scale run multiple agents. No one achieves high throughput with a single agent.</li>
          <li><strong>Git As Recovery:</strong> All practitioners use git commits as checkpoints for recovery. Not as version control for humans, but as state recovery for agents.</li>
          <li><strong>Simplicity Bias:</strong> Every practitioner warns against over-engineering. Every war story involves complexity failing.</li>
          <li><strong>Human Judgment Irreplaceable:</strong> Machines are excellent at HOW. Humans are essential for WHY and WHETHER.</li>
          <li><strong>Learnings Must Persist:</strong> Institutional memory only grows through deliberate compounding. CLAUDE.md updates, progress.txt archives, learning repositories.</li>
        </ol>
      </section>

      <hr class="section-divider">

      <!-- Philosophy Repos Validation Section -->
      <section id="philosophy-validation">
        <h2>How Philosophy Repos Validate These Invariants</h2>
        <p>The major philosophy repos don't just follow these invariants - they codify them as explicit principles.</p>

        <h3>HumanLayer's 12-Factor Agents: Invariants as Factors</h3>
        <table>
          <thead>
            <tr>
              <th>Invariant</th>
              <th>12-Factor Equivalent</th>
              <th>Factor Number</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Context Is Constraint</td><td>"Own your context window"</td><td>Factor 3</td></tr>
            <tr><td>Fresh Beats Extended</td><td>"Stateless reducer" pattern</td><td>Factor 12</td></tr>
            <tr><td>External Memory Required</td><td>"Unify execution & business state"</td><td>Factor 5</td></tr>
            <tr><td>Verification Non-Negotiable</td><td>"Tools are structured outputs"</td><td>Factor 4</td></tr>
            <tr><td>Parallelization Essential</td><td>"Small, focused agents"</td><td>Factor 10</td></tr>
            <tr><td>Human Judgment Irreplaceable</td><td>"Contact humans with tools"</td><td>Factor 7</td></tr>
          </tbody>
        </table>

        <h3>BMAD-METHOD: Invariants as Compliance Requirements</h3>
        <p><strong>Checklist-Driven Invariant Enforcement:</strong></p>
        <ul>
          <li>Is state externalized? (Invariant 3)</li>
          <li>Is the task atomic? (Invariant 1)</li>
          <li>Is verification programmatic? (Invariant 4)</li>
          <li>Is complexity justified? (Invariant 7)</li>
        </ul>

        <h3>Aider: Invariants Through Separation</h3>
        <p><strong>Architect vs Editor = Role-Based Invariant Enforcement:</strong></p>
        <ul>
          <li>Architect handles WHY and WHETHER (Invariant 8)</li>
          <li>Editor handles HOW (implementation)</li>
          <li>Neither can violate the other's domain</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Scenario Practice Section -->
      <section id="scenario-practice">
        <h2>What Would You Do? Scenario Practice</h2>
        <p>Test your understanding of the invariants with these scenarios.</p>

        <h3>Scenario 1: The Long Session</h3>
        <p>You've been working with Claude for 2 hours on a complex feature. The session is going well, but you're getting close to finishing. Claude's responses are still accurate.</p>
        <p><strong>Options:</strong></p>
        <ul>
          <li>A) Continue until done - it's working</li>
          <li>B) Save state, restart, finish with fresh context</li>
          <li>C) Ask Claude if it needs a break</li>
        </ul>

        <details class="troubleshoot">
          <summary>Click to reveal answer</summary>
          <div class="troubleshoot-content">
            <p><strong>Best choice: B</strong></p>
            <p><strong>Invariants that apply:</strong></p>
            <ul>
              <li><strong>Invariant 2: Fresh Beats Extended</strong> - Even if it seems fine, quality degrades invisibly</li>
              <li><strong>Invariant 3: External Memory Required</strong> - Save state before reset</li>
              <li><strong>Invariant 6: Git As Recovery</strong> - Commit before resetting</li>
            </ul>
          </div>
        </details>

        <h3>Scenario 2: The Super-Agent Request</h3>
        <p>Your manager wants you to build "one agent that can handle all our code review, security scanning, and documentation updates."</p>
        <p><strong>Options:</strong></p>
        <ul>
          <li>A) Build it - consolidation is efficient</li>
          <li>B) Build three specialized agents</li>
          <li>C) Explain why this is impossible</li>
        </ul>

        <details class="troubleshoot">
          <summary>Click to reveal answer</summary>
          <div class="troubleshoot-content">
            <p><strong>Best choice: B</strong></p>
            <p><strong>Invariants that apply:</strong></p>
            <ul>
              <li><strong>Invariant 1: Context Is The Constraint</strong> - One agent can't hold all three domains' context</li>
              <li><strong>Invariant 5: Parallelization Essential</strong> - Three agents can work in parallel</li>
              <li><strong>Invariant 7: Simplicity Bias</strong> - Three simple agents beat one complex agent</li>
            </ul>
          </div>
        </details>

        <h3>Scenario 3: The Framework Pitch</h3>
        <p>A colleague recommends LangChain for your new multi-agent system. "It handles orchestration, memory, and tool use out of the box."</p>
        <p><strong>Options:</strong></p>
        <ul>
          <li>A) Use LangChain - leverage existing tools</li>
          <li>B) Build custom - roll your own</li>
          <li>C) Evaluate based on your specific needs</li>
        </ul>

        <details class="troubleshoot">
          <summary>Click to reveal answer</summary>
          <div class="troubleshoot-content">
            <p><strong>Best choice: C (leaning toward B)</strong></p>
            <p><strong>Invariants that apply:</strong></p>
            <ul>
              <li><strong>Invariant 7: Simplicity Bias</strong> - Frameworks add complexity</li>
              <li><strong>Invariant 1: Context Is The Constraint</strong> - Frameworks abstract away context control</li>
            </ul>
            <blockquote>
              "Frameworks abstract away the levers that matter: context window and control flow."
              <cite>-- Dexter Horthy</cite>
            </blockquote>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Preventing Anti-Patterns Section -->
      <section id="preventing-anti-patterns">
        <h2>How Philosophy Repos Prevent Anti-Patterns</h2>
        <p>The major philosophy repos have built-in protections against the 12 anti-patterns.</p>

        <h3>HumanLayer's 12-Factor Agents: Anti-Patterns as Violations</h3>
        <table>
          <thead>
            <tr>
              <th>Anti-Pattern</th>
              <th>12-Factor Violation</th>
              <th>Prevention</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Super-Agent Fallacy</td><td>Violates Factor 10 (Small, Focused Agents)</td><td>One agent per responsibility</td></tr>
            <tr><td>Extended Context Optimism</td><td>Violates Factor 3 (Own Your Context)</td><td>Explicit context budgets</td></tr>
            <tr><td>Trust Without Verification</td><td>Violates Factor 4 (Structured Outputs)</td><td>Verifiable tool call outputs</td></tr>
            <tr><td>Framework Enchantment</td><td>Violates Factor 8 (Own Your Control Flow)</td><td>"Roll your own stack"</td></tr>
            <tr><td>Memory in Context</td><td>Violates Factor 5 (Unify Execution & Business State)</td><td>External state mandatory</td></tr>
            <tr><td>Big Task Syndrome</td><td>Violates Factor 12 (Stateless Reducer)</td><td>Atomic operations only</td></tr>
          </tbody>
        </table>

        <h3>BMAD-METHOD: Anti-Patterns as Compliance Failures</h3>
        <p>BMAD's checklist-driven approach catches anti-patterns before they cause damage:</p>
        <ul>
          <li>Is this task atomic? (Prevents Big Task Syndrome)</li>
          <li>Is state externalized? (Prevents Memory in Context)</li>
          <li>Is there a verification gate? (Prevents Trust Without Verification)</li>
          <li>Is this the right agent? (Prevents Super-Agent Fallacy)</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- When to Stop Section -->
      <section id="stuck-protocol">
        <h2>When to Stop - Stuck Protocol</h2>
        <p>Detect when agents are stuck and escalate appropriately:</p>

        <div class="code-block">
          <button class="copy-btn" onclick="copyCode(this)">Copy</button>
          <pre><code class="language-bash"># Detect: 3 iterations, no new commits
COMMITS_BEFORE=$(git rev-list --count HEAD)
# ... run iteration ...
COMMITS_AFTER=$(git rev-list --count HEAD)

if [ "$COMMITS_BEFORE" -eq "$COMMITS_AFTER" ]; then
    STUCK_COUNT=$((STUCK_COUNT + 1))
fi

if [ "$STUCK_COUNT" -ge 3 ]; then
    echo "STUCK: Escalating to human"
    exit 1
fi</code></pre>
        </div>
      </section>

      <hr class="section-divider">

      <!-- Coordination Pattern Section -->
      <section id="scale-repository">
        <h2>Coordination Pattern - Scale Repository Decision Guide</h2>

        <table>
          <thead>
            <tr>
              <th>Scale</th>
              <th>Repository</th>
              <th>Key Pattern to Apply</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>3-10</td><td>swarms</td><td>Choose topology: sequential, concurrent, or graph</td></tr>
            <tr><td>10-50</td><td>claude-flow</td><td>Queen/Worker + claims + SONA</td></tr>
            <tr><td>50+</td><td>wshobson/agents</td><td>Capability taxonomy + skill repository</td></tr>
            <tr><td>All</td><td>anthropic-cookbook</td><td>Verify against canonical patterns</td></tr>
          </tbody>
        </table>

        <div class="ascii-diagram">
The swarms Topology Selection:
  Independent tasks? -> Concurrent topology (parallel execution)
  Dependent chain?   -> Sequential topology (step-by-step)
  Complex deps?      -> Graph topology (DAG-based)
  Hierarchical?      -> claude-flow Queen/Worker
        </div>
      </section>

      <hr class="section-divider">

      <!-- The Meta-Model Section -->
      <section id="meta-model">
        <h2>The Meta-Model</h2>
        <blockquote>
          <strong>AI agents are capable but unreliable, fast but stateless.</strong>
        </blockquote>

        <p>Every model in this document compensates for one of these limitations:</p>
        <table>
          <thead>
            <tr>
              <th>Limitation</th>
              <th>Compensation Pattern</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Context degrades</td><td>Model 1: Context-First Paradigm</td></tr>
            <tr><td>Stateless</td><td>Model 2: External State Over Internal Memory</td></tr>
            <tr><td>Quality fades over time</td><td>Model 3: Fresh Context Beats Extended</td></tr>
            <tr><td>Unreliable</td><td>Model 4: Verification as Trust Boundary</td></tr>
            <tr><td>Single agent limits</td><td>Model 5: Parallelization Over Single-Agent</td></tr>
            <tr><td>Can't specify for itself</td><td>Model 6: Human as Orchestrator</td></tr>
            <tr><td>Misunderstands big tasks</td><td>Model 7: Atomic Tasks</td></tr>
            <tr><td>Variable capability by task</td><td>Model 8: Model Tiering & Cost Optimization</td></tr>
            <tr><td>No cross-session learning</td><td>Model 9: Learning Must Compound</td></tr>
            <tr><td>Complex systems fail</td><td>Model 10: Simplicity Compensates</td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- Thinking Transformation Section -->
      <section id="thinking-transformation">
        <h2>The Thinking Transformation</h2>
        <div class="ascii-diagram">
<strong>Before these mental models:</strong>
- "How do I prompt the agent better?"
- "How do I make the agent smarter?"
- "Why doesn't the agent understand?"

<strong>After these mental models:</strong>
- "How do I design around agent limitations?"
- "How do I build systems that compensate?"
- "How do I structure work for agent success?"
        </div>
        <p>The shift is from "fixing the agent" to "designing the system."</p>
      </section>

      <hr class="section-divider">

      <!-- Implementation Sequence Section -->
      <section id="implementation-sequence">
        <h2>The Implementation Sequence</h2>
        <p>When applying these models to a new project:</p>
        <ol>
          <li><strong>Start with Context-First Paradigm</strong> - Design all work to fit context limits</li>
          <li><strong>Establish External State</strong> - Create CLAUDE.md and state files before agents touch code</li>
          <li><strong>Define Verification</strong> - Know how "done" is measured before work begins</li>
          <li><strong>Size Tasks Atomically</strong> - Decompose until each task passes the 2-3 sentence test</li>
          <li><strong>Choose Models</strong> - Match model tier to task complexity</li>
          <li><strong>Design for Fresh Context</strong> - Plan for sessions to restart, not extend</li>
          <li><strong>Enable Compounding</strong> - Set up mechanisms for learnings to persist</li>
          <li><strong>Keep It Simple</strong> - Use the simplest architecture that works</li>
          <li><strong>Scale Horizontally</strong> - When capacity is needed, add agents, don't optimize one</li>
          <li><strong>Orchestrate, Don't Implement</strong> - Your job is specification and verification</li>
        </ol>

        <h3>Scale Implementation Progression</h3>
        <table>
          <thead>
            <tr>
              <th>Scale</th>
              <th>Add This</th>
              <th>Reference</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>10+</td><td>Coordination topology</td><td>swarms (sequential/concurrent/graph)</td></tr>
            <tr><td>20+</td><td>Hierarchical orchestration</td><td>claude-flow (Queen/Worker)</td></tr>
            <tr><td>30+</td><td>Shared learning</td><td>claude-flow (ReasoningBank, SONA)</td></tr>
            <tr><td>50+</td><td>Capability taxonomy</td><td>wshobson/agents (14 categories)</td></tr>
            <tr><td>75+</td><td>Skills repository</td><td>wshobson/agents (110 skills)</td></tr>
            <tr><td>All</td><td>Canonical baseline</td><td>anthropic-cookbook patterns</td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- Final Checkpoint Section -->
      <section id="final-checkpoint" class="checkpoint">
        <h2>You're Ready If</h2>
        <ul>
          <li>You can explain all 16 mental models in one sentence each</li>
          <li>You naturally think "design around limitations" not "fix the agent"</li>
          <li>You can identify which stage of evolution you're at</li>
          <li>You recognize anti-patterns when you see them (or catch yourself doing them)</li>
          <li>You can apply the decision heuristics without looking them up</li>
          <li>You understand that simplicity is strength, not weakness</li>
          <li>You've identified at least 3 changes to make in your workflow</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Where to Go Next Section -->
      <section id="where-next">
        <h2>Where to Go Next</h2>
        <table>
          <thead>
            <tr>
              <th>Your Situation</th>
              <th>Next Journey</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Ready to choose specific patterns</td><td><a href="../architecture/index.html">Choosing Your Architecture</a></td></tr>
            <tr><td>Ready to implement production systems</td><td><a href="../implementation/index.html">Building Production Systems</a></td></tr>
            <tr><td>Ready to run and monitor in production</td><td><a href="../implementation/ralph.html">Running Production Claude</a></td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- Want to Go Deeper Section -->
      <section id="go-deeper">
        <h2>Want to Go Deeper?</h2>
        <table>
          <thead>
            <tr>
              <th>Topic</th>
              <th>Depth Layer</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Boris Cherny's full workflow</td><td>Practitioner profile</td></tr>
            <tr><td>Ralph ecosystem variants</td><td>Implementation depth</td></tr>
            <tr><td>CC Mirror deep implementation</td><td>Practitioner-specific</td></tr>
            <tr><td>Advanced context techniques</td><td>Technical depth</td></tr>
            <tr><td>Cost economics analysis</td><td>Economic analysis</td></tr>
            <tr><td>Pattern combinations</td><td>Advanced patterns</td></tr>
          </tbody>
        </table>

        <h3>Scale Repository Deep Dives</h3>
        <table>
          <thead>
            <tr>
              <th>Repository</th>
              <th>What to Study</th>
              <th>Mental Models Covered</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>anthropic-cookbook</td><td>Canonical Claude patterns</td><td>Simplicity (10), Model Tiering (8)</td></tr>
            <tr><td>swarms</td><td>Coordination topologies</td><td>Parallelization (5), Atomic Tasks (7)</td></tr>
            <tr><td>claude-flow</td><td>Queen/Worker, ReasoningBank</td><td>Claims (14), Swarm (15), Enterprise (16)</td></tr>
            <tr><td>wshobson/agents</td><td>110 skills, capability taxonomy</td><td>Orchestration (6), Compounding (9)</td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- Known Gaps Section -->
      <section id="known-gaps">
        <h2>Known Gaps</h2>
        <p>This journey has acknowledged gaps based on gap analysis:</p>
        <table>
          <thead>
            <tr>
              <th>Gap</th>
              <th>Status</th>
              <th>Notes</th>
            </tr>
          </thead>
          <tbody>
            <tr><td><strong>MCP Ecosystem</strong></td><td>CRITICAL</td><td>Model Context Protocol not covered - foundational infrastructure</td></tr>
            <tr><td><strong>Mobile Workflows</strong></td><td>CRITICAL</td><td>Mobile-first patterns absent</td></tr>
            <tr><td><strong>Personal Panopticon</strong></td><td>HIGH</td><td>Molly Cantillon's 8-domain life architecture only briefly mentioned</td></tr>
            <tr><td><strong>Eric Buess "Unhobbled" Stack</strong></td><td>HIGH</td><td>LSP+Hooks+Adversarial Validation stack (10x multiplier) not fully covered</td></tr>
          </tbody>
        </table>
      </section>

      <hr class="section-divider">

      <!-- Quick Reference Card Section -->
      <section id="quick-reference">
        <h2>Quick Reference Card</h2>

        <h3>The 16 Models (One Line Each)</h3>
        <h4>Core Models (1-10):</h4>
        <ol>
          <li><strong>Context-First:</strong> Design around limits, not through them</li>
          <li><strong>External State:</strong> If it's not in a file, it doesn't exist</li>
          <li><strong>Fresh Context:</strong> 20 short sessions beat 1 long session</li>
          <li><strong>Verification:</strong> Programmatic verification defines "done"</li>
          <li><strong>Parallelization:</strong> Build colonies, not super-workers</li>
          <li><strong>Human Orchestration:</strong> You specify and verify; agents implement</li>
          <li><strong>Atomic Tasks:</strong> 2-3 sentences, clear verification</li>
          <li><strong>Model Tiering:</strong> Bypass first, cache second, tier third</li>
          <li><strong>Compounding:</strong> Every mistake becomes permanent context</li>
          <li><strong>Simplicity:</strong> Simple systems survive; complex systems fail</li>
        </ol>

        <h4>Advanced Models (11-16):</h4>
        <ol start="11">
          <li><strong>Ralph Mindset:</strong> Files carry state, not context</li>
          <li><strong>Phase Isolation:</strong> Research -> compact -> Plan -> compact -> Implement</li>
          <li><strong>Validator Consensus:</strong> Implementation is a proposal; validators decide</li>
          <li><strong>Claims Coordination:</strong> Advisory reservations enable async collaboration</li>
          <li><strong>Swarm Intelligence:</strong> Fresh context for agents, accumulated memory for swarms</li>
          <li><strong>Enterprise Infrastructure:</strong> Scale requires observability, coordination, and cost control</li>
        </ol>

        <h3>Key Numbers</h3>
        <table>
          <thead>
            <tr>
              <th>Metric</th>
              <th>Value</th>
              <th>Meaning</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Context fill warning</td><td>40%</td><td>Dogan's conservative threshold</td></tr>
            <tr><td>Context fill danger</td><td>70%</td><td>Reset recommended</td></tr>
            <tr><td>Context fill critical</td><td>85%+</td><td>Hallucination probable</td></tr>
            <tr><td>Task size (LOC)</td><td>100-500</td><td>Atomic task range</td></tr>
            <tr><td>Task size (files)</td><td>1-3</td><td>Scope limit</td></tr>
            <tr><td>Stuck iterations</td><td>3</td><td>Escalate after this</td></tr>
            <tr><td>Model cost ratio</td><td>1:12:60</td><td>Haiku:Sonnet:Opus</td></tr>
          </tbody>
        </table>

        <h3>Decision Trees</h3>
        <div class="ascii-diagram">
<strong>Fresh Context or Continue?</strong>
Context > 70%? -> Fresh
Quality degraded? -> Fresh
Phase boundary? -> Fresh + Compact
< 30 min since completion? -> Continue
Otherwise -> Fresh

<strong>Subagent or Tool?</strong>
Needs reasoning? -> Subagent
Would pollute context? -> Subagent
Just execution? -> Tool

<strong>What Model?</strong>
Deterministic op? -> LLM Bypass
Similar recent query? -> Semantic Cache
Just lookup/fetch? -> Haiku
Standard implementation? -> Sonnet
Deep reasoning needed? -> Opus
        </div>
      </section>

      <hr class="section-divider">

      <!-- The Final Test Section -->
      <section id="final-test" class="milestone">
        <h2>The Final Test</h2>
        <p>You've internalized these mental models when you naturally:</p>
        <ul>
          <li>Design work around context limits without thinking about it</li>
          <li>Externalize state automatically, never trusting context alone</li>
          <li>Prefer fresh sessions to extended conversations</li>
          <li>Build verification into every workflow</li>
          <li>Think in terms of agent colonies, not super-agents</li>
          <li>Specify and verify rather than implement</li>
          <li>Size tasks atomically without being told</li>
          <li>Choose models based on task, not habit or budget</li>
          <li>Document learnings as they occur</li>
          <li>Default to simplicity, add complexity only when forced</li>
        </ul>
        <p><strong>These aren't rules to follow. They're patterns of thought. When they become automatic, you've made the transformation from agent user to agent practitioner.</strong></p>
      </section>

      <hr class="section-divider">

      <!-- Navigation -->
      <div class="footer-nav">
        <a href="advanced-models.html" class="nav-prev">
          <span class="nav-direction">Previous</span>
          <span class="nav-title">Advanced Models (11-16)</span>
        </a>
        <a href="../foundations/invariants-reference.html" class="nav-next">
          <span class="nav-direction">Next</span>
          <span class="nav-title">Invariants Reference</span>
        </a>
      </div>

      <div class="related-pages">
        <h3>Related Content</h3>
        <ul>
          <li><a href="core-models.html">Core Mental Models (1-10)</a> - The fundamentals behind these heuristics</li>
          <li><a href="advanced-models.html">Advanced Mental Models (11-16)</a> - Scale-specific thinking</li>
          <li><a href="../foundations/invariants-reference.html">Invariants Reference</a> - The 9 universal truths</li>
          <li><a href="advanced-models.html#anti-patterns">Anti-Patterns Deep Dive</a> - Extended examples and recovery</li>
        </ul>
      </div>
    </main>
  </div>

  <!-- Mobile sidebar toggle -->
  <button class="sidebar-toggle" aria-label="Open navigation">Menu</button>
  <div class="sidebar-overlay"></div>

  <script src="../../js/sidebar.js"></script>
</body>
</html>
