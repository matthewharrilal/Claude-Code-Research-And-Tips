<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta data-pagefind-meta="chapter" content="Journeys">
  <meta data-pagefind-meta="section" content="Mental Models">
  <title>Advanced Mental Models (11-16) - Claude Code Knowledge Base</title>
  <link rel="stylesheet" href="../../css/style.css">
  <link rel="stylesheet" href="../../css/sidebar.css">
</head>
<body>
  <div class="page-with-sidebar">
    <!-- Sidebar Navigation -->
    <nav class="sidebar">
      <button class="sidebar-close" aria-label="Close sidebar">&times;</button>
      <div class="sidebar-header">
        <h2 class="sidebar-title"><a href="../../index.html">Claude Code KB</a></h2>
      </div>
      <ul class="sidebar-nav">
        <li class="nav-section">
          <div class="nav-section-title">Start Here</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../../start-here/index.html">Overview</a></li>
            <li class="nav-page"><a href="../../start-here/master-playbook.html">Master Playbook</a></li>
            <li class="nav-page"><a href="../../start-here/judgment-guide.html">Judgment Guide</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Foundations</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../../foundations/index.html">Overview</a></li>
            <li class="nav-page"><a href="../../foundations/principles/core.html">Core Principles</a></li>
            <li class="nav-page"><a href="../../foundations/architecture/complexity-ladder.html">Complexity Ladder</a></li>
          </ul>
        </li>
        <li class="nav-section open">
          <div class="nav-section-title">Mental Models Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="core-models.html">Core Models (1-10)</a></li>
            <li class="nav-page current"><a href="advanced-models.html">Advanced Models (11-16)</a></li>
            <li class="nav-page"><a href="practice-heuristics.html">Practice &amp; Heuristics</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Architecture Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../architecture/index.html">Decision Trees</a></li>
            <li class="nav-page"><a href="../architecture/core-patterns.html">Core Patterns</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Implementation Journey</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../implementation/index.html">Getting Started</a></li>
            <li class="nav-page"><a href="../implementation/ralph.html">Ralph Pattern</a></li>
          </ul>
        </li>
        <li class="nav-section">
          <div class="nav-section-title">Reference</div>
          <ul class="nav-subsections">
            <li class="nav-page"><a href="../foundations/invariants-reference.html">Invariants Reference</a></li>
            <li class="nav-page"><a href="../../reference/cost-analysis.html">Cost Analysis</a></li>
          </ul>
        </li>
      </ul>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
      <div class="breadcrumb">
        <a href="../../index.html">Home</a>
        <span class="breadcrumb-separator">/</span>
        <a href="../index.html">Journeys</a>
        <span class="breadcrumb-separator">/</span>
        <a href="index.html">Mental Models</a>
        <span class="breadcrumb-separator">/</span>
        <span class="breadcrumb-current">Advanced Models (11-16)</span>
      </div>

      <div class="page-meta">
        <span class="page-meta-item">52 min read</span>
        <span class="page-meta-item">~1,570 lines</span>
      </div>

      <h1>Advanced Mental Models (11-16)</h1>

      <!-- You Are Here Context Box -->
      <div class="context-box you-are-here">
        <h3>You Are Here</h3>
        <p>This is the <strong>advanced mental models section</strong> for practitioners who have mastered Models 1-10 and are now scaling to multi-agent orchestration. These 6 models emerge when operating at scale - with 5+ agents, overnight autonomous runs, or enterprise coordination needs.</p>
        <p><strong>Prerequisites:</strong> You should be able to explain Models 1-10 in one sentence each before proceeding. If you cannot, return to <a href="core-models.html">Core Models (1-10)</a> first.</p>
      </div>

      <p class="lead">These models emerge when operating at scale. They build on the 10 core models and address challenges that appear as systems grow more sophisticated.</p>

      <p>If you have not internalized Models 1-10, these advanced models will not help you. Master the fundamentals first, then return here when you hit scale challenges.</p>

      <div class="toc">
        <div class="toc-title">On This Page</div>
        <ul>
          <li><a href="#model-11">Model 11: The Ralph Mindset</a></li>
          <li><a href="#model-12">Model 12: Phase Isolation Mindset</a></li>
          <li><a href="#model-13">Model 13: Validator Consensus Mindset</a></li>
          <li><a href="#model-14">Model 14: Claims-Based Coordination Mindset</a></li>
          <li><a href="#model-15">Model 15: The Swarm Mindset</a></li>
          <li><a href="#model-16">Model 16: The Enterprise Mindset</a></li>
          <li><a href="#evolution">The Practitioner Evolution</a></li>
          <li><a href="#maturity">The Maturity Ladder</a></li>
        </ul>
      </div>

      <hr class="section-divider">

      <!-- Model 11 -->
      <section id="model-11">
        <h2>Mental Model 11: The Ralph Mindset</h2>

        <h3>The Core Insight</h3>
        <p><strong>Files carry state, not context. Each iteration is fresh.</strong></p>
        <p>This mindset is not about a specific tool - it is about HOW you think about autonomous agent work.</p>

        <h3>The Ralph Mental Shift</h3>
        <div class="ascii-diagram">
WRONG THINKING:
"I'll set up a long-running agent that learns and improves"

RALPH THINKING:
"I'll set up iterations that read state, execute, write state, and exit clean"
        </div>

        <h3>Key Components of Ralph Thinking</h3>
        <ol>
          <li><strong>Bounded Iterations</strong> - Always know when to stop</li>
          <li><strong>External State</strong> - PRD + Progress + Git as source of truth</li>
          <li><strong>Clean Exit</strong> - Each iteration terminates explicitly</li>
          <li><strong>Quality Gates</strong> - Verification defines completion</li>
          <li><strong>Atomic Tasks</strong> - One context window per story</li>
        </ol>

        <h3>The Formula</h3>
        <div class="code-block">
          <button class="copy-btn">Copy</button>
          <pre><code>while not complete:
    read_state_from_files()
    select_next_atomic_task()
    execute_with_fresh_context()
    verify_output()
    write_state_to_files()
    commit_checkpoint()
    emit_exit_signal_if_done()</code></pre>
        </div>

        <h3>Evidence</h3>
        <p>All 5 Ralph variants (snarktank, frankbria, mikeyobrien, covibes, and canonical) implement this exact mindset with minor variations in state file format.</p>

        <h3>Horizontal Scaling with Swarms</h3>
        <p>The Ralph mindset scales horizontally through the swarms patterns:</p>
        <div class="ascii-diagram">
SINGLE RALPH (Traditional):
  while not complete:
    one_agent_iterates()

HORIZONTAL RALPH (swarms-informed):
  # Spawn multiple Ralph workers
  workers = [spawn_ralph(story) for story in independent_stories]

  # Each worker runs Ralph pattern independently
  # swarms coordinates: task distribution, result aggregation
  swarms.coordinate(workers, topology="concurrent")

The Mental Shift:
- Ralph = the PATTERN (iterate, verify, checkpoint)
- swarms = the SCALE (multiple patterns running in parallel)
        </div>

        <table>
          <thead>
            <tr>
              <th>Stories</th>
              <th>Workers</th>
              <th>Pattern</th>
              <th>Speedup</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>5 independent</td><td>5</td><td>Concurrent Ralph</td><td>~5x</td></tr>
            <tr><td>5 dependent</td><td>1</td><td>Sequential Ralph</td><td>1x</td></tr>
            <tr><td>10 mixed</td><td>Variable</td><td>Graph topology</td><td>~3-4x</td></tr>
          </tbody>
        </table>

        <h3>When to Apply</h3>
        <ul>
          <li>Autonomous feature development</li>
          <li>Multi-story implementation</li>
          <li>Any work that exceeds one context window</li>
          <li>Overnight/unattended operation</li>
        </ul>

        <details class="troubleshoot">
          <summary>Loop runs forever</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No termination condition</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add COMPLETE signal detection. Either check prd.json for all stories passing, or grep for an explicit completion signal in the output.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Repeating same work</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Progress not persisting</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Verify progress.txt is being written correctly. Add logging to confirm state persistence. Check that the next iteration reads the updated state.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 12 -->
      <section id="model-12">
        <h2>Mental Model 12: Phase Isolation Mindset</h2>

        <h3>The Core Insight</h3>
        <p><strong>Separate research, planning, and implementation into isolated sessions to maximize effective context usage.</strong></p>
        <p>This is the Frequent Intentional Compaction (FIC) methodology from HumanLayer.</p>

        <h3>The Three-Phase Model</h3>
        <div class="ascii-diagram">
PHASE 1: RESEARCH (30-40% context)
  - Gather information
  - Explore options
  - DO NOT IMPLEMENT
  - Compact and save to external file

PHASE 2: PLANNING (20-30% context)
  - Design solution
  - Define approach
  - DO NOT IMPLEMENT
  - Compact and save to external file

PHASE 3: IMPLEMENTATION (60-70% context)
  - Read research summary
  - Read plan summary
  - Execute implementation
  - Full context available for code
        </div>

        <h3>Why This Works</h3>
        <ul>
          <li>Research context does not pollute implementation</li>
          <li>Planning decisions are crystallized before execution</li>
          <li>Implementation gets maximum working context</li>
          <li>Each phase starts fresh at peak capability</li>
        </ul>

        <h3>Context Threshold Resolution</h3>
        <p>This resolves an apparent contradiction about context thresholds:</p>
        <div class="ascii-diagram">
SINGLE EXTENDED SESSION:
  40% - Conservative warning (Jaana Dogan)
  60-70% - Quality degradation begins
  85%+ - Hallucination risk
  -> Use conservative thresholds

PHASE-ISOLATED SESSIONS (FIC Methodology):
  Research Session: Use 30-40%, then compact
  Planning Session: Use 20-30%, then compact
  Implementation Session: 60-70% is ACCEPTABLE
  -> Phase isolation enables higher thresholds
        </div>

        <h3>The Phase Isolation Mental Shift</h3>
        <div class="ascii-diagram">
TRADITIONAL THINKING:
"I'll research, plan, and implement in one session"
-> Context fills with exploration, leaving little for implementation

FIC THINKING:
"I'll research until I know what I need -> compact
 I'll plan until I know how to do it -> compact
 I'll implement with full context available"
-> Each phase gets clean context at peak capability
        </div>

        <h3>When to Apply</h3>
        <ul>
          <li>Complex features requiring research</li>
          <li>Unfamiliar domains</li>
          <li>Large-scale refactoring</li>
          <li>Any task where exploration precedes implementation</li>
        </ul>

        <details class="troubleshoot">
          <summary>Implementation session forgetting research</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Did not read research file</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Explicitly load research file at session start. Begin the implementation session with "Read docs/research.md for context" or similar.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Plan does not match implementation</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Plan was vague</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Make plan more specific. Include file paths, method names, specific data structures. The plan should be detailed enough to execute mechanically.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 13 -->
      <section id="model-13">
        <h2>Mental Model 13: Validator Consensus Mindset</h2>

        <h3>The Core Insight</h3>
        <p><strong>For high-stakes work, single-agent output is insufficient. Multiple specialized validators catch what individuals miss.</strong></p>

        <h3>The Validator Architecture</h3>
        <div class="ascii-diagram">
IMPLEMENTER
    |
    +---> VALIDATORS
          +-- Requirements Validator
          +-- Code Review Validator
          +-- Security Validator (OWASP, XSS, CSRF)
          +-- Adversarial Validator (Attack surface)
          +-- Privacy Validator (GDPR)
          +-- Performance Validator (N+1, indexing)

          ALL must pass -> Accept
          ANY fails -> Iterate
        </div>

        <h3>The Validator Mindset Shift</h3>
        <div class="ascii-diagram">
TRUST-ONE THINKING:
"The implementation agent says it's done, so it's done"

VALIDATOR THINKING:
"The implementation is a proposal. Validators determine acceptance."
        </div>

        <h3>Key Properties</h3>
        <ol>
          <li><strong>Specialized Expertise</strong> - Each validator focuses on one domain</li>
          <li><strong>Fresh Context</strong> - Each validator evaluates with clean perspective</li>
          <li><strong>Veto Power</strong> - Any validator can reject</li>
          <li><strong>Iteration Loop</strong> - Rejection triggers implementation refinement</li>
        </ol>

        <h3>Cost Trade-off</h3>
        <ul>
          <li>Higher token cost (multiple validators per change)</li>
          <li>Lower error cost (catches issues before production)</li>
          <li>Right for: Security-critical, compliance-required, high-stakes</li>
        </ul>

        <h3>Exit Detection Evolution</h3>
        <p>Validator consensus is the highest tier of exit detection:</p>
        <table>
          <thead>
            <tr>
              <th>Strategy</th>
              <th>Mechanism</th>
              <th>Best For</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Simple Grep</td><td><code>grep -q "&lt;promise&gt;COMPLETE&lt;/promise&gt;"</code></td><td>Learning, simple tasks</td></tr>
            <tr><td>Dual-Condition Gate</td><td>Heuristic count + explicit signal</td><td>Long-running sessions</td></tr>
            <tr><td>Validator Consensus</td><td>All validators must approve</td><td>Security-critical</td></tr>
          </tbody>
        </table>

        <h3>When to Apply</h3>
        <ul>
          <li>Production code changes</li>
          <li>Security-sensitive systems</li>
          <li>Compliance-required domains</li>
          <li>Public-facing functionality</li>
        </ul>

        <details class="troubleshoot">
          <summary>Validators never agree</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Requirements unclear</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Align validators on shared acceptance criteria before starting. Each validator should know exactly what "pass" looks like for their domain.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Implementation loops endlessly</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Contradictory validator feedback</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add human arbitration for conflicts. When validators disagree, escalate to human judgment rather than letting the loop continue.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 14 -->
      <section id="model-14">
        <h2>Mental Model 14: Claims-Based Coordination Mindset</h2>

        <h3>The Core Insight</h3>
        <p><strong>Between full human control and full autonomy lies claims-based coordination.</strong></p>

        <h3>The HITL Spectrum</h3>
        <table>
          <thead>
            <tr>
              <th>Level</th>
              <th>Pattern</th>
              <th>Human Role</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1</td><td>Full Human (Claude Squad)</td><td>Coordinates all</td></tr>
            <tr><td>2</td><td>Tool-Based Escalation</td><td>Called via tool for decisions</td></tr>
            <tr><td>3</td><td>Claims-Based (claude-flow)</td><td>Reviews conflicts only</td></tr>
            <tr><td>4</td><td>Full Autonomy (Gas Town)</td><td>Reviews results only</td></tr>
          </tbody>
        </table>

        <h3>The Claims System</h3>
        <div class="ascii-diagram">
AGENT A wants to work on file.ts:
  -> Claims file.ts (advisory reservation)
  -> Other agents see the claim
  -> Other agents avoid file.ts
  -> Agent A completes, releases claim
  -> File.ts available for others
        </div>

        <h3>The Claims Mindset Shift</h3>
        <div class="ascii-diagram">
BINARY THINKING:
"Either I control everything or the agents are fully autonomous"

CLAIMS THINKING:
"Agents coordinate among themselves via claims. I only intervene for conflicts."
        </div>

        <h3>Key Properties</h3>
        <ol>
          <li><strong>Advisory, Not Blocking</strong> - Claims are signals, not locks</li>
          <li><strong>Conflict Detection</strong> - Overlapping claims surface issues</li>
          <li><strong>Human Escalation</strong> - Only unresolvable conflicts need human</li>
          <li><strong>Async-Friendly</strong> - No polling or real-time monitoring required</li>
        </ol>

        <h3>The Queen/Worker Hierarchy (claude-flow)</h3>
        <div class="ascii-diagram">
         QUEEN (Orchestrator)
            |
    +-------+-------+
    |       |       |
 Worker  Worker  Worker
   A       B       C

Queen Responsibilities:
- Maintains global view of work state
- Assigns tasks to available workers
- Resolves conflicts through claims registry
- Aggregates results

Worker Responsibilities:
- Claims files before editing
- Reports completion to Queen
- Releases claims on finish

The 87 MCP Tools distributed:
- Queen: Orchestration tools (task assignment, status)
- Workers: Execution tools (file ops, code analysis)
        </div>

        <h3>The SONA Coordination Layer (claude-flow)</h3>
        <p>Self-Organizing Neural Architecture enables dynamic coordination:</p>
        <table>
          <thead>
            <tr>
              <th>Component</th>
              <th>Function</th>
              <th>Claims Integration</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Task Queue</td><td>Pending work</td><td>Workers claim from queue</td></tr>
            <tr><td>Claims Registry</td><td>Active reservations</td><td>Conflict prevention</td></tr>
            <tr><td>Result Aggregator</td><td>Completed work</td><td>Claims release triggers</td></tr>
            <tr><td>ReasoningBank</td><td>Pattern memory</td><td>Shared across all workers</td></tr>
          </tbody>
        </table>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>Scaling beyond 5 agents (need hierarchical coordination)</li>
          <li>Workers need different tool sets (Queen routes appropriately)</li>
          <li>You need centralized visibility with distributed execution</li>
        </ul>

        <h3>When to Apply</h3>
        <ul>
          <li>Multi-agent file operations</li>
          <li>Shared codebases</li>
          <li>Parallel feature development</li>
          <li>Teams transitioning from manual to autonomous</li>
        </ul>

        <details class="troubleshoot">
          <summary>Agents ignoring claims</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Claims not checked in prompt</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add explicit claim-checking to agent instructions: "Before editing any file, check claims.json. If file is claimed by another agent, skip it and work on unclaimed files."</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Stale claims blocking work</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Agent crashed without release</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Implement TTL-based automatic release. Claims older than 10 minutes (configurable) are automatically released.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 15 -->
      <section id="model-15">
        <h2>Mental Model 15: The Swarm Mindset</h2>

        <h3>The Core Insight</h3>
        <p><strong>Individual agents learn nothing. Swarms can learn collectively through external knowledge stores.</strong></p>
        <p>Model 9 (Learning Must Compound) was about CLAUDE.md and progress.txt. The Swarm Mindset takes this further: Self-Learning Swarms with queryable collective memory.</p>

        <h3>The ReasoningBank Pattern (agentic-flow)</h3>
        <div class="ascii-diagram">
PRE-TASK:
  - Search ReasoningBank for similar past solutions
  - Load relevant patterns into context

POST-TASK:
  - Store successful patterns with reward scores
  - Tag with task type and context
  - Share across the swarm
        </div>

        <h3>The Swarm Mental Shift</h3>
        <div class="ascii-diagram">
INDIVIDUAL THINKING:
"Each agent starts fresh with no memory"

SWARM THINKING:
"Each agent starts fresh but queries the swarm's collective memory"
        </div>

        <h3>Key Insight</h3>
        <p>This does not contradict "fresh context" - agents still have fresh context windows. But they can QUERY external knowledge stores that contain accumulated swarm intelligence.</p>

        <h3>Components of Swarm Intelligence</h3>
        <ol>
          <li><strong>ReasoningBank</strong> - Past solutions indexed by similarity</li>
          <li><strong>Reward Scoring</strong> - Successful patterns ranked higher</li>
          <li><strong>Cross-Agent Sharing</strong> - One agent's learning benefits all</li>
          <li><strong>Pattern Tagging</strong> - Metadata for efficient retrieval</li>
        </ol>

        <!-- Organizational Memory Expansion -->
        <h3>The Organizational Memory Mental Model (from wshobson/agents and claude-flow)</h3>
        <p>Think of swarm intelligence as <strong>organizational memory at scale</strong>. Two architectures demonstrate this:</p>

        <div class="ascii-diagram">
WSHOBSON/AGENTS: Skill-Based Organizational Memory

110 skills accumulated represent:
- Reusable capabilities across agents
- Documented patterns for common tasks
- Composable building blocks

When a new agent joins:
- It inherits ALL 110 skills immediately
- No re-learning required
- Organizational capability is preserved

CLAUDE-FLOW: Query-Based Organizational Memory

ReasoningBank + SONA provide:
- Similarity-based pattern retrieval
- Reward-scored solution quality
- Cross-agent pattern sharing

When an agent faces a task:
- It queries for similar past solutions
- It receives proven patterns with scores
- It contributes new learnings back
        </div>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>Building organizational agent capabilities (use skills repository pattern)</li>
          <li>Handling repeated similar problems (use ReasoningBank pattern)</li>
          <li>Scaling beyond single-project scope (combine both approaches)</li>
        </ul>

        <h3>The Swarm Memory Quadrant</h3>
        <table>
          <thead>
            <tr>
              <th>Memory Type</th>
              <th>Storage</th>
              <th>Access</th>
              <th>Example</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Skills (wshobson)</td><td>Files</td><td>Direct load</td><td>agent-skills/file-ops.md</td></tr>
            <tr><td>Patterns (claude-flow)</td><td>ReasoningBank</td><td>Similarity query</td><td>"error handling in async"</td></tr>
            <tr><td>Context (CLAUDE.md)</td><td>Markdown</td><td>Session inject</td><td>Project-specific rules</td></tr>
            <tr><td>State (progress.txt)</td><td>Files</td><td>Direct read</td><td>Current work status</td></tr>
          </tbody>
        </table>

        <h3>When to Apply</h3>
        <ul>
          <li>Multi-agent systems at scale</li>
          <li>Repeated similar tasks across agents</li>
          <li>Long-running operations with learning opportunities</li>
          <li>Organizations building institutional agent memory</li>
        </ul>

        <details class="troubleshoot">
          <summary>Patterns never used</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">Query not finding matches</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Improve pattern tagging and similarity search. Use more descriptive tags, consider vector similarity for semantic matching.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>Bad patterns propagating</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No reward scoring</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add success/failure feedback loop. When developer accepts review feedback, increment success_count. When rejected, decrement or flag.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Model 16 -->
      <section id="model-16">
        <h2>Mental Model 16: The Enterprise Mindset</h2>

        <h3>The Core Insight</h3>
        <p><strong>Scale requires infrastructure. What works for 5 agents fails at 50.</strong></p>
        <p>At solo/team scale (1-10 agents), vanilla approaches work. At enterprise scale (10-100+), you need dedicated infrastructure.</p>

        <h3>The Enterprise Requirements</h3>
        <ol>
          <li><strong>Observability</strong> - Distributed tracing (Jaeger/OTEL)</li>
          <li><strong>Coordination</strong> - Advisory file reservations to prevent conflicts</li>
          <li><strong>Recovery</strong> - Atomic writes, checkpoint rollback</li>
          <li><strong>Cost Control</strong> - Budget limits, semantic caching</li>
          <li><strong>Multi-Provider</strong> - Abstract provider choice</li>
        </ol>

        <h3>The Coordination Ladder Extended</h3>
        <div class="ascii-diagram">
Level 1-2: SOLO (1-2 agents)
   Single Claude session, basic subagents

Level 3-4: HUB-AND-SPOKE (3-10 agents)
   Central orchestrator with specialized workers
   Example: orchestra (Vision, Docs, Coder, Arch...)

Level 5: PLATFORM ORCHESTRATION (10-50 agents)
   MCP-based enterprise coordination
   Example: station (41 MCP tools, N agents)
   Key: OpenAPI -> MCP conversion enables scale

Level 6: BOOTSTRAP FACTORY (50-100+ agents)
   Auto-configured agent management
   Example: claude-007-agents (112 agents, 14 categories)
   Key: Bootstrap orchestrator handles setup

Level 7: GAS TOWN (Unlimited)
   Full factory architecture
   Mayor, Deacon, Dogs, Refinery, Polecats, Witness
        </div>

        <h3>The Enterprise Mental Shift</h3>
        <div class="ascii-diagram">
TEAM THINKING:
"I'll run a few parallel Claude sessions with worktrees"

ENTERPRISE THINKING:
"I'll deploy a platform with MCP-based coordination,
observability, and cost controls"
        </div>

        <!-- Factory-Scale Expansion -->
        <h3>The Factory-Scale Mental Model (from wshobson/agents, swarms, and claude-flow)</h3>
        <p>At enterprise scale, think in terms of <strong>factory operations</strong>, not individual agents:</p>

        <div class="ascii-diagram">
FACTORY-SCALE THINKING (100+ agents):

wshobson/agents demonstrates:
- 100+ agents organized by capability
- 110 skills as shared organizational memory
- Category-based agent selection
- Ecosystem growth through skill accumulation

swarms demonstrates:
- 10+ coordination topologies
- Task-appropriate routing (sequential/concurrent/graph)
- Horizontal scaling through worker dispatch
- Failure isolation per stream

claude-flow demonstrates:
- Queen/Worker hierarchical control
- 87 MCP tools distributed by role
- SONA for self-organization
- ReasoningBank for pattern learning

The Common Enterprise Pattern:
1. TAXONOMY: Organize agents by capability (wshobson pattern)
2. COORDINATION: Route tasks through appropriate topology (swarms pattern)
3. HIERARCHY: Queen manages, Workers execute (claude-flow pattern)
4. MEMORY: Shared patterns across all agents (ReasoningBank)
        </div>

        <p><strong>Apply This When:</strong></p>
        <ul>
          <li>Deploying 50+ agents (need factory-scale thinking)</li>
          <li>Managing multi-team agent deployments (need taxonomy)</li>
          <li>Requiring organizational learning (need shared memory layer)</li>
        </ul>

        <h3>The Enterprise Architecture Stack</h3>
        <table>
          <thead>
            <tr>
              <th>Layer</th>
              <th>Component</th>
              <th>Implementation</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Capability</td><td>Agent taxonomy</td><td>wshobson/agents 14 categories</td></tr>
            <tr><td>Coordination</td><td>Task routing</td><td>swarms topologies</td></tr>
            <tr><td>Orchestration</td><td>Queen/Worker</td><td>claude-flow hierarchy</td></tr>
            <tr><td>Memory</td><td>Organizational learning</td><td>ReasoningBank + skills</td></tr>
            <tr><td>Infrastructure</td><td>Cost/Observability</td><td>LiteLLM + Jaeger</td></tr>
          </tbody>
        </table>

        <h3>Non-Negotiable Enterprise Needs</h3>
        <ol>
          <li><strong>Cost Control:</strong> How much are we spending? Per-team limits, alerts, enforcement.</li>
          <li><strong>Observability:</strong> What is happening? Logging, tracing, dashboards.</li>
          <li><strong>Audit Trail:</strong> What happened? Git-based changes, PR requirements, rollback.</li>
        </ol>

        <h3>When to Apply</h3>
        <ul>
          <li>10+ simultaneous agents</li>
          <li>Production deployments</li>
          <li>Compliance/audit requirements</li>
          <li>Multi-team coordination</li>
        </ul>

        <details class="troubleshoot">
          <summary>Surprise bills</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No budget controls</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Implement LiteLLM proxy with per-team limits immediately. Set alert thresholds at 50%, 75%, 90% of budget.</p>
            </div>
          </div>
        </details>

        <details class="troubleshoot">
          <summary>"What happened last night?"</summary>
          <div class="troubleshoot-content">
            <p class="troubleshoot-cause">No logging</p>
            <div class="troubleshoot-fix">
              <p class="troubleshoot-fix-label">Fix</p>
              <p>Add structured JSON logging for all agent actions. Deploy a dashboard (Grafana) for visibility. Every agent action should be queryable.</p>
            </div>
          </div>
        </details>
      </section>

      <hr class="section-divider">

      <!-- Evolution Section -->
      <section id="evolution">
        <h2>The Practitioner Evolution</h2>

        <p>How practitioners progress through mental models as they scale.</p>

        <h3>The Four Evolutionary Stages</h3>
        <div class="ascii-diagram">
STAGE 1: BEGINNER MINDSET
|
|   Mental Models Active:
|   - Context-First (learning)
|   - External State (learning)
|   - Verification (basic)
|
|   Characteristic Thinking:
|   "How do I prompt the agent to understand better?"
|
|   Scale: 1 session
|
+-------------------------------------------------------
|
STAGE 2: RALPH MINDSET
|
|   Mental Models Active:
|   - All 10 core models
|   - Fresh Context (internalized)
|   - Atomic Tasks (disciplined)
|   - Ralph Mindset (Model 11)
|
|   Characteristic Thinking:
|   "How do I structure this as an iterative loop with file-based state?"
|
|   Scale: 1-10 iterations, 1-5 parallel sessions
|
+-------------------------------------------------------
|
STAGE 3: ORCHESTRATION MINDSET
|
|   Mental Models Active:
|   - All Stage 2 models
|   - Phase Isolation (Model 12)
|   - Validator Consensus (Model 13)
|   - Claims-Based Coordination (Model 14)
|   - Swarm Memory (Model 15 - emerging)
|
|   Characteristic Thinking:
|   "How do I coordinate multiple agents with minimal conflict?"
|
|   Scale: 5-20 agents, hub-and-spoke patterns
|
+-------------------------------------------------------
|
STAGE 4: ENTERPRISE MINDSET
|
|   Mental Models Active:
|   - All Stage 3 models
|   - Enterprise Infrastructure (Model 16)
|   - Platform Orchestration
|   - Swarm Intelligence (mature)
|   - Three-Layer Cost Optimization
|
|   Characteristic Thinking:
|   "What infrastructure makes this reliable at scale?"
|
|   Scale: 20-100+ agents, factory patterns
        </div>

        <h3>Stage Transition Triggers</h3>
        <table>
          <thead>
            <tr>
              <th>Transition</th>
              <th>Trigger</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Beginner -> Ralph</td><td>Tasks consistently exceed one context window</td></tr>
            <tr><td>Ralph -> Orchestration</td><td>Parallel execution causes conflicts or duplication</td></tr>
            <tr><td>Orchestration -> Enterprise</td><td>Cost, observability, or reliability become blockers</td></tr>
          </tbody>
        </table>

        <h3>Self-Assessment</h3>
        <p>Rate each statement (1 = Never, 5 = Always):</p>

        <h4>Stage 1 Indicators</h4>
        <ul>
          <li>I add more explanation when Claude struggles</li>
          <li>I keep sessions going hoping Claude will "get it"</li>
          <li>I trust Claude when it says it is done</li>
        </ul>

        <h4>Stage 2 Indicators</h4>
        <ul>
          <li>I write state to files before ending sessions</li>
          <li>I break work into 2-3 sentence tasks</li>
          <li>I proactively restart sessions before quality degrades</li>
        </ul>

        <h4>Stage 3 Indicators</h4>
        <ul>
          <li>I separate research/planning/implementation into phases</li>
          <li>I use multiple agents with coordination</li>
          <li>I have validators for high-stakes work</li>
        </ul>

        <h4>Stage 4 Indicators</h4>
        <ul>
          <li>I have cost controls per agent/team</li>
          <li>I have observability dashboards</li>
          <li>I have audit trails for agent actions</li>
        </ul>
      </section>

      <hr class="section-divider">

      <!-- Maturity Ladder -->
      <section id="maturity">
        <h2>The Maturity Ladder</h2>

        <div class="ascii-diagram">
Level 0: Single interactive session
         Human types, agent responds, human reviews
         Time: Day 1

Level 1: CLAUDE.md + slash commands (Boris baseline)
         Persistent context, but manual sessions
         Time: First week

Level 2: Subagents + hooks (Buess unhobbling)
         Automated triggers, delegated work
         Time: Week 2-3

Level 3: Simple loops (Basic Ralph)
         Autonomous iteration on single tasks
         Time: Week 3-4

Level 4: PRD-driven loops (Full Ralph + compounding)
         Autonomous progress across multiple stories
         Time: Week 4-6

Level 5: Multi-agent orchestration (CC Mirror)
         Coordinated parallel execution
         Time: Week 6-8

Level 6: Platform orchestration (station-style)
         MCP-based enterprise coordination
         Time: Month 2-3
         Reference: claude-flow Queen/Worker, swarms topologies

Level 7: Factory scale (Gas Town + autonomous until complete)
         Production multi-agent systems
         Time: Month 3+
         Reference: wshobson/agents (100+ agents, 110 skills),
                    swarms (10+ coordination patterns),
                    claude-flow (87 MCP tools, SONA, ReasoningBank)
        </div>

        <h3>Model Activation by Scale</h3>
        <table>
          <thead>
            <tr>
              <th>Scale</th>
              <th>Critical Models</th>
              <th>New Models to Activate</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Solo (1-2)</td><td>Context-First, External State, Verification</td><td>-</td></tr>
            <tr><td>Ralph (1-10 iter)</td><td>Fresh Context, Atomic Tasks, Learning Compound</td><td>Ralph Mindset (11)</td></tr>
            <tr><td>Team (3-10 agents)</td><td>Parallelization, Human Orchestration</td><td>Claims Coordination (14)</td></tr>
            <tr><td>Enterprise (10-50)</td><td>Simplicity (even more critical)</td><td>Phase Isolation (12), Validator Consensus (13)</td></tr>
            <tr><td>Factory (50+)</td><td>Model Tiering</td><td>Enterprise Infrastructure (16), Swarm Intelligence (15)</td></tr>
          </tbody>
        </table>

        <div class="callout-warning">
          <div class="callout-title">Critical Insight</div>
          <p>Do not skip levels. Each builds on mastery of the previous. Jumping to Level 6 without mastering Level 3 produces failures, not productivity.</p>
        </div>
      </section>

      <hr class="section-divider">

      <!-- Navigation -->
      <div class="footer-nav">
        <a href="core-models.html" class="nav-prev">
          <span class="nav-direction">Previous</span>
          <span class="nav-title">Core Models (1-10)</span>
        </a>
        <a href="practice-heuristics.html" class="nav-next">
          <span class="nav-direction">Next</span>
          <span class="nav-title">Practice &amp; Heuristics</span>
        </a>
      </div>

      <div class="related-pages">
        <h3>Related Content</h3>
        <ul>
          <li><a href="core-models.html">Core Mental Models (1-10)</a> - The fundamentals you must master first</li>
          <li><a href="practice-heuristics.html">Practice and Heuristics</a> - Anti-patterns and quick decision rules</li>
          <li><a href="../foundations/invariants-reference.html">Invariants Reference</a> - The 9 universal truths</li>
          <li><a href="../../extractions/orchestration-master.html">Orchestration Patterns</a> - Deep dives on specific implementations</li>
        </ul>
      </div>
    </main>
  </div>

  <!-- Mobile sidebar toggle -->
  <button class="sidebar-toggle" aria-label="Open navigation">Menu</button>
  <div class="sidebar-overlay"></div>

  <script src="../../js/sidebar.js"></script>
</body>
</html>
