{
  "items": [
    {
      "id": "inv-1",
      "type": "inversion",
      "linkedSection": "essence",
      "title": "What if cost didn't matter?",
      "content": "<strong>You'd design:</strong> Use Opus for everything, never compact context, run unlimited iterations.<br>\n          <strong>Why this fails:</strong> At $75/MTok output (Opus 4.1), a 50-iteration overnight loop could cost $500+.<br>\n          <strong>Hidden constraint revealed:</strong> Cost forces efficiency, which often improves quality through constraint."
    },
    {
      "id": "min-2",
      "type": "minimal",
      "linkedSection": "essence",
      "title": "The irreducible cost optimization",
      "content": "<strong>Essential:</strong> Match model to task complexity.<br>\n          <strong>Essential:</strong> Enable prompt caching.<br>\n          <strong>Everything else:</strong> Refinement for scale. If you do only these two, you've captured 70% of savings."
    },
    {
      "id": "war-3",
      "type": "warstory",
      "linkedSection": "essence",
      "title": "YC Hackathon: 6 repos, $297 total",
      "content": "Multiple teams ran overnight Ralph loops building 6 repositories. Total cost: $297. Average: ~$50/repo. Proof that autonomous development can be cost-effective when properly constrained."
    },
    {
      "id": "grad-4",
      "type": "gradient",
      "linkedSection": "core",
      "title": "How cost optimization fails gradually",
      "content": "<strong>100% efficiency</strong>: Perfect model selection, warm cache<br>\n          <strong>80% efficiency</strong>: Occasional Opus for simple tasks (you won't notice)<br>\n          <strong>50% efficiency</strong>: Cold cache, no model switching<br>\n          <strong>20% efficiency</strong>: Opus for everything, runaway loops<br>\n          <strong>CLIFF</strong>: No limits, overnight surprises<br><br>\n          <em>Critical: The gradient feels fine until the monthly bill arrives.</em>"
    },
    {
      "id": "ana-5",
      "type": "analogy",
      "linkedSection": "core",
      "title": "Token economics = Cloud compute",
      "content": "<strong>On-demand pricing</strong> = API pay-per-token<br>\n          <strong>Reserved instances</strong> = Subscription plans<br>\n          <strong>Spot instances</strong> = Batch API (50% discount)<br>\n          <strong>Caching layers</strong> = Prompt caching<br>\n          <strong>Right-sizing</strong> = Model selection<br><br>\n          <em>If you've optimized AWS costs, you already know how to optimize Claude costs.</em>"
    },
    {
      "id": "con-6",
      "type": "constraint",
      "linkedSection": "core",
      "title": "One constraint produces FIVE decisions",
      "content": "<strong>ROOT:</strong> Output tokens cost 5x input tokens<br>\n          --&gt; Prefer concise outputs over verbose explanations<br>\n          --&gt; Use structured formats (JSON) over prose<br>\n          --&gt; Request code, not explanations of code<br>\n          --&gt; Leverage caching for repeated input context<br>\n          --&gt; Batch similar tasks to amortize input costs"
    },
    {
      "id": "trade-7",
      "type": "tradeoff",
      "linkedSection": "decisions",
      "title": "The Model Selection Dilemma",
      "content": "<strong>Haiku:</strong> 80% cheaper, but loses track in long sessions, forgets variable names<br>\n          <strong>Sonnet:</strong> Balanced, but occasional hallucinations on edge cases<br>\n          <strong>Opus:</strong> Best quality, but too slow/expensive for routine tasks<br><br>\n          <strong>WHY NO PERFECT ANSWER:</strong> The \"right\" model depends on task, codebase, and risk tolerance.<br>\n          <strong>HEURISTIC:</strong> If the mistake would cost more to fix than the model difference, use the better model."
    },
    {
      "id": "vio-8",
      "type": "violation",
      "linkedSection": "decisions",
      "title": "If you ignore caching",
      "content": "<strong>IF:</strong> You don't enable prompt caching<br>\n          <strong>THEN:</strong> Every request pays full price for system prompt<br>\n          <strong>THEN:</strong> 10K token context * 50 requests = 500K tokens * $3/MTok = $1.50 wasted<br>\n          <strong>THEN:</strong> Per day, that's $1.50. Per month: $30-45<br>\n          <strong>FINALLY:</strong> You've paid for a Max 5x subscription in wasted cache hits<br><br>\n          <em>The fix: Structure prompts with static content first. Always.</em>"
    },
    {
      "id": "exp-9",
      "type": "expertise",
      "linkedSection": "decisions",
      "title": "Cost optimization understanding",
      "content": "<strong>Beginner:</strong> \"How much does Claude cost?\" --&gt; $20-200/month typical<br>\n          <strong>Intermediate:</strong> \"How do I reduce costs?\" --&gt; Model selection + caching<br>\n          <strong>Advanced:</strong> \"What's my cost per feature?\" --&gt; Track /cost per session<br>\n          <strong>Staff:</strong> \"What's my team's ROI?\" --&gt; Cost per commit, cost per PR merged<br>\n          <strong>Expert:</strong> \"How do I optimize at scale?\" --&gt; Batch API, team rate limits, workspace budgets"
    },
    {
      "id": "inf-10",
      "type": "inflection",
      "linkedSection": "pricing",
      "title": "When subscription beats API",
      "content": "<strong>$0-50/month API:</strong> Pro subscription overkill<br>\n          <strong>$50-100/month API:</strong> Pro subscription is good value<br>\n          <strong>$100-150/month API:</strong> Max 5x starts making sense<br>\n          <strong>$150-200+/month API:</strong> Max 20x clearly wins<br><br>\n          <strong>THE INFLECTION:</strong> ~$100/month API spend<br>\n          <strong>DETECTION:</strong> Track API spend for 2 weeks, extrapolate to monthly"
    },
    {
      "id": "hor-11",
      "type": "horizon",
      "linkedSection": "pricing",
      "title": "How pricing perception changes",
      "content": "<strong>Day 1:</strong> \"$6/day feels expensive for a tool\"<br>\n          <strong>Week 2:</strong> \"Wait, I shipped 3x more code\"<br>\n          <strong>Month 2:</strong> \"My effective hourly rate doubled\"<br>\n          <strong>Month 6:</strong> \"I'd pay 10x this for the productivity\"<br><br>\n          <em>Don't judge Claude costs by tool pricing. Judge by productivity ROI.</em>"
    },
    {
      "id": "eff-12",
      "type": "effect",
      "linkedSection": "pricing",
      "title": "Opus 4.5 price drop changes everything",
      "content": "<strong>OLD:</strong> Opus 4.1 at $15/$75 per MTok --&gt; \"Only for critical reviews\"<br>\n          <strong>NEW:</strong> Opus 4.5 at $5/$25 per MTok --&gt; \"Use for any complex task\"<br><br>\n          <strong>IMPLICATION:</strong> The \"Haiku/Sonnet/Opus\" ladder collapses. Opus 4.5 is now affordable for daily work. The new decision is \"Haiku for trivial, Opus 4.5 for everything else.\""
    },
    {
      "id": "inv-13",
      "type": "invariant",
      "linkedSection": "pricing",
      "title": "Output costs 5x input across ALL models",
      "content": "This ratio is invariant across Haiku, Sonnet, and Opus. It's not a coincidence--it reflects the computational cost of generation vs. understanding.<br><br>\n          <strong>Why this matters:</strong> Optimization strategies transfer across models. \"Minimize output, maximize cache hits\" works universally."
    },
    {
      "id": "war-14",
      "type": "warstory",
      "linkedSection": "patterns",
      "title": "Geoffrey Huntley: 3-month Ralph loop",
      "content": "Built a programming language using continuous Ralph loops over 3 months. Extensive token usage but ROI-positive--the alternative was hiring a compiler engineer at $200K+/year."
    },
    {
      "id": "comp-15",
      "type": "composition",
      "linkedSection": "patterns",
      "title": "Multi-agent + Batch API",
      "content": "<strong>WORKS?</strong> Yes, with careful design<br>\n          <strong>WHY IT WORKS:</strong> Non-blocking workers can queue to Batch API for 50% savings<br>\n          <strong>THE DANGER:</strong> 24-hour Batch turnaround breaks real-time coordination<br>\n          <strong>RECOMMENDATION:</strong> Use Batch for background analysis, real-time for coordination"
    },
    {
      "id": "inv-16",
      "type": "inversion",
      "linkedSection": "patterns",
      "title": "What if Ralph didn't reset context?",
      "content": "<strong>You'd expect:</strong> Higher cost (accumulated context)<br>\n          <strong>Reality:</strong> Context rot causes MORE cost (retries, failed iterations)<br>\n          <strong>Hidden insight:</strong> Fresh context is cheaper because it succeeds more often. The \"waste\" of reloading state is recouped in reliability."
    },
    {
      "id": "con-17",
      "type": "constraint",
      "linkedSection": "patterns",
      "title": "Token limits force architecture",
      "content": "<strong>ROOT:</strong> 200K context window<br>\n          --&gt; Can't load entire codebase<br>\n          --&gt; Must select relevant files<br>\n          --&gt; Need file discovery tools<br>\n          --&gt; Grep/Glob become essential<br>\n          --&gt; Smart context loading = cost savings"
    },
    {
      "id": "vio-18",
      "type": "violation",
      "linkedSection": "gotchas",
      "title": "If you run Ralph without MAX_ITERATIONS",
      "content": "<strong>IF:</strong> No iteration limit on overnight loop<br>\n          <strong>THEN:</strong> Loop runs until rate limited or budget exhausted<br>\n          <strong>THEN:</strong> 100+ iterations on stuck task<br>\n          <strong>THEN:</strong> $200+ surprise bill<br>\n          <strong>FINALLY:</strong> Morning reveals no progress + empty budget<br><br>\n          <em>The fix: MAX_ITERATIONS=10 is the floor. Never omit it.</em>"
    },
    {
      "id": "grad-19",
      "type": "gradient",
      "linkedSection": "gotchas",
      "title": "How budget surprises compound",
      "content": "<strong>Week 1:</strong> $30 spent (expected)<br>\n          <strong>Week 2:</strong> $45 spent (\"huh, a bit more\")<br>\n          <strong>Week 3:</strong> $80 spent (\"what happened?\")<br>\n          <strong>Week 4:</strong> $150 spent (\"need to investigate\")<br>\n          <strong>Post-mortem:</strong> Playwright MCP was taking screenshots every action<br><br>\n          <em>Critical: The gradient is subtle until you investigate.</em>"
    },
    {
      "id": "fron-20",
      "type": "frontier",
      "linkedSection": "gotchas",
      "title": "UNSOLVED: Optimal budget allocation",
      "content": "<strong>THE QUESTION:</strong> How should you split budget between models? 50% Haiku / 40% Sonnet / 10% Opus? Or 0% / 80% / 20%?<br>\n          <strong>WHY IT'S HARD:</strong> Varies by task type, codebase, team skill<br>\n          <strong>CURRENT BEST PRACTICE:</strong> Track cost per task type for 2 weeks, then allocate based on actual patterns"
    },
    {
      "id": "trade-21",
      "type": "tradeoff",
      "linkedSection": "hard",
      "title": "The Productivity Paradox dilemma",
      "content": "<strong>Individual level:</strong> +98% PR throughput (clear win)<br>\n          <strong>Team level:</strong> +91% review time (where did the gain go?)<br>\n          <strong>Org level:</strong> Delivery velocity unchanged (wait, what?)<br><br>\n          <strong>WHY NO PERFECT ANSWER:</strong> AI shifts the bottleneck, doesn't eliminate it.<br>\n          <strong>HEURISTIC:</strong> Measure the whole pipeline, not just the AI-assisted step."
    },
    {
      "id": "hor-22",
      "type": "horizon",
      "linkedSection": "hard",
      "title": "ROI perception over time",
      "content": "<strong>Week 2:</strong> \"Productivity dropped, this isn't working\"<br>\n          <strong>Month 2:</strong> \"Starting to see patterns form\"<br>\n          <strong>Month 4:</strong> \"Can't imagine working without it\"<br>\n          <strong>Month 6:</strong> \"ROI is clearly positive\"<br><br>\n          <em>Warning: Week 2 measurements produce misleading negative results.</em>"
    },
    {
      "id": "eff-23",
      "type": "effect",
      "linkedSection": "hard",
      "title": "More code = more defects",
      "content": "<strong>OBSERVED:</strong> +98% PR throughput<br>\n          <strong>ALSO OBSERVED:</strong> Higher defect rate in AI-generated code<br>\n          <strong>IMPLICATION:</strong> Raw throughput gains are offset by quality issues<br>\n          <strong>THRESHOLD:</strong> ~1.5x code requires ~2x review effort<br><br>\n          <em>Track quality metrics alongside quantity metrics. Always.</em>"
    },
    {
      "id": "ana-24",
      "type": "analogy",
      "linkedSection": "hard",
      "title": "Hidden consumers = cloud egress",
      "content": "<strong>Cloud egress:</strong> Free to upload, expensive to download, often forgotten<br>\n          <strong>Claude tools:</strong> Web Search ($10/1K), Computer Use (735 tokens + screenshots), forgotten in estimates<br><br>\n          <em>If you've been surprised by AWS egress bills, you'll be surprised by tool token costs.</em>"
    },
    {
      "id": "alt-25",
      "type": "alternative",
      "linkedSection": "when",
      "title": "If subscription isn't right",
      "content": "<strong>Need transparent usage?</strong> --&gt; API with LiteLLM tracking<br>\n          <strong>Need per-agent keys?</strong> --&gt; API with separate keys<br>\n          <strong>Need batch processing?</strong> --&gt; API Batch (50% discount)<br>\n          <strong>Enterprise compliance?</strong> --&gt; Bedrock/Vertex deployment"
    },
    {
      "id": "exp-26",
      "type": "expertise",
      "linkedSection": "when",
      "title": "Subscription decision understanding",
      "content": "<strong>Beginner:</strong> \"Should I get Pro?\" --&gt; If you use it daily, yes<br>\n          <strong>Intermediate:</strong> \"Pro vs Max?\" --&gt; Track your 5-hour window usage<br>\n          <strong>Advanced:</strong> \"Team vs Max 20x?\" --&gt; Depends on usage patterns<br>\n          <strong>Staff:</strong> \"Hybrid approach?\" --&gt; Subscription + API for burst<br>\n          <strong>Expert:</strong> \"Enterprise custom?\" --&gt; When compliance/support matter"
    },
    {
      "id": "inv-27",
      "type": "invariant",
      "linkedSection": "when",
      "title": "Cost optimization = Context management",
      "content": "INV-004: Context management strategies apply universally to cost optimization. Compact context = fewer tokens. Fewer tokens = lower cost. The same techniques that prevent context rot also minimize spend."
    },
    {
      "id": "comp-28",
      "type": "composition",
      "linkedSection": "when",
      "title": "Subscription + API hybrid",
      "content": "<strong>WORKS?</strong> Yes, optimal for variable usage<br>\n          <strong>PATTERN:</strong> Max subscription for predictable daily work, API for burst automation<br>\n          <strong>WHY IT WORKS:</strong> Subscription caps downside, API handles overflow<br>\n          <strong>DANGER:</strong> Complexity in tracking two cost streams"
    },
    {
      "id": "war-29",
      "type": "warstory",
      "linkedSection": "when",
      "title": "Molly Cantillon: Jmail, 18M users",
      "content": "Built Jmail (18M users) overnight using Ralph loops. Cost was high but ROI was immediate--the alternative was months of manual development. When velocity matters more than cost, constraints flip."
    },
    {
      "id": "inv-30",
      "type": "inversion",
      "linkedSection": "when",
      "title": "What if you optimized for quality only?",
      "content": "<strong>You'd design:</strong> Opus for everything, extended think mode always, no cost monitoring<br>\n          <strong>Why this might work:</strong> Higher quality = fewer retries = potentially lower total cost<br>\n          <strong>Hidden insight:</strong> \"Cheap\" models that require 3 retries cost more than \"expensive\" models that succeed first try."
    }
  ]
}