{
  "items": [
    {
      "id": "inv-1",
      "type": "inversion",
      "linkedSection": "essence",
      "title": "What if all models cost the same?",
      "content": "<strong>You'd design:</strong> Always use Opus. Maximum capability, always.<br>\n          <strong>Why this fails:</strong> Even if free, context windows still degrade. Model selection isn't just cost.<br>\n          <strong>Hidden constraint revealed:</strong> The right model is about task fit, not just budget."
    },
    {
      "id": "min-2",
      "type": "minimal",
      "linkedSection": "essence",
      "title": "The irreducible cost optimization",
      "content": "<code style=\"background: #f4f4f5; padding: 2px 6px; border-radius: 4px; font-size: 12px;\">if task.simple: use haiku else: use sonnet</code><br>\n          <strong>Essential:</strong> Model tiering based on task complexity.<br>\n          <strong>Everything else:</strong> Refinements on top of this foundation."
    },
    {
      "id": "war-3",
      "type": "warstory",
      "linkedSection": "essence",
      "title": "@arvidkahl: $50-100+ per feature with Ralph",
      "content": "50 iterations overnight. \"Expensive as hell\" but shipped while sleeping. The question isn't \"is it cheap\" but \"is the value worth the cost?\""
    },
    {
      "id": "con-4",
      "type": "constraint",
      "linkedSection": "core",
      "title": "One constraint → FIVE cost decisions",
      "content": "<strong>ROOT:</strong> Output tokens cost 5x input tokens<br>\n          → Control max_tokens on all calls<br>\n          → Prefer structured JSON over prose<br>\n          → Ask for bullet points, not paragraphs<br>\n          → Skip preambles and conclusions<br>\n          → Measure output tokens separately"
    },
    {
      "id": "ana-5",
      "type": "analogy",
      "linkedSection": "core",
      "title": "Cost Optimization = Cloud Resource Tiering",
      "content": "Opus = m5.24xlarge (use for heavy compute)<br>\n          Sonnet = m5.xlarge (default workload)<br>\n          Haiku = t3.micro (background tasks)<br>\n          Spot instances = Batches API (50% off, flexible timing)<br><br>\n          <em>If you've optimized AWS bills, you already understand this.</em>"
    },
    {
      "id": "grad-6",
      "type": "gradient",
      "linkedSection": "core",
      "title": "How costs spiral (invisibly)",
      "content": "<strong>$5/day</strong>: Normal, no action needed<br>\n          <strong>$15/day</strong>: Check model selection<br>\n          <strong>$50/day</strong>: Audit workflows, implement tiering<br>\n          <strong>$200/day</strong>: Something is wrong. Check for runaway workers.<br>\n          <strong>$500+/day</strong>: Emergency. Stop and investigate.<br><br>\n          <em>Costs creep. Set alerts at each threshold.</em>"
    },
    {
      "id": "eff-7",
      "type": "effect",
      "linkedSection": "core",
      "title": "At scale: coordination costs dominate",
      "content": "<strong>At 1 worker:</strong> Pure task cost<br>\n          <strong>At 5 workers:</strong> 10-20% coordination overhead<br>\n          <strong>At 20 workers:</strong> Coordination can exceed task cost<br><br>\n          <strong>THRESHOLD:</strong> ~8-10 parallel workers<br>\n          <em>Beyond this, diminishing returns kick in hard.</em>"
    },
    {
      "id": "trade-8",
      "type": "tradeoff",
      "linkedSection": "decisions",
      "title": "The Model Selection Dilemma",
      "content": "<strong>Always Opus:</strong> Best quality, but 60x cost<br>\n          <strong>Always Haiku:</strong> Cheapest, but frequent failures<br>\n          <strong>Mixed:</strong> Optimal, but judgment required<br><br>\n          <strong>WHY NO PERFECT ANSWER:</strong> You can't know task complexity before trying.<br>\n          <strong>HEURISTIC:</strong> Start cheap, escalate on failure."
    },
    {
      "id": "vio-9",
      "type": "violation",
      "linkedSection": "decisions",
      "title": "If you skip model tiering",
      "content": "<strong>IF:</strong> You use Opus for everything<br>\n          <strong>THEN:</strong> Simple tasks cost 60x what they should<br>\n          <strong>THEN:</strong> Budget depleted faster<br>\n          <strong>THEN:</strong> Cut features to stay in budget<br>\n          <strong>FINALLY:</strong> Ship less while spending more<br><br>\n          <em>The fix: Default Sonnet. Opus only for complex reasoning.</em>"
    },
    {
      "id": "hor-10",
      "type": "horizon",
      "linkedSection": "decisions",
      "title": "How cost perception evolves",
      "content": "<strong>Day 1:</strong> \"$5? That's nothing.\"<br>\n          <strong>Week 1:</strong> \"$35/week. Getting real.\"<br>\n          <strong>Month 1:</strong> \"$150/month. Need to optimize.\"<br>\n          <strong>Month 3:</strong> \"Saving $100/month was worth 2 hours of setup.\"<br><br>\n          <em>Don't judge optimization by Day 1 costs.</em>"
    },
    {
      "id": "inv-11",
      "type": "invariant",
      "linkedSection": "decisions",
      "title": "Fresh context saves money across ALL patterns",
      "content": "Ralph, CC Mirror, Gas Town all share <strong>INV-003: External state &gt; internal memory</strong>.<br><br>\n          The same principle that maintains quality ALSO reduces cost. Fresh context = fewer tokens = lower bills."
    },
    {
      "id": "exp-12",
      "type": "expertise",
      "linkedSection": "models",
      "title": "How deep is your model selection skill?",
      "content": "<strong>Beginner:</strong> \"Which model is best?\" → Opus<br>\n          <strong>Intermediate:</strong> \"When is Sonnet enough?\" → Most implementation<br>\n          <strong>Advanced:</strong> \"When is Haiku right?\" → Parallel errands<br>\n          <strong>Staff:</strong> \"Dynamic selection?\" → Complexity classifier<br>\n          <strong>Expert:</strong> \"Fallback cascade?\" → Start cheap, escalate"
    },
    {
      "id": "war-13",
      "type": "warstory",
      "linkedSection": "models",
      "title": "Code Review Pipeline: 93% savings",
      "content": "<strong>Before:</strong> Full codebase + Opus = $300/month for 50 PRs/week<br>\n          <strong>After:</strong> Git diff only + tiered models + caching = $20/month<br><br>\n          <strong>Key insight:</strong> Context reduction mattered more than model selection."
    },
    {
      "id": "comp-14",
      "type": "composition",
      "linkedSection": "models",
      "title": "Haiku Army + Sonnet Orchestrator",
      "content": "<strong>Works?</strong> Yes, extremely well.<br>\n          <strong>Pattern:</strong> Sonnet plans, Haiku executes in parallel.<br>\n          <strong>The benefit:</strong> 10 Haiku workers = 1/6th cost of 1 Opus, often faster.<br>\n          <strong>Recommendation:</strong> Use for embarrassingly parallel tasks (file processing, test runs)."
    },
    {
      "id": "inv-15",
      "type": "inversion",
      "linkedSection": "models",
      "title": "What if Haiku was as smart as Opus?",
      "content": "<strong>You'd design:</strong> Haiku for everything. 60x cheaper, no downside.<br>\n          <strong>Why this fails:</strong> Capability differences are real. Haiku fails on complex reasoning.<br>\n          <strong>Hidden constraint revealed:</strong> Cost optimization has a quality floor."
    },
    {
      "id": "inf-16",
      "type": "inflection",
      "linkedSection": "patterns",
      "title": "When caching flips from overhead to savings",
      "content": "<strong>1-2 calls:</strong> Net negative (write cost &gt; savings)<br>\n          <strong>3-4 calls:</strong> Break-even<br>\n          <strong>5-10 calls:</strong> 80%+ savings<br>\n          <strong>100+ calls:</strong> 90%+ savings<br><br>\n          <strong>THE INFLECTION:</strong> ~3-4 calls with same cached content<br>\n          <strong>DETECTION:</strong> Multiply daily calls by prompt size. If &gt;5K tokens/day, cache."
    },
    {
      "id": "con-17",
      "type": "constraint",
      "linkedSection": "patterns",
      "title": "Batching constraint → workflow changes",
      "content": "<strong>ROOT:</strong> Batches API requires 24-48h turnaround<br>\n          → Can't use for real-time work<br>\n          → Must separate urgent from deferrable<br>\n          → Need queue system for batch jobs<br>\n          → Results delivered async<br>\n          → Workflow must handle delayed responses"
    },
    {
      "id": "fron-18",
      "type": "frontier",
      "linkedSection": "patterns",
      "title": "UNSOLVED: Optimal model routing",
      "content": "<strong>The question:</strong> Can we automatically route tasks to optimal models before trying?<br>\n          <strong>Why it's hard:</strong> Complexity isn't obvious from prompt text alone.<br>\n          <strong>Current best practice:</strong> Start cheap, escalate on failure. No reliable pre-routing yet."
    },
    {
      "id": "ana-19",
      "type": "analogy",
      "linkedSection": "patterns",
      "title": "Fresh Context = Serverless Functions",
      "content": "Long session = EC2 instance (always running, accumulating state)<br>\n          Fresh context = Lambda (stateless, spins up fresh)<br>\n          State files = DynamoDB (external persistence)<br>\n          Iteration = Invocation (clean start each time)<br><br>\n          <em>If you've designed for serverless, you understand why fresh context is cheaper.</em>"
    },
    {
      "id": "vio-20",
      "type": "violation",
      "linkedSection": "gotchas",
      "title": "If you don't monitor context size",
      "content": "<strong>IF:</strong> You ignore context accumulation<br>\n          <strong>THEN:</strong> Each iteration costs more than the last<br>\n          <strong>THEN:</strong> Quality degrades silently<br>\n          <strong>THEN:</strong> Retries needed for degraded output<br>\n          <strong>FINALLY:</strong> Paying 3x for 0.5x quality<br><br>\n          <em>The fix: Claude HUD shows context %. Compact at 80%.</em>"
    },
    {
      "id": "eff-21",
      "type": "effect",
      "linkedSection": "gotchas",
      "title": "At iteration 50+: reading dominates thinking",
      "content": "<strong>At iteration 10:</strong> Read 5K, think 95K context<br>\n          <strong>At iteration 30:</strong> Read 30K, think 70K context<br>\n          <strong>At iteration 50:</strong> Read 50K+, thinking compressed<br><br>\n          <strong>THRESHOLD:</strong> ~20KB state files<br>\n          <em>Beyond this, you're paying for history, not work.</em>"
    },
    {
      "id": "grad-22",
      "type": "gradient",
      "linkedSection": "gotchas",
      "title": "How budget overruns happen (invisibly)",
      "content": "<strong>10% over:</strong> Normal variance, ignore<br>\n          <strong>25% over:</strong> Something changed, investigate<br>\n          <strong>50% over:</strong> Model or workflow issue<br>\n          <strong>100% over:</strong> Runaway process or leak<br>\n          <strong>200%+ over:</strong> Emergency. Workers spawning workers.<br><br>\n          <em>Critical: Set alerts at 50% and 80% of daily budget.</em>"
    },
    {
      "id": "hor-23",
      "type": "horizon",
      "linkedSection": "gotchas",
      "title": "When \"acceptable\" costs become problems",
      "content": "<strong>First run:</strong> \"$10 for a feature? Great!\"<br>\n          <strong>10th run:</strong> \"$100/month... getting significant\"<br>\n          <strong>50th run:</strong> \"$500/month on one workflow\"<br>\n          <strong>100th run:</strong> \"This is my biggest expense\"<br><br>\n          <em>Today's acceptable is tomorrow's problem. Track from day 1.</em>"
    },
    {
      "id": "trade-24",
      "type": "tradeoff",
      "linkedSection": "hard",
      "title": "The Value Calculation Dilemma",
      "content": "<strong>THE DILEMMA:</strong> How do you measure AI ROI?<br>\n          <strong>Hours saved:</strong> Hard to measure precisely<br>\n          <strong>Quality improvement:</strong> Subjective<br>\n          <strong>Developer happiness:</strong> Not in the budget<br><br>\n          <strong>WHY NO PERFECT ANSWER:</strong> Value is context-dependent.<br>\n          <strong>HEURISTIC:</strong> If dev_hourly_rate * hours_saved &gt; AI_cost, it's worth it."
    },
    {
      "id": "war-25",
      "type": "warstory",
      "linkedSection": "hard",
      "title": "Steve Yegge on Gas Town costs",
      "content": "\"If you care about costs, don't use this.\"<br><br>\n          Gas Town runs multiple Claude accounts in parallel. Designed for capability, not economy. The warning is honest: some architectures optimize for power, not price."
    },
    {
      "id": "exp-26",
      "type": "expertise",
      "linkedSection": "hard",
      "title": "Cost optimization depth",
      "content": "<strong>Beginner:</strong> \"How do I reduce costs?\" → Use cheaper models<br>\n          <strong>Intermediate:</strong> \"What's the ROI?\" → Break-even calculation<br>\n          <strong>Advanced:</strong> \"Where's the waste?\" → Token-level analysis<br>\n          <strong>Staff:</strong> \"Systemic savings?\" → Architecture changes<br>\n          <strong>Expert:</strong> \"Cost as feature?\" → Intentional spending allocation"
    },
    {
      "id": "inv-27",
      "type": "invariant",
      "linkedSection": "hard",
      "title": "The winning formula across all patterns",
      "content": "<code style=\"background: #f4f4f5; padding: 2px 6px; border-radius: 4px; font-size: 12px;\">Fresh context + Tiered models + Early exit + Verification = Maximum value per dollar</code><br><br>\n          This formula appears in Ralph, CC Mirror, and Gas Town documentation. The principles are invariant."
    },
    {
      "id": "alt-28",
      "type": "alternative",
      "linkedSection": "when",
      "title": "If cost optimization isn't your priority",
      "content": "<strong>Need maximum quality?</strong> → Use Opus, accept the cost<br>\n          <strong>Need fastest iteration?</strong> → Skip optimization, ship now<br>\n          <strong>Need simplicity?</strong> → Pro subscription, no API<br>\n          <strong>Need scale?</strong> → Focus on parallelism, optimize later"
    },
    {
      "id": "inv-29",
      "type": "inversion",
      "linkedSection": "when",
      "title": "What if you over-optimized?",
      "content": "<strong>You'd design:</strong> Haiku for everything, minimal context, no caching overhead.<br>\n          <strong>Why this fails:</strong> Quality suffers. Rework costs exceed savings. Frustration increases.<br>\n          <strong>Hidden constraint revealed:</strong> Cost floor exists. Below it, you're trading value for savings."
    },
    {
      "id": "comp-30",
      "type": "composition",
      "linkedSection": "when",
      "title": "Cost Optimization + Ralph Pattern",
      "content": "<strong>Works?</strong> Extremely well. Natural fit.<br>\n          <strong>Why:</strong> Ralph's fresh context already saves 50-60%. Add tiering for another 60%.<br>\n          <strong>Compound effect:</strong> Combined savings: 80-90%<br>\n          <strong>Recommendation:</strong> Implement together. Synergies are strong."
    },
    {
      "id": "fron-31",
      "type": "frontier",
      "linkedSection": "when",
      "title": "UNSOLVED: Predictive cost modeling",
      "content": "<strong>The question:</strong> Can we predict total cost before starting a workflow?<br>\n          <strong>Why it's hard:</strong> Iterations depend on task difficulty. Parallel scaling depends on task decomposability. Both are unknown upfront.<br>\n          <strong>Current best practice:</strong> Estimate 2x optimistic guess. Track actuals. Adjust."
    }
  ]
}