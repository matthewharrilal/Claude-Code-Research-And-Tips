{
  "items": [
    {
      "id": "inv-1",
      "type": "inversion",
      "linkedSection": "essence",
      "title": "What if context DIDN'T degrade?",
      "content": "<strong>You'd design:</strong> One long session per feature, no external files, no restarts, accumulated knowledge building forever.<br>\n          <strong>Why this fails:</strong> 80K token context rot is transformer physics, not a bug. Attention degrades.<br>\n          <strong>Hidden constraint revealed:</strong> Context management patterns exist BECAUSE degradation is inevitable."
    },
    {
      "id": "min-2",
      "type": "minimal",
      "linkedSection": "essence",
      "title": "The irreducible core",
      "content": "<strong>Essential:</strong> Fresh context (kill and restart).<br>\n          <strong>Essential:</strong> External state (files persist).<br>\n          <strong>Everything else:</strong> Refinement for specific use cases (Claude-Mem, subagents, compaction)."
    },
    {
      "id": "war-3",
      "type": "warstory",
      "linkedSection": "essence",
      "title": "Matt Pocock: Context rot awareness",
      "content": "\"Context rot: LLMs get stupider with more tokens.\" Matt's observation became a rallying cry for the fresh context movement. Led to widespread adoption of iteration-based workflows over extended sessions."
    },
    {
      "id": "grad-4",
      "type": "gradient",
      "linkedSection": "core",
      "title": "How context degrades (invisibly)",
      "content": "<strong>100% -&gt; 90%</strong> (40-60K): Subtle drift, you won't notice<br>\n          <strong>90% -&gt; 70%</strong> (60-80K): Repetition, compression beginning<br>\n          <strong>70% -&gt; 50%</strong> (80-100K): Instructions forgotten, CLAUDE.md ignored<br>\n          <strong>50% -&gt; CLIFF</strong> (100K+): Hallucinations, amnesia, contradictions<br><br>\n          <em>Critical: The gradient is invisible until the cliff. By the time you notice, quality is already compromised.</em>"
    },
    {
      "id": "ana-5",
      "type": "analogy",
      "linkedSection": "core",
      "title": "Context Management = Computer Memory Hierarchy",
      "content": "<strong>In-context (conversation)</strong> = CPU registers (fast, tiny, volatile)<br>\n          <strong>progress.txt</strong> = RAM (fast, medium, session-scoped)<br>\n          <strong>CLAUDE.md</strong> = L2 cache (warm start, project-scoped)<br>\n          <strong>Git history</strong> = Disk (slow, huge, persistent)<br>\n          <strong>Claude-Mem</strong> = Database (queryable, cross-session)<br><br>\n          <em>If you've optimized memory hierarchies, you already understand context management.</em>"
    },
    {
      "id": "inv-6",
      "type": "invariant",
      "linkedSection": "core",
      "title": "INV-003: External state > internal memory",
      "content": "Ralph, Gas Town, CC Mirror, Personal Panopticon - all share this invariant. The filesystem IS the memory. The agent is stateless. This principle appears in every successful orchestration pattern."
    },
    {
      "id": "con-7",
      "type": "constraint",
      "linkedSection": "decisions",
      "title": "One constraint -> SEVEN decisions",
      "content": "<strong>ROOT:</strong> Context finite (200K) -&gt; Quality degrades as context fills<br>\n          -&gt; Fresh context beats extended sessions<br>\n          -&gt; State must persist externally (files)<br>\n          -&gt; Each iteration must be self-contained<br>\n          -&gt; Tasks must complete in one context window<br>\n          -&gt; Verification must be automatable<br>\n          -&gt; Subagents isolate expensive operations<br>\n          -&gt; Compaction is emergency, not strategy"
    },
    {
      "id": "vio-8",
      "type": "violation",
      "linkedSection": "decisions",
      "title": "If you rely on \"Claude remembering\"",
      "content": "<strong>IF:</strong> You rely on in-context memory instead of files<br>\n          <strong>THEN:</strong> Next iteration has no knowledge of previous<br>\n          <strong>THEN:</strong> Same mistakes repeated, same questions asked<br>\n          <strong>THEN:</strong> No velocity increase over iterations<br>\n          <strong>FINALLY:</strong> Iteration 20 is as slow as iteration 1<br><br>\n          <em>The fix: \"If it's not in a file, it doesn't exist.\"</em>"
    },
    {
      "id": "trade-9",
      "type": "tradeoff",
      "linkedSection": "decisions",
      "title": "The Context Richness Dilemma",
      "content": "<strong>Rich context:</strong> More files loaded = better understanding, but context fills faster<br>\n          <strong>Lean context:</strong> Less loaded = more room for work, but may miss important context<br>\n          <strong>External state:</strong> More in files = less in context, but reading files costs tokens too<br><br>\n          <em>Heuristic: Load only what's needed for the current task. .claudeignore aggressively.</em>"
    },
    {
      "id": "exp-10",
      "type": "expertise",
      "linkedSection": "strategies",
      "title": "How deep is your understanding?",
      "content": "<strong>Beginner:</strong> \"What files do I need?\" -&gt; CLAUDE.md, prd.json, progress.txt<br>\n          <strong>Intermediate:</strong> \"Why these files?\" -&gt; Each serves ONE purpose in state management<br>\n          <strong>Advanced:</strong> \"When to use each strategy?\" -&gt; Match strategy to task duration<br>\n          <strong>Staff:</strong> \"How do strategies compose?\" -&gt; Ralph + Git + Claude-Mem layers<br>\n          <strong>Expert:</strong> \"What's the fundamental constraint?\" -&gt; Attention degradation is physics"
    },
    {
      "id": "comp-11",
      "type": "composition",
      "linkedSection": "strategies",
      "title": "Fresh Context + Claude-Mem",
      "content": "<strong>Works?</strong> Yes, complementary.<br>\n          <strong>Why:</strong> Fresh context prevents rot. Claude-Mem provides cross-session learning. Best of both worlds.<br>\n          <strong>Danger:</strong> Claude-Mem injection consumes tokens. Keep max_tokens low (2000-5000).<br>\n          <strong>Recommendation:</strong> Use for long-term projects where compound learning outweighs injection cost."
    },
    {
      "id": "comp-12",
      "type": "composition",
      "linkedSection": "strategies",
      "title": "Subagents + Playwright",
      "content": "<strong>Works?</strong> Essential combination.<br>\n          <strong>Why:</strong> Browser automation generates massive token output. Keeping it in main context would cause rapid exhaustion.<br>\n          <strong>Pattern:</strong> delegate(task, subagent, return_summary_only=True)<br>\n          <strong>Benefit:</strong> Visual verification without context cost."
    },
    {
      "id": "war-13",
      "type": "warstory",
      "linkedSection": "strategies",
      "title": "Ryan Carson: Overnight development",
      "content": "Ran Ralph loops overnight for Untangle Legal Agent. Key insight: \"Learnings compound. By story 10, Ralph knew our patterns.\" The progress.txt paid off in later iterations. Fresh context prevented rot; file-based state preserved learnings."
    },
    {
      "id": "hor-14",
      "type": "horizon",
      "linkedSection": "path",
      "title": "How strategy choice evolves with project duration",
      "content": "<strong>30 min task:</strong> \"Just use single session, why complicate?\"<br>\n          <strong>2 hour feature:</strong> \"Maybe I should use files...\"<br>\n          <strong>Overnight run:</strong> \"Fresh context essential. Files are memory.\"<br>\n          <strong>Week-long project:</strong> \"Claude-Mem + structured archives + git as truth\"<br><br>\n          <em>Strategy choice is a function of time horizon.</em>"
    },
    {
      "id": "inv-15",
      "type": "inversion",
      "linkedSection": "path",
      "title": "What if you used Claude-Mem for everything?",
      "content": "<strong>You'd get:</strong> Cross-session memory always, compound learning everywhere.<br>\n          <strong>Why this fails:</strong> Stale context injection for short tasks. Token cost for simple work. Cross-project contamination. Overhead that doesn't pay off.<br>\n          <strong>Hidden constraint revealed:</strong> Complexity has cost. Match strategy to need."
    },
    {
      "id": "eff-16",
      "type": "effect",
      "linkedSection": "path",
      "title": "Context monitoring creates its own overhead",
      "content": "<strong>At scale:</strong> Checking context usage, running Claude HUD, tracking percentages - all consume mental bandwidth.<br>\n          <strong>Implication:</strong> For quick tasks, monitoring overhead exceeds benefit. Only monitor for long work.<br>\n          <strong>Threshold:</strong> Don't monitor sessions under 30 minutes."
    },
    {
      "id": "inf-17",
      "type": "inflection",
      "linkedSection": "gotchas",
      "title": "When progress.txt flips from help to hurt",
      "content": "<strong>0-10KB:</strong> Pure benefit (learnings compound)<br>\n          <strong>10-20KB:</strong> Diminishing returns (more to read each iteration)<br>\n          <strong>20-30KB:</strong> Neutral (reading cost = thinking benefit)<br>\n          <strong>30KB+:</strong> Net negative (context wasted on history)<br><br>\n          <strong>THE INFLECTION:</strong> ~20KB<br>\n          <em>Detection: Late iterations worse than early? Check progress.txt size.</em>"
    },
    {
      "id": "vio-18",
      "type": "violation",
      "linkedSection": "gotchas",
      "title": "If you skip .claudeignore",
      "content": "<strong>IF:</strong> No .claudeignore, Claude reads everything<br>\n          <strong>THEN:</strong> node_modules, dist, logs all loaded<br>\n          <strong>THEN:</strong> Context fills with irrelevant content<br>\n          <strong>THEN:</strong> Less room for actual work<br>\n          <strong>FINALLY:</strong> Quality degrades faster than necessary<br><br>\n          <em>The fix: Aggressive .claudeignore. Every ignored file saves tokens.</em>"
    },
    {
      "id": "fron-19",
      "type": "frontier",
      "linkedSection": "gotchas",
      "title": "UNSOLVED: Optimal compaction timing",
      "content": "<strong>The question:</strong> When exactly should you compact? At what % context? After what activities?<br>\n          <strong>Why it's hard:</strong> Compaction is lossy. Optimal varies by task type. No way to predict what gets lost.<br>\n          <strong>Current best practice:</strong> Compact at 60-70%, or prefer fresh session instead."
    },
    {
      "id": "grad-20",
      "type": "gradient",
      "linkedSection": "gotchas",
      "title": "CLAUDE.md quality degradation",
      "content": "<strong>0-200 tokens:</strong> Perfect recall, all directives followed<br>\n          <strong>200-400 tokens:</strong> Good recall, occasional misses<br>\n          <strong>400-600 tokens:</strong> Important rules sometimes forgotten<br>\n          <strong>600+ tokens:</strong> Significant portions ignored<br><br>\n          <em>Target: Under 500 tokens. Every token in CLAUDE.md costs context elsewhere.</em>"
    },
    {
      "id": "trade-21",
      "type": "tradeoff",
      "linkedSection": "hard",
      "title": "The 200K/100K Paradox",
      "content": "<strong>THE DILEMMA:</strong><br>\n          Claude advertises 200K context. Reality is 100K effective.<br>\n          Users plan for 200K. Quality fails at 100K.<br>\n          The gap creates false confidence.<br><br>\n          <strong>WHY NO PERFECT ANSWER:</strong><br>\n          200K is technically possible. It's just not quality-preserving. The limit is soft, not hard.<br><br>\n          <em>Accept: Budget for 100K. Anything beyond is risk.</em>"
    },
    {
      "id": "exp-22",
      "type": "expertise",
      "linkedSection": "hard",
      "title": "Context Management Understanding",
      "content": "<strong>Beginner:</strong> \"Why does Claude keep forgetting?\" -&gt; Context limits<br>\n          <strong>Intermediate:</strong> \"How do I prevent forgetting?\" -&gt; Fresh context + files<br>\n          <strong>Advanced:</strong> \"How do I optimize for my use case?\" -&gt; Strategy selection<br>\n          <strong>Staff:</strong> \"What are the fundamental tradeoffs?\" -&gt; Freshness vs continuity<br>\n          <strong>Expert:</strong> \"What's the physics?\" -&gt; Attention mechanism degradation"
    },
    {
      "id": "war-23",
      "type": "warstory",
      "linkedSection": "hard",
      "title": "Molly Cantillon: Personal Panopticon",
      "content": "8 parallel Claude instances managing different life domains. Key architecture: Each instance has its own context, isolated from others. Shared state through external files only. The pattern scales because each agent stays fresh."
    },
    {
      "id": "ana-24",
      "type": "analogy",
      "linkedSection": "when",
      "title": "Strategy Selection = Caching Strategy",
      "content": "<strong>Single session</strong> = No caching (everything in memory)<br>\n          <strong>File-based state</strong> = Write-through cache (always persist)<br>\n          <strong>Claude-Mem</strong> = Smart cache with eviction policy<br>\n          <strong>Compaction</strong> = Cache compression (lossy)<br><br>\n          <em>Match caching strategy to access pattern. Same applies to context.</em>"
    },
    {
      "id": "alt-25",
      "type": "alternative",
      "linkedSection": "when",
      "title": "If these strategies don't fit",
      "content": "<strong>Need real-time collaboration?</strong> -&gt; Human-in-tight-loop, skip automation<br>\n          <strong>Need cross-agent coordination?</strong> -&gt; CC Mirror pattern<br>\n          <strong>Need subjective evaluation?</strong> -&gt; HOTL (Human On The Loop) variants<br>\n          <strong>Need massive parallelism?</strong> -&gt; Gas Town factory architecture"
    },
    {
      "id": "inv-26",
      "type": "invariant",
      "linkedSection": "when",
      "title": "INV-002: Fresh context > extended sessions",
      "content": "This invariant appears across ALL patterns documented in this knowledge base. Ralph, Gas Town, CC Mirror, Personal Panopticon - they all spawn fresh instances rather than extending sessions. It's not preference; it's physics."
    },
    {
      "id": "hor-27",
      "type": "horizon",
      "linkedSection": "when",
      "title": "How judgment about context management evolves",
      "content": "<strong>Week 1:</strong> \"Why all these files? Just use Claude.\"<br>\n          <strong>Week 2:</strong> \"Claude keeps forgetting things...\"<br>\n          <strong>Week 4:</strong> \"Files ARE the memory. Claude is just the processor.\"<br>\n          <strong>Month 2:</strong> \"I've internalized stateless architecture.\"<br><br>\n          <em>Don't judge file-based state by day 1 overhead.</em>"
    },
    {
      "id": "eff-28",
      "type": "effect",
      "linkedSection": "when",
      "title": "External state enables reproducibility",
      "content": "<strong>At scale:</strong> When state is in files (not context), you can: replay runs, share with teammates, debug failures, audit decisions.<br>\n          <strong>Implication:</strong> File-based state isn't just about memory - it's about observability.<br>\n          <strong>Threshold:</strong> Any project where you might need to explain \"what happened\" benefits from external state."
    }
  ]
}