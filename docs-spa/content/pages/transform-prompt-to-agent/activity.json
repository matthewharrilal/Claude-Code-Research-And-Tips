{
  "items": [
    {
      "id": "inv-1",
      "type": "inversion",
      "linkedSection": "essence",
      "title": "What if the perfect prompt DID exist?",
      "content": "<strong>You'd design:</strong> A library of perfect prompts for every situation.<br>\n          <strong>Why this fails:</strong> Context varies. Tasks compound. One prompt can't handle multi-step verification, state persistence, or error recovery.<br>\n          <strong>Hidden constraint revealed:</strong> Prompts are atomic. Systems are molecular."
    },
    {
      "id": "min-2",
      "type": "minimal",
      "linkedSection": "essence",
      "title": "The irreducible transformation",
      "content": "<strong>From:</strong> \"What should I say?\"<br>\n          <strong>To:</strong> \"What should I build?\"<br><br>\n          <strong>Essential:</strong> This question change.<br>\n          <strong>Everything else:</strong> Implementation details."
    },
    {
      "id": "war-3",
      "type": "warstory",
      "linkedSection": "essence",
      "title": "Boris Cherny: \"Vanilla workflow\"",
      "content": "Claude Code creator's insight: \"I don't use fancy prompts. I use systems.\" His workflow is CLAUDE.md + Task tool + verification loops. The system compensates for prompt imperfection."
    },
    {
      "id": "ana-4",
      "type": "analogy",
      "linkedSection": "essence",
      "title": "Prompt to Agent = Assembly to C",
      "content": "Prompt engineering → Assembly (precise, low-level, manual)<br>\n          Agent engineering → C (abstracted, systematic, composable)<br>\n          You don't write better assembly. You switch languages."
    },
    {
      "id": "inv-5",
      "type": "invariant",
      "linkedSection": "essence",
      "title": "INV-6: Human as Orchestrator",
      "content": "The transformation embodies this invariant: Humans define WHAT, agents execute HOW. This applies whether you're at Level 1 or Level 5. The scale changes, the principle doesn't."
    },
    {
      "id": "grad-6",
      "type": "gradient",
      "linkedSection": "core",
      "title": "How prompt-thinking fails at scale",
      "content": "<strong>1-3 prompts:</strong> Fine, prompt tweaking works<br>\n          <strong>4-10 prompts:</strong> Chains get fragile, state lost between<br>\n          <strong>10-50:</strong> Impossible to maintain, context everywhere<br>\n          <strong>50+:</strong> You've built a system anyway, just badly<br><br>\n          <em>The transition is mandatory at scale. Choose when to make it.</em>"
    },
    {
      "id": "con-7",
      "type": "constraint",
      "linkedSection": "core",
      "title": "Why the mental model MUST change",
      "content": "<strong>ROOT:</strong> Context finite + Tasks complex<br>\n          → Can't fit everything in one prompt<br>\n          → Must decompose into steps<br>\n          → Steps need coordination<br>\n          → Coordination needs state<br>\n          → State needs persistence<br>\n          → You've built a system"
    },
    {
      "id": "eff-8",
      "type": "effect",
      "linkedSection": "core",
      "title": "At day 3, human-on-the-loop outperforms",
      "content": "<strong>Day 1:</strong> Human-in-the-loop is faster (no setup cost)<br>\n          <strong>Day 2:</strong> Roughly equal (system paying off, prompts degrading)<br>\n          <strong>Day 3+:</strong> Human-on-the-loop wins (compounding, overnight execution)<br><br>\n          <em>The crossover is at ~8 hours of total work.</em>"
    },
    {
      "id": "hor-9",
      "type": "horizon",
      "linkedSection": "core",
      "title": "How judgment evolves",
      "content": "<strong>Hour 1:</strong> \"System setup feels like overhead\"<br>\n          <strong>Hour 4:</strong> \"Wait, I can walk away now\"<br>\n          <strong>Hour 8:</strong> \"Work happened while I slept\"<br>\n          <strong>Day 3:</strong> \"Why did I ever babysit prompts?\"<br><br>\n          <em>Don't judge agent engineering by hour 1.</em>"
    },
    {
      "id": "vio-10",
      "type": "violation",
      "linkedSection": "decisions",
      "title": "If you skip verification design",
      "content": "<strong>IF:</strong> Skip \"What verification steps ensure quality?\"<br>\n          <strong>THEN:</strong> Agents produce unchecked output<br>\n          <strong>THEN:</strong> Errors compound across iterations<br>\n          <strong>THEN:</strong> Final output is garbage on good foundation<br>\n          <strong>FINALLY:</strong> You lose trust in autonomous systems<br><br>\n          <em>Verification isn't overhead. It's what makes autonomy possible.</em>"
    },
    {
      "id": "trade-11",
      "type": "tradeoff",
      "linkedSection": "decisions",
      "title": "System Complexity vs. Task Complexity",
      "content": "<strong>Simple task + complex system:</strong> Overhead dominates<br>\n          <strong>Complex task + simple system:</strong> Task fails, no reliability<br>\n          <strong>Match complexity to match:</strong> Judgment required<br><br>\n          <em>Heuristic: If system setup takes longer than task would, stay simple.</em>"
    },
    {
      "id": "inv-12",
      "type": "inversion",
      "linkedSection": "decisions",
      "title": "What if decomposition wasn't needed?",
      "content": "<strong>You'd have:</strong> Infinite context windows, perfect attention at all scales.<br>\n          <strong>Why this fails:</strong> Transformer attention is O(n^2). Context limits are physics.<br>\n          <strong>Hidden constraint revealed:</strong> Decomposition IS the workaround for finite context."
    },
    {
      "id": "exp-13",
      "type": "expertise",
      "linkedSection": "decisions",
      "title": "Design Decision Understanding",
      "content": "<strong>Beginner:</strong> \"Why not just use better prompts?\"<br>\n          → Because prompts don't persist state<br>\n          <strong>Intermediate:</strong> \"How do I know when to decompose?\"<br>\n          → When task exceeds one context window<br>\n          <strong>Advanced:</strong> \"What's the minimum viable system?\"<br>\n          → Loop + external state + verification<br>\n          <strong>Staff:</strong> \"When does system overhead exceed benefit?\"<br>\n          → When setup time &gt; 2x task time"
    },
    {
      "id": "comp-14",
      "type": "composition",
      "linkedSection": "decisions",
      "title": "Verification + Autonomy",
      "content": "<strong>Works:</strong> Automated verification enables unattended execution.<br>\n          <strong>Danger:</strong> Verification must be comprehensive. One missed edge case can cascade.<br>\n          <strong>Key:</strong> typecheck + tests + output validation = minimum bar."
    },
    {
      "id": "ana-15",
      "type": "analogy",
      "linkedSection": "skills",
      "title": "Skill translation = language translation",
      "content": "<strong>Prompt crafting</strong> → System architecture (same goal: clear communication)<br>\n          <strong>Few-shot examples</strong> → Task decomposition (same goal: guide behavior)<br>\n          <strong>Role prompting</strong> → Worker specialization (same goal: context setting)<br><br>\n          <em>Your skills transfer. The syntax changes, the semantics don't.</em>"
    },
    {
      "id": "exp-16",
      "type": "expertise",
      "linkedSection": "skills",
      "title": "New Questions Mastery",
      "content": "<strong>Beginner:</strong> \"What architecture ships code?\"<br>\n          → Ralph loop for overnight execution<br>\n          <strong>Intermediate:</strong> \"Where should state live?\"<br>\n          → Files (prd.json, progress.txt, git)<br>\n          <strong>Advanced:</strong> \"How decompose into parallel tasks?\"<br>\n          → By domain, by output, by dependency<br>\n          <strong>Staff:</strong> \"What happens when worker fails?\"<br>\n          → Retry logic, escalation path, state recovery"
    },
    {
      "id": "inf-17",
      "type": "inflection",
      "linkedSection": "skills",
      "title": "When old skills become liabilities",
      "content": "<strong>0-3 prompt tweaks:</strong> Good instinct (refinement)<br>\n          <strong>4-6 prompt tweaks:</strong> Diminishing returns<br>\n          <strong>7+ prompt tweaks:</strong> Net negative (wrong approach)<br><br>\n          <strong>THE INFLECTION:</strong> ~3 iterations<br>\n          <em>Detection: Third prompt tweak = time to think systems.</em>"
    },
    {
      "id": "war-18",
      "type": "warstory",
      "linkedSection": "skills",
      "title": "Matt Pocock: From prompts to Ralph",
      "content": "Started as prompt expert. Now runs Ralph loops for features. \"I spent 6 months on prompt engineering. Then realized the skill is architecture.\" His TypeScript content now gets built by agent systems he designs."
    },
    {
      "id": "vio-19",
      "type": "violation",
      "linkedSection": "path",
      "title": "If you skip the ladder levels",
      "content": "<strong>IF:</strong> Jump from Level 1 to Level 4 (skip 2, 3)<br>\n          <strong>THEN:</strong> No intuition for task sizing<br>\n          <strong>THEN:</strong> Workers fail unpredictably<br>\n          <strong>THEN:</strong> Debugging is guesswork<br>\n          <strong>FINALLY:</strong> Conclude \"agent systems don't work\"<br><br>\n          <em>The ladder exists because each level builds intuition for the next.</em>"
    },
    {
      "id": "hor-20",
      "type": "horizon",
      "linkedSection": "path",
      "title": "Level perception over time",
      "content": "<strong>Week 1:</strong> \"Level 3 is amazing, why go further?\"<br>\n          <strong>Week 2:</strong> \"I keep hitting context limits...\"<br>\n          <strong>Week 4:</strong> \"Level 4 unlocks overnight work\"<br>\n          <strong>Month 2:</strong> \"Level 5 is just Level 4 with better hygiene\"<br><br>\n          <em>Each level feels complete until you hit its limits.</em>"
    },
    {
      "id": "con-21",
      "type": "constraint",
      "linkedSection": "path",
      "title": "Why the 5-step order matters",
      "content": "<strong>1. Stop optimizing prompts</strong> → Frees mental bandwidth<br>\n          <strong>2. Start designing systems</strong> → Uses that bandwidth<br>\n          <strong>3. Think in orchestration</strong> → Scales the designs<br>\n          <strong>4. Embrace autonomy</strong> → Unlocks human time<br>\n          <strong>5. Build feedback loops</strong> → Makes autonomy safe<br><br>\n          <em>Each step enables the next. Order isn't arbitrary.</em>"
    },
    {
      "id": "alt-22",
      "type": "alternative",
      "linkedSection": "path",
      "title": "Different entry points by background",
      "content": "<strong>From DevOps:</strong> Start at orchestration (familiar territory)<br>\n          <strong>From Data Science:</strong> Start at decomposition (pipeline thinking)<br>\n          <strong>From Frontend:</strong> Start at feedback loops (test-driven)<br>\n          <strong>From Backend:</strong> Start at state management (database thinking)"
    },
    {
      "id": "inv-23",
      "type": "inversion",
      "linkedSection": "gotchas",
      "title": "Why prompt-tweaking habit is so strong",
      "content": "<strong>The habit:</strong> Prompt tweaking feels productive. Each change is a micro-experiment.<br>\n          <strong>The trap:</strong> Local optimization. You're improving the wrong thing.<br>\n          <strong>Hidden constraint revealed:</strong> Human brains prefer immediate feedback to delayed payoff."
    },
    {
      "id": "eff-24",
      "type": "effect",
      "linkedSection": "gotchas",
      "title": "Orchestrator drift compounds",
      "content": "If orchestrator starts doing worker tasks, it becomes a bottleneck. At 3 workers, 10% drift costs 30% capacity. At 10 workers, same drift costs 100%. Iron Law exists because violations don't scale linearly."
    },
    {
      "id": "trade-25",
      "type": "tradeoff",
      "linkedSection": "gotchas",
      "title": "Pattern Selection Complexity",
      "content": "<strong>Option A:</strong> Learn one pattern deeply, apply everywhere (brittle)<br>\n          <strong>Option B:</strong> Learn all patterns, decide case-by-case (decision fatigue)<br>\n          <strong>Option C:</strong> Learn decision tree, navigate to pattern (recommended)<br><br>\n          <em>Heuristic: The quick selector in Section 6 is your decision tree.</em>"
    },
    {
      "id": "fron-26",
      "type": "frontier",
      "linkedSection": "gotchas",
      "title": "UNSOLVED: Automatic task sizing",
      "content": "No tool exists that automatically decomposes \"Build auth system\" into properly-sized agent tasks. Optimal varies by codebase, team, and model version. Currently requires human judgment."
    },
    {
      "id": "trade-27",
      "type": "tradeoff",
      "linkedSection": "hard",
      "title": "Human Involvement Level",
      "content": "<strong>High involvement:</strong> Quality assured, but no leverage<br>\n          <strong>Medium involvement:</strong> Review gates, balanced<br>\n          <strong>Low involvement:</strong> Maximum leverage, quality varies<br><br>\n          <em>There is no \"right\" level. Match to task risk and reversibility.</em>"
    },
    {
      "id": "grad-28",
      "type": "gradient",
      "linkedSection": "hard",
      "title": "How decomposition skill degrades",
      "content": "<strong>Clear domain:</strong> 90% success (you know the grain)<br>\n          <strong>Adjacent domain:</strong> 70% (some transfer)<br>\n          <strong>New domain:</strong> 50% (learning curve)<br>\n          <strong>Unknown domain:</strong> 30% (exploration needed first)<br><br>\n          <em>Your decomposition skill is domain-specific. Expect re-learning.</em>"
    },
    {
      "id": "exp-29",
      "type": "expertise",
      "linkedSection": "hard",
      "title": "Context Management Understanding",
      "content": "<strong>Beginner:</strong> \"Where does state go?\"<br>\n          → Files (prd.json, progress.txt)<br>\n          <strong>Intermediate:</strong> \"How do agents share knowledge?\"<br>\n          → Common file reading at iteration start<br>\n          <strong>Advanced:</strong> \"When does context become a liability?\"<br>\n          → progress.txt &gt; 20KB, unbounded growth<br>\n          <strong>Staff:</strong> \"System-level context architecture?\"<br>\n          → Tiered: session (volatile) → project (stable) → org (permanent)"
    },
    {
      "id": "war-30",
      "type": "warstory",
      "linkedSection": "hard",
      "title": "Steve Yegge: Gas Town evolution",
      "content": "\"We redesigned Gas Town three times. First version: prompts everywhere. Second: basic orchestration. Third: true agent factory.\" Each redesign came from hitting the limits of the previous architecture."
    },
    {
      "id": "inv-31",
      "type": "inversion",
      "linkedSection": "when",
      "title": "What if you NEVER made the shift?",
      "content": "<strong>You'd:</strong> Max out at Level 3 capability forever. Babysit every AI interaction. Never achieve overnight execution.<br>\n          <strong>Why this fails:</strong> Others who shift will outpace you 10x.<br>\n          <strong>Hidden constraint revealed:</strong> The shift is mandatory for scale. Only timing is optional."
    },
    {
      "id": "inf-32",
      "type": "inflection",
      "linkedSection": "when",
      "title": "When prompting flips to overhead",
      "content": "<strong>1-2 prompts:</strong> Prompting is faster (no setup)<br>\n          <strong>3-5 prompts:</strong> Break-even zone<br>\n          <strong>6-10 prompts:</strong> System wins clearly<br>\n          <strong>10+:</strong> Prompting is unsustainable<br><br>\n          <strong>THE INFLECTION:</strong> ~5 prompts for same task<br>\n          <em>Detection: Third time you prompt the same type of task = build a system.</em>"
    },
    {
      "id": "ana-33",
      "type": "analogy",
      "linkedSection": "when",
      "title": "Task verification = unit testing",
      "content": "<strong>No tests:</strong> Quick to write, scary to run<br>\n          <strong>Some tests:</strong> Slower to write, safer to run<br>\n          <strong>Full coverage:</strong> Slowest to write, safest to run<br><br>\n          <em>If you believe in tests for code, you should believe in verification for agents.</em>"
    },
    {
      "id": "alt-34",
      "type": "alternative",
      "linkedSection": "when",
      "title": "If transformation isn't right yet",
      "content": "<strong>Quick questions?</strong> → Stay with prompts<br>\n          <strong>Exploratory work?</strong> → Single Claude session<br>\n          <strong>Creative brainstorm?</strong> → Conversational mode<br>\n          <strong>One-off task?</strong> → YOLO mode, don't over-engineer"
    }
  ]
}