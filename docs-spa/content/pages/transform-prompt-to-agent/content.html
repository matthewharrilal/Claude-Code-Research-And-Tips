<!--
═══════════════════════════════════════════════════════════════════════════════
INLINE THREADING HEADER — Phase 2B
File: docs-spa/content/pages/transform-prompt-to-agent/content.html
Tier: C | Batch: 13 | Generated: 2026-02-06

1. WHY THIS EXISTS
Rendered HTML content page for the transform-prompt-to-agent synthesis document.

3. STATUS
ACTIVE

5. BUILT ON
Extracted from synthesis/transform-prompt-to-agent.md by content extraction scripts.

8. CONSUMED BY
docs-spa/app/(docs)/synthesis/transform-prompt-to-agent/page.tsx renders this content via dangerouslySetInnerHTML.

═══════════════════════════════════════════════════════════════════════════════
END INLINE THREADING HEADER
═══════════════════════════════════════════════════════════════════════════════
-->

      <!-- Section 1: ESSENCE -->
      <section id="essence" data-activity="essence">
        <div class="essence-box">
          <div class="essence-label">Essence (15 words)</div>
          <div class="essence-text">Stop crafting prompts. Start designing systems. The question is now "What should I build?"</div>
        </div>

        <p class="text-text-secondary mb-6">
          This document captures the fundamental mindset shift from crafting individual prompts to designing autonomous systems. If you're still obsessing over the perfect wording or few-shot examples, this transformation shows you the path to system-level thinking.
        </p>

        <p class="text-text-secondary mb-6">
          This connects to the evolution from Level 1-2 (prompt-focused) to Level 3-5 (architecture-focused) on the complexity ladder.
        </p>
      </section>

      <!-- Section 2: CORE ABSTRACTION + IMPLEMENTATION -->
      <section id="core-abstraction" data-activity="core">
        <h2 class="section-title">
          <span class="section-number">2</span>
          The Core Abstraction
        </h2>

        <div class="core-abstraction">
          <div class="core-philosophy">"The question is no longer 'What should I say?' The question is now 'What should I build?'"</div>

          <div class="transition-arrow">
            <span>Human-in-the-Loop</span>
            <div class="arrow"></div>
            <span>Human-on-the-Loop</span>
          </div>

          <div class="core-anchor">This is the shift from prompt engineering to agent engineering.</div>
        </div>

        <div class="era-box old">
          <div class="era-label">Before: Prompt Engineering Era (2023-2024)</div>
          <div class="era-mindset">"How do I phrase this to get the best output?"</div>
          <ul class="era-list">
            <li><i data-lucide="minus" class="w-4 h-4 text-text-muted"></i> Focus: Crafting the perfect prompt</li>
            <li><i data-lucide="minus" class="w-4 h-4 text-text-muted"></i> Model: Request followed by Response</li>
            <li><i data-lucide="minus" class="w-4 h-4 text-text-muted"></i> Skill: Prompt writing, few-shot examples</li>
            <li><i data-lucide="minus" class="w-4 h-4 text-text-muted"></i> Time horizon: Single interaction</li>
          </ul>
        </div>

        <div class="era-box new">
          <div class="era-label">After: Agent Engineering Era (2025-2026)</div>
          <div class="era-mindset">"How do I design a system that accomplishes this autonomously?"</div>
          <ul class="era-list">
            <li><i data-lucide="check" class="w-4 h-4 text-accent"></i> Focus: Designing systems of agents</li>
            <li><i data-lucide="check" class="w-4 h-4 text-accent"></i> Model: Orchestration followed by Execution followed by Iteration</li>
            <li><i data-lucide="check" class="w-4 h-4 text-accent"></i> Skill: System architecture, feedback loops</li>
            <li><i data-lucide="check" class="w-4 h-4 text-accent"></i> Time horizon: Hours to days</li>
          </ul>
        </div>

        <h3 class="font-semibold text-lg mb-4 mt-8">Mental Model Comparison</h3>

        <div class="code-block">
          <button class="copy-btn" onclick="copyCodeBlock(this)">
            <i data-lucide="copy" class="w-3 h-3"></i>
            Copy
          </button>
          <pre><span class="comment"># OLD: Human-in-the-Loop</span>
Human crafts prompt
    |
    v
AI generates response
    |
    v
Human reviews output
    |
    v
Human refines prompt
    |
    v
[Repeat until satisfied]

<span class="comment"># NEW: Human-on-the-Loop</span>
Human designs system architecture
    |
    v
Human launches orchestrator agent
    |
    v
Orchestrator spawns worker agents
    |
    v
Workers execute, verify, iterate
    |
    v
Human sleeps / does other work
    |
    v
Human reviews completed results</pre>
        </div>
      </section>

      <!-- Section 3: DESIGN DECISIONS -->
      <section id="why-systems" data-activity="decisions">
        <h2 class="section-title">
          <span class="section-number">3</span>
          Design Decisions
        </h2>

        <div class="decision-box">
          <div class="decision-why">WHY SYSTEMS OVER PROMPTS?</div>
          <div class="decision-reasoning">
            The perfect prompt doesn't exist. And even if it did, it wouldn't scale. Every comma mattered in prompt engineering. Tiny changes cascaded unpredictably. That energy is wasted now. System design produces reliable, repeatable results.
          </div>
          <div class="decision-implication">
            <div class="decision-implication-label">What this means for you</div>
            <div class="text-text-secondary text-sm">
              If you're spending more than 10 minutes tweaking prompt wording, stop. That time goes into system design instead. Think about the whole flow: input, intermediate steps, state persistence, communication, verification, output.
            </div>
          </div>
        </div>

        <div class="decision-box" id="why-decomposition">
          <div class="decision-why">WHY TASK DECOMPOSITION?</div>
          <div class="decision-reasoning">
            Single agents hit limits. Context windows are finite. Complex tasks exceed what one agent can hold in context. Decomposition lets you distribute work across multiple focused agents, each with fresh context for their specific subtask.
          </div>
          <div class="decision-implication">
            <div class="decision-implication-label">What this means for you</div>
            <div class="text-text-secondary text-sm">
              Every task should be decomposable into atomic units. If you can't describe a task in 2-3 sentences, split it. "Build auth system" becomes "Add users table", "Add auth middleware", "Add login form", "Add session handling".
            </div>
          </div>
        </div>

        <div class="decision-box" id="why-verification">
          <div class="decision-why">WHY VERIFICATION LOOPS?</div>
          <div class="decision-reasoning">
            Agents without verification go off the rails. Prompts alone can't guarantee quality. Verification through tests, typecheck, and output validation catches errors before they compound. This is what makes autonomous execution safe.
          </div>
          <div class="decision-implication">
            <div class="decision-implication-label">What this means for you</div>
            <div class="text-text-secondary text-sm">
              Every system needs: output validation, error detection, quality checks, self-correction triggers. The question is no longer "How do I avoid hallucinations in this prompt?" but "What verification step catches hallucinations before they matter?"
            </div>
          </div>
        </div>

        <div class="checkpoint-box">
          <div class="checkpoint-title">
            <i data-lucide="check-circle" class="w-4 h-4"></i>
            Checkpoint: After System Design
          </div>
          <div class="checkpoint-content">
            <strong>Verify your mindset shift:</strong><br><br>
            Old: "How do I phrase this?" → New: "How do I decompose this?"<br>
            Old: "What few-shot examples?" → New: "What verification steps?"<br>
            Old: "Which temperature?" → New: "Which orchestration pattern?"<br>
            Old: "How do I avoid hallucination?" → New: "How do I detect and recover from errors?"
          </div>
        </div>
      </section>

      <!-- Section 4: THE NEW SKILLS -->
      <section id="skills" data-activity="skills">
        <h2 class="section-title">
          <span class="section-number">4</span>
          The New Skills
        </h2>

        <p class="text-text-secondary mb-6">
          The skills you developed for prompt engineering don't disappear - they transform. Here's the mapping:
        </p>

        <table class="comparison-table">
          <thead>
            <tr>
              <th>Old Skill</th>
              <th>New Skill</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Prompt crafting</td>
              <td>System architecture</td>
            </tr>
            <tr>
              <td>Few-shot examples</td>
              <td>Task decomposition</td>
            </tr>
            <tr>
              <td>Role prompting</td>
              <td>Worker specialization</td>
            </tr>
            <tr>
              <td>Output parsing</td>
              <td>State management</td>
            </tr>
            <tr>
              <td>Prompt chaining</td>
              <td>Orchestration patterns</td>
            </tr>
            <tr>
              <td>Temperature tuning</td>
              <td>Feedback loop design</td>
            </tr>
            <tr>
              <td>Token optimization</td>
              <td>Checkpoint strategy</td>
            </tr>
            <tr>
              <td>Single-model mastery</td>
              <td>Multi-agent coordination</td>
            </tr>
          </tbody>
        </table>

        <h3 class="font-semibold text-lg mb-4 mt-8">Key Questions Changed</h3>

        <div class="code-block">
          <button class="copy-btn" onclick="copyCodeBlock(this)">
            <i data-lucide="copy" class="w-3 h-3"></i>
            Copy
          </button>
          <pre><span class="comment"># Old Questions (Prompt Engineering)</span>
- "What prompt gets the best answer?"
- "How do I avoid hallucinations in this prompt?"
- "What temperature should I use?"
- "How many few-shot examples are enough?"
- "Should I use JSON or markdown output?"

<span class="comment"># New Questions (Agent Engineering)</span>
- "What architecture ships code overnight?"
- "How do I design feedback loops that catch errors?"
- "Where should state live between agent sessions?"
- "How do I decompose this into parallelizable tasks?"
- "What verification steps ensure quality?"
- "How does the orchestrator coordinate workers?"
- "What happens when a worker fails mid-task?"</pre>
        </div>
      </section>

      <!-- Section 5: THE PATH OF TRANSITION -->
      <section id="path" data-activity="path">
        <h2 class="section-title">
          <span class="section-number">5</span>
          Making the Transition
        </h2>

        <p class="text-text-secondary mb-6">
          Follow this path to transform from prompt engineering to agent engineering:
        </p>

        <div class="path-container">
          <div class="path-step">
            <div class="path-number">1</div>
            <div class="path-content">
              <strong>Stop Optimizing Prompts</strong><br>
              The perfect prompt doesn't exist. If you're on iteration 3+ of prompt tweaks, STOP and design a system instead.
            </div>
          </div>
          <div class="path-step">
            <div class="path-number">2</div>
            <div class="path-content">
              <strong>Start Designing Systems</strong><br>
              Think about the whole flow: What's the input? What are intermediate steps? Where does state persist? How do agents communicate? What's the verification strategy? What's the output?
            </div>
          </div>
          <div class="path-step">
            <div class="path-number">3</div>
            <div class="path-content">
              <strong>Think in Orchestration</strong><br>
              Single agents hit limits. Learn orchestration patterns: Ralph Architecture, CC Mirror Pattern, Domain Isolation, Swarm Patterns.
            </div>
          </div>
          <div class="path-step">
            <div class="path-number">4</div>
            <div class="path-content">
              <strong>Embrace Autonomy</strong><br>
              Design systems that: run without supervision, self-correct errors, checkpoint progress, resume from failures, report results when done.
            </div>
          </div>
          <div class="path-step">
            <div class="path-number">5</div>
            <div class="path-content">
              <strong>Build Feedback Loops</strong><br>
              Every system needs: output validation, error detection, quality checks, self-correction triggers, human review gates (used sparingly).
            </div>
          </div>
        </div>

        <h3 class="font-semibold text-lg mb-4 mt-8">The Capability Ladder</h3>

        <div class="code-block">
          <button class="copy-btn" onclick="copyCodeBlock(this)">
            <i data-lucide="copy" class="w-3 h-3"></i>
            Copy
          </button>
          <pre>Level 1: Single prompt
         "Write a function that..."

Level 2: Prompt chain
         "First analyze, then design, then implement"

Level 3: Single agent with tools
         Agent reads code, edits, runs tests

Level 4: Multi-agent orchestration
         Orchestrator coordinates specialist workers

Level 5: Autonomous systems
         Self-managing agent swarms with learning</pre>
        </div>

        <p class="text-text-secondary mt-4">
          Most practitioners jumped from Level 1 to Level 3 without mastering Level 2. That's fine. Level 2 was a bridge. But going from Level 3 to Level 4 requires genuinely new thinking.
        </p>

        <div class="checkpoint-box">
          <div class="checkpoint-title">
            <i data-lucide="check-circle" class="w-4 h-4"></i>
            Checkpoint: Identify Your Current Level
          </div>
          <div class="checkpoint-content">
            <strong>Self-assessment:</strong><br><br>
            Level 1: You copy-paste prompts, tweak wording<br>
            Level 2: You manually sequence multiple prompts<br>
            Level 3: You use Claude Code with file/bash access<br>
            Level 4: You spawn workers, manage task dependencies<br>
            Level 5: Agents run overnight, self-correct, compound<br><br>
            <strong>Your next step based on level:</strong><br>
            Level 1-2: Start using Claude Code CLI<br>
            Level 3: Try Ralph pattern (overnight loop)<br>
            Level 4: Implement CC Mirror or Gas Town<br>
            Level 5: You're building your own orchestrator
          </div>
        </div>
      </section>

      <!-- Section 6: GOTCHAS -->
      <section id="gotchas" data-activity="gotchas">
        <h2 class="section-title">
          <span class="section-number">6</span>
          Gotchas
        </h2>

        <p class="text-text-secondary mb-6">
          Common pitfalls when transitioning from prompt engineering to agent engineering:
        </p>

        <div class="gotcha-box">
          <div class="gotcha-title">
            <i data-lucide="alert-triangle" class="w-4 h-4"></i>
            Falling Back to Prompt Tweaking
          </div>
          <div class="gotcha-detail"><strong>Symptom:</strong> You spend 30+ minutes rewording a prompt trying to get better output</div>
          <div class="gotcha-detail"><strong>Cause:</strong> Old habits die hard. Prompt engineering instincts are strong.</div>
          <div class="gotcha-detail"><strong>Fix:</strong> STOP and ask: "Am I tweaking words or designing systems?" "Would a verification step catch this error?" "Could I decompose this into smaller tasks?"</div>
        </div>

        <div class="gotcha-box">
          <div class="gotcha-title">
            <i data-lucide="alert-triangle" class="w-4 h-4"></i>
            Over-Engineering Agent Systems
          </div>
          <div class="gotcha-detail"><strong>Symptom:</strong> You designed an 8-agent orchestration system for a 30-minute task</div>
          <div class="gotcha-detail"><strong>Cause:</strong> Agent thinking doesn't mean agent everything</div>
          <div class="gotcha-detail"><strong>Fix:</strong> Task &lt;30 min? Single agent. Task &lt;2 hours? Ralph. Multi-domain, multi-day? Swarm patterns. Match complexity to workload.</div>
        </div>

        <div class="gotcha-box">
          <div class="gotcha-title">
            <i data-lucide="alert-triangle" class="w-4 h-4"></i>
            Skipping Feedback Loops
          </div>
          <div class="gotcha-detail"><strong>Symptom:</strong> Autonomous system produces garbage because there's no verification</div>
          <div class="gotcha-detail"><strong>Cause:</strong> Autonomy without verification = chaos</div>
          <div class="gotcha-detail"><strong>Fix:</strong> Minimum viable feedback loop: <code>npm run typecheck</code> (catches 80%), <code>npm run test</code> (catches logic errors), output validation (catches hallucinations)</div>
        </div>

        <div class="gotcha-box">
          <div class="gotcha-title">
            <i data-lucide="alert-triangle" class="w-4 h-4"></i>
            Can't Decompose Tasks
          </div>
          <div class="gotcha-detail"><strong>Symptom:</strong> Task seems monolithic. "It's all connected, I can't break it apart."</div>
          <div class="gotcha-detail"><strong>Cause:</strong> Thinking at wrong level of abstraction, or task needs planning first</div>
          <div class="gotcha-detail"><strong>Fix:</strong> List all OUTPUTS the task produces. Each output is a candidate task. Identify dependencies. Group by domain. Each group is a worker's scope.</div>
        </div>

        <div class="gotcha-box">
          <div class="gotcha-title">
            <i data-lucide="alert-triangle" class="w-4 h-4"></i>
            Orchestrator Starts Doing Work
          </div>
          <div class="gotcha-detail"><strong>Symptom:</strong> Your orchestrator agent is reading files, writing code, running commands</div>
          <div class="gotcha-detail"><strong>Cause:</strong> Prompt didn't enforce boundaries, or task seemed "small enough" to do directly</div>
          <div class="gotcha-detail"><strong>Fix:</strong> Add IRON LAW to orchestrator prompt: "You do NOT write code, run commands, read files, edit files, run tests. You ONLY spawn workers, coordinate dependencies, synthesize results."</div>
        </div>

        <div class="gotcha-box">
          <div class="gotcha-title">
            <i data-lucide="alert-triangle" class="w-4 h-4"></i>
            Pattern Selection Paralysis
          </div>
          <div class="gotcha-detail"><strong>Symptom:</strong> You understand concepts but freeze when choosing between Ralph, CC Mirror, Gas Town</div>
          <div class="gotcha-detail"><strong>Cause:</strong> Too many options, unclear criteria</div>
          <div class="gotcha-detail"><strong>Fix:</strong> Quick selector: No clear "done" criteria? Single session exploration first. Can finish in one context window? Single session. Multi-domain? CC Mirror. Need parallelism? Git Worktrees.</div>
        </div>
      </section>

      <!-- Section 7: WHAT'S HARD -->
      <section id="hard" data-activity="hard">
        <h2 class="section-title">
          <span class="section-number">7</span>
          What's Hard
        </h2>

        <p class="text-text-secondary mb-6">
          These are fundamental tensions in the transition, not bugs to fix:
        </p>

        <div class="hard-box">
          <div class="hard-title">
            <i data-lucide="flame" class="w-4 h-4"></i>
            Clear Instructions Still Matter
          </div>
          <div class="hard-detail"><strong>The tension:</strong> You stopped obsessing over prompt wording, but agents still need clear instructions. The difference: now it's at system level, not sentence level.</div>
          <div class="hard-detail"><strong>Symptoms:</strong> Workers misunderstand tasks. Orchestrator doesn't coordinate properly.</div>
          <div class="hard-detail"><strong>Mitigation:</strong> Write CLAUDE.md files. Define acceptance criteria. Specify verification commands. Instructions live in files, not ephemeral prompts.</div>
        </div>

        <div class="hard-box">
          <div class="hard-title">
            <i data-lucide="flame" class="w-4 h-4"></i>
            Humans Still Define Goals
          </div>
          <div class="hard-detail"><strong>The tension:</strong> Agent engineering reduces human involvement but doesn't eliminate it. You still define what "done" means. You still set quality standards.</div>
          <div class="hard-detail"><strong>Symptoms:</strong> Agents complete tasks that don't match your intent. "It did what I said, not what I meant."</div>
          <div class="hard-detail"><strong>Mitigation:</strong> Invest more time in PRD/specification. Write better acceptance criteria. Review completed work before next iteration.</div>
        </div>

        <div class="hard-box">
          <div class="hard-title">
            <i data-lucide="flame" class="w-4 h-4"></i>
            Task Decomposition Is a Skill
          </div>
          <div class="hard-detail"><strong>The tension:</strong> There's no formula for how small tasks should be. Too big = context overflow. Too small = overhead dominates. Wrong order = broken dependencies.</div>
          <div class="hard-detail"><strong>Symptoms:</strong> Tasks fail mid-execution. Progress is slower than single agent. You're debugging decomposition, not code.</div>
          <div class="hard-detail"><strong>Mitigation:</strong> Start conservative (smaller tasks). Learn your codebase's grain. Review iteration logs to see what worked. Accept that you'll improve over time.</div>
        </div>

        <div class="hard-box">
          <div class="hard-title">
            <i data-lucide="flame" class="w-4 h-4"></i>
            Context Still Needs Management
          </div>
          <div class="hard-detail"><strong>The tension:</strong> You escaped prompt-level context management, but now you have system-level context management. Where does state live? How do agents share knowledge?</div>
          <div class="hard-detail"><strong>Symptoms:</strong> Agents repeat solved problems. Knowledge doesn't transfer between workers. Context grows unbounded.</div>
          <div class="hard-detail"><strong>Mitigation:</strong> Use external state (files, git, databases). Keep progress.txt under 20KB. Archive permanent learnings to CLAUDE.md.</div>
        </div>
      </section>

      <!-- Section 8: WHEN TO TRANSFORM -->
      <section id="when" data-activity="when">
        <h2 class="section-title">
          <span class="section-number">8</span>
          When to Transform / When Not
        </h2>

        <div class="when-grid">
          <div class="when-use">
            <div class="when-title">
              <i data-lucide="check" class="w-5 h-5"></i>
              MAKE THE SHIFT WHEN
            </div>
            <div class="when-item">
              <i data-lucide="check" class="w-4 h-4 flex-shrink-0"></i>
              <span>Tasks exceed what you can complete in 30 minutes of focused prompting</span>
            </div>
            <div class="when-item">
              <i data-lucide="check" class="w-4 h-4 flex-shrink-0"></i>
              <span>You find yourself babysitting AI output constantly</span>
            </div>
            <div class="when-item">
              <i data-lucide="check" class="w-4 h-4 flex-shrink-0"></i>
              <span>Work stops when you walk away from the keyboard</span>
            </div>
            <div class="when-item">
              <i data-lucide="check" class="w-4 h-4 flex-shrink-0"></i>
              <span>You want "ship while you sleep" capability</span>
            </div>
            <div class="when-item">
              <i data-lucide="check" class="w-4 h-4 flex-shrink-0"></i>
              <span>Tasks have verifiable acceptance criteria (tests, typecheck)</span>
            </div>
            <div class="when-item">
              <i data-lucide="check" class="w-4 h-4 flex-shrink-0"></i>
              <span>You're iterating on the same prompt more than 3 times</span>
            </div>
          </div>

          <div class="when-not">
            <div class="when-title">
              <i data-lucide="x" class="w-5 h-5"></i>
              STAY WITH PROMPTS WHEN
            </div>
            <div class="when-item">
              <i data-lucide="x" class="w-4 h-4 flex-shrink-0"></i>
              <span>Quick one-off questions or explanations</span>
            </div>
            <div class="when-item">
              <i data-lucide="x" class="w-4 h-4 flex-shrink-0"></i>
              <span>Exploratory work with no defined end state</span>
            </div>
            <div class="when-item">
              <i data-lucide="x" class="w-4 h-4 flex-shrink-0"></i>
              <span>Tasks requiring real-time human judgment</span>
            </div>
            <div class="when-item">
              <i data-lucide="x" class="w-4 h-4 flex-shrink-0"></i>
              <span>Creative brainstorming where "wrong" doesn't exist</span>
            </div>
            <div class="when-item">
              <i data-lucide="x" class="w-4 h-4 flex-shrink-0"></i>
              <span>Setup overhead exceeds task duration</span>
            </div>
            <div class="when-item">
              <i data-lucide="x" class="w-4 h-4 flex-shrink-0"></i>
              <span>No verification possible (subjective quality)</span>
            </div>
          </div>
        </div>

        <h3 class="font-semibold text-lg mb-4">What Stays the Same</h3>

        <p class="text-text-secondary mb-6">
          Not everything changed:
        </p>

        <ul class="list-disc pl-6 text-text-secondary space-y-2 mb-8">
          <li><strong>Clear instructions still matter</strong> - they just live at system level now</li>
          <li><strong>Context still needs management</strong> - external state instead of context window</li>
          <li><strong>Quality still needs verification</strong> - automated verification instead of human review</li>
          <li><strong>Humans still define goals</strong> - we're orchestrators, not obsolete</li>
        </ul>

        <div class="core-abstraction">
          <div class="text-center text-lg font-semibold text-text-primary mb-4">The Bottom Line</div>
          <div class="text-center text-text-secondary">
            <strong>Prompt Engineering:</strong> Human art of talking to AI<br><br>
            <strong>Agent Engineering:</strong> Human art of designing AI systems<br><br>
            The question is no longer "What should I say?"<br>
            The question is now <span class="text-accent font-semibold">"What should I build?"</span>
          </div>
        </div>
      </section>

    