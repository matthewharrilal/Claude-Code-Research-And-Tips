# Independent Pipeline & Skills Evaluation

**Evaluator:** Fresh-eyes Opus agent (Task #3)
**Date:** 2026-02-27
**Method:** Read only source files listed in brief. Zero prior analysis consulted.

---

## A. SKILL INVOCATION — Does /build-page invoke the skills?

**TC Skill:** NO. /build-page does NOT invoke /tension-composition. The pipeline replaced TC's 5-phase process with two dedicated agents: Content Analyst (Phase 0) + Brief Assembler (Phase 1). The TC brief template (`artifact-tc-brief-template.md`) is a 236-line static template that the Brief Assembler fills in — it is NOT generated by running the TC skill. The artifact-routing.md explicitly describes the "old vs new TC brief" transition: old = TC generates 99-line brief with CSS values; new = Brief Assembler merges template + content map (~100-165 lines).

**PA Skill:** PARTIALLY. /build-page does not invoke /perceptual-auditing as a skill. However, it directly uses the PA question definitions and deployment protocol from files that MIRROR the PA skill's content (pa-questions.md, pa-deployment.md, pa-weaver.md, pa-guardrails.md). The skill content was extracted INTO the pipeline artifacts.

**Evidence from actual builds:** Both execution trackers (yegge-gas-town, molly-panopticon) show zero references to `/tension-composition`, zero Skill tool invocations, zero TC skill mentions. The pipeline runs Content Analyst + Brief Assembler agents instead.

**Verdict:** The skills are NOT invoked. The pipeline evolved independently and absorbed their content into dedicated artifacts.

## B. SKILL QUALITY — Independent Assessment

### Tension-Composition Skill (~1,650 lines)

**Genuinely insightful:**
- The FEEL/UNDERSTAND/DO/BECOME axis framework is a real contribution — it systematizes content analysis that designers do intuitively
- The Addition Test (genuine vs cosmetic tension) is sharp and useful
- The "construction, not discovery" framing is philosophically honest and practically important
- Perceptual Risk assessment (3.5E) captures a genuine insight: structural richness does NOT predict visual quality
- The 6-criterion Metaphor Quality Rubric (3.5G) with binary rejection checks is well-designed

**System-specific (valuable only within KortAI):**
- The Personality Profile (75% austere, 95% angular, etc.) and Domain Search Menu are tightly coupled to this system
- Incompatible Metaphor Families (organic, liquid, atmospheric) are constraints of the specific soul rules

**Bloat:**
- Phase 4 (~800 lines) duplicates much of what the builder recipe already specifies
- Guardrails section repeats perception thresholds from the PA skill
- The "Standalone Appendix" concept adds complexity for a mode that is apparently never used
- Excessive worked examples (geological core sample appears 5+ times)

**Assessment:** The first 700 lines (Phases 0-3.5) are genuinely valuable methodology. Phase 4+ is mostly redundant with pipeline artifacts.

### Perceptual-Auditing Skill (~770 lines)

**Genuinely insightful:**
- The "One Rule" (react before you check) and Fresh-Eyes Principle are non-obvious and battle-tested
- PA-05's 4 sub-criteria (DESIGNED/COHERENT/PROPORTIONATE/POLISHED) are a real measurement framework
- Tier 4 Void Prevention questions were derived from actual failure (ceiling experiment) — these are hard-won
- The severity calibration (LOOKS-WRONG / WOULD-NOT-SHIP / CATASTROPHIC) is practical
- S-09 stacking check catches a real failure mode that individual-property checks miss

**System-specific:**
- Metaphor-awareness principles and metaphor failure root-cause diagnosis are KortAI-specific
- Weaver calibration tables (multi-coherence scale, metaphor expression spectrum) are system-specific

**Bloat:**
- Minimal — this skill is leaner and more focused than TC. Most content earns its place.
- The Tier 5 questions (PA-60 through PA-68) have honest "epistemic status: INITIAL HYPOTHESES" — refreshingly honest.

**Assessment:** Well-designed measurement framework. The questions are concrete, the scoring is binary, the principles are sound. This is the stronger of the two skills.

## C. PIPELINE ARCHITECTURE

**How it actually works:**
1. Content Analyst (Opus) reads raw content, produces ~50-line Content Map
2. Brief Assembler (Opus) merges Content Map + 236-line TC Brief Template into ~100-165-line Execution Brief
3. Pass A Builder (Opus) writes structural HTML/CSS using the brief + recipe
4. Orchestrator runs structural gate check
5. Pass B Builder (DIFFERENT Opus) enriches CSS (add-only)
6. Orchestrator captures screenshots + runs 57 programmatic gates via Playwright JS
7. 9 PA Auditors (parallel Opus) evaluate screenshots with assigned questions
8. Integrative Auditor synthesizes
9. Weaver issues verdict: RELEASE / POLISH / IMPROVE / RETHINK
10. If IMPROVE: different Opus builder receives artistic impressions only (not scores), full re-audit

**Strengths:**
- Two-pass build with DIFFERENT agents defeats continuation bias — this is a real insight
- IMPROVE builder receives artistic language, not gate scores — prevents metric-chasing
- 9 parallel PA auditors with thematic specialization is genuinely more thorough than 1-2 auditors
- The Observer (independent compliance monitor) running full lifecycle is good process design
- Screenshot pre-capture eliminates Playwright contention — practical engineering solution
- Brief Verification gates (BV-01 through BV-07) catch spec problems before they become build problems
- Execution tracker template provides real accountability

**Weaknesses:**
- ~17 agents + 57 gates + 69 PA questions for a single HTML page is heavy. Total runtime ~90-120 min.
- The Brief Assembler is doing what TC's Phases 0-3.5 did, but compressed into a template fill-in exercise. Metaphor derivation is now the Content Analyst's job in ~15 min, replacing what TC designed as a 5-phase process.
- Gate runner code is 3,185 lines of Playwright JS — maintenance burden is substantial.

## D. SKILL vs ARTIFACT RELATIONSHIP

The artifacts EVOLVED FROM the skills but then REPLACED them. The pipeline did not merely extract skill content — it restructured it:

- TC's 5-phase metaphor derivation became: Content Analyst (content map) + Brief Assembler (template merge). The deliberate multi-phase process was compressed into two agent prompts.
- PA's question bank was extracted verbatim into pa-questions.md. The deployment protocol was extracted into pa-deployment.md. The weaver protocol into pa-weaver.md. This is genuine extraction, not duplication.
- The skills still provide value as REFERENCE DOCUMENTS for understanding WHY the pipeline does what it does. The TC skill's provenance notes (which experiments failed and why) are the institutional memory.
- The skills are NOT duplicates of the artifacts — they serve different purposes (skill = methodology explanation, artifact = operational instruction).

## E. WHAT THE SYSTEM GETS RIGHT

1. **Binary rules over judgment calls.** The entire system is built on this principle and it works. Soul constraints, gate checks, PA questions — all binary.
2. **Perception thresholds as physics, not preference.** The minimum deltas (15 RGB, 0.025em letter-spacing, 120px stacked gap) are empirically derived from actual failures. This is real design engineering.
3. **Fresh-eyes auditing.** PA auditors receive ONLY screenshots and questions. Zero build context. This produces honest assessment. The contrast with build-context-loaded auditors is documented and real.
4. **Iteration as the standard path.** The pipeline assumes Cycle 0 will need improvement. IMPROVE is the expected outcome, not a failure. This is architecturally honest about LLM generation quality.
5. **Recipe over checklist.** The distinction between "Read/Select/Deploy/Assess" (recipe verbs) and "Verify/Fail if/Must be" (checklist verbs) in builder instructions is a genuine finding that drives real quality differences.
6. **The soul constraints are GENERATIVE.** border-radius:0, box-shadow:none, no gradients — these are not arbitrary. They force designers to use spacing, borders, and backgrounds for hierarchy. The constraints create a distinctive visual identity.
7. **Anti-gravity mechanisms.** Phase-gated library access, divergence mandates, anti-prescription framing — these address a real problem (LLM pattern-matching tendency).

## F. WHAT THE SYSTEM GETS WRONG

1. **Enormous infrastructure-to-output ratio.** The MANIFEST alone is ~1,300 lines. Add 9 artifacts, split gate runner (5 files), split PA protocol (6 files), templates, and you have ~10,000+ lines of pipeline infrastructure to produce one HTML page. The meta-complexity is disproportionate.
2. **TC skill is effectively dead code.** ~1,650 lines of methodology that the pipeline does not invoke. It is a historical document masquerading as an active skill. The trigger phrases in its frontmatter ("tension composition", "derive a layout") would invoke it, but /build-page has its own path that bypasses TC entirely.
3. **Unvalidated Tier 5 questions.** The PA skill honestly labels them "INITIAL HYPOTHESES" but the pipeline treats them as if validated (assigns them to auditors, scores them, uses them for verdicts). N=2 builds is not enough data.
4. **57 gates is likely overtesting.** Some gates are checking the same property at different granularities (container width appears in identity gates, structural checks, and perception thresholds). Consolidation would reduce noise without losing coverage.
5. **The metaphor derivation bottleneck.** The pipeline depends on a Content Analyst deriving a viable metaphor in ~15 minutes. The TC skill's 5-phase process for this was designed to take longer for good reason. The compression may sacrifice derivation quality.
6. **Retina DPR screenshot issues.** Both builds had significant screenshot problems (dark zones in yegge, "catastrophic dark void" false positive in panopticon). This is a practical engineering problem that has NOT been solved despite being documented.

## G. SOUL CONSTRAINTS

The soul constraints in TC skill (Personality Profile, Soul Test) MATCH prohibitions.md. Specifically:
- border-radius: 0 (Prohibition #1) = "100% geometric" and Soul Test "Does this look like Bootstrap? FAIL"
- box-shadow: none (Prohibition #2) = "100% flat"
- No gradients (Prohibition #5) = solid backgrounds only
- Warm palette, font trinity, border-weight hierarchy — all consistent

**Assessment:** These are reasonable design decisions, not arbitrary restrictions. They define a coherent visual identity (sharp, flat, warm, editorial). The constraints are GENERATIVE — they force creative solutions within a distinctive design language. The "Could I swap the accent color to Bootstrap blue and it would fit? FAIL" test is a genuinely useful identity check.

The one questionable constraint is "NEVER use pure black (#000) or pure white (#FFF)." This is reasonable for backgrounds and text but creates edge cases with SVGs, third-party embeds, or code syntax highlighting where pure black may be appropriate.

## H. OVERALL ASSESSMENT

| Component | Rating | Justification |
|-----------|--------|---------------|
| **TC Skill** | MIXED | Phases 0-3.5 = genuinely insightful methodology. Phase 4+ = bloated duplication. Entire skill is effectively bypassed by the pipeline. Value is as reference/documentation, not as operational tool. |
| **PA Skill** | SOLID | Well-designed measurement framework. Questions are concrete, scoring is binary, principles are battle-tested. Content was successfully extracted into pipeline artifacts. Tier 5 questions are honest about their epistemic status. |
| **Pipeline** | SOLID | Architecture is sound. Two-pass build, fresh-eyes auditing, iteration as standard path, recipe-over-checklist — these are real innovations. Weaknesses are proportional (heavy infrastructure) not structural (wrong architecture). |
| **Build-Page Skill** | STRONG | Thin launcher pointing to comprehensive manifest. Does exactly what it should — routes to the right files, lists non-negotiables, specifies execution rules. No bloat. |

**Bottom line:** The pipeline is well-designed and produces real results (PA-05 3.0-3.5 on both actual builds). The TC skill contributed its ideas but is no longer operationally relevant. The PA skill's content was successfully migrated into pipeline artifacts. The infrastructure overhead is high but the architecture is sound. The screenshot/DPR problem is the most pressing practical issue.
