# Attention-Analyst Full Report: Attention Dilution Analysis

**Extracted from:** Session transcript `727db751-33b0-4a4b-95be-80b22c5583ba.jsonl`, line 200882
**Team:** `paradigm-exploration`
**Agent:** `attention-analyst`
**Message type:** SendMessage to `team-lead`
**Timestamp:** 2026-02-22T22:21:xx (approximately, based on surrounding lines)
**Extraction date:** 2026-02-22

---

**Team-lead summary (line 200884):** "First report in. The attention-analyst's key finding: **effective working memory during CSS generation is ~200-400 lines at any moment, and only 5-10% of the 3,700 lines is actively driving CSS decisions at any given token.** But critically â€” attention dilution is fundamental to transformers, but its IMPACT is highly engineerable. The stacked-gap rule was in a section the builder explicitly CITED as influential and it still violated it. That's the gap between 'present in context' and 'actually used.'"

---

# Task #1: Attention Dilution Analysis

## 1. What Does LLM Attention Look Like Over 3,700+ Lines of Input?

### The Actual Input Budget

The builder receives these files in order:

| File | Lines | Role |
|------|-------|------|
| TC Brief (_tc-brief.md) | ~98 | Content-specific design brief |
| Conventions Brief (conventions-brief.md) | 610 | World model / physics |
| Content markdown | ~200-400 | The actual text to design |
| mechanism-catalog.md | 1,218 | Mechanism CSS patterns |
| components.css | 1,195 | Component library |
| tokens.css | 183 | CSS variable values |
| prohibitions.md | 419 | Soul constraints |
| **TOTAL** | **~3,720-3,920** | |

Plus the builder spawn prompt itself is ~130 lines (from SKILL.md lines 93-135), making the full context around 3,850-4,050 lines before the builder writes a single token.

### Attention Is Not Uniform -- It Has Architecture

Transformer attention does not work like a flashlight that dims over distance. It works more like a relevance-weighted associative memory. Key dynamics:

**Positional recency bias.** Information near the END of the context window and near the BEGINNING receives disproportionate attention during generation. This is the well-documented "lost in the middle" phenomenon. The builder's reading order (TC brief -> conventions brief -> content -> reference files -> prohibitions LAST) is actually engineered to exploit this: TC brief gets primacy, prohibitions get recency. But the middle 2,400 lines (mechanism catalog + components.css) are in the attention valley.

**Task-relevance gating.** During CSS generation, the model's attention is driven by what it needs RIGHT NOW. When writing a `.zone-3 .callout` rule, the model attends strongly to: (a) callout-related lines in components.css, (b) zone-3 chromatic values it planned in its transition table, (c) the border-weight vocabulary from conventions-brief Section 8. It does NOT attend uniformly to all 3,700 lines -- it queries specific fragments via self-attention patterns.

**Interference during generation.** This is the critical mechanism. When the model is generating its 500th line of CSS output, its own generated tokens are now in the context, competing for attention with the input. At 800+ lines of CSS output, the model has ~4,500+ total context. The generated output acts as a powerful attractor because it's recent and highly coherent (the model has been building a CSS narrative). The original input gets progressively de-weighted -- not because the attention mechanism forgets it, but because the model's own output becomes a stronger signal.

### Effective Working Memory During CSS Generation

The model's "working memory" during active generation is approximately **200-400 lines of effective utilization** at any given moment. This consists of:

- The most recent 50-100 lines of its OWN generated CSS (strongest signal)
- The TC brief / conviction statement (~50-80 lines, if committed to memory early)
- The specific conventions-brief section relevant to the current build phase (~30-50 lines)
- The specific mechanism catalog entries being deployed (~30-50 lines)
- Random fragments from other files activated by semantic association

This is NOT 200-400 lines total from input -- it's 200-400 lines of ACTIVE INFLUENCE on the next generated token. The rest of the context is latent, accessible but not driving behavior.

## 2. Actionable vs Background: The 80/20 Split Is More Like 95/5

Of the ~3,720 reference lines, at any given moment during CSS generation:

**ACTIVELY ACTIONABLE (5-10%, ~185-370 lines):**
- TC brief Section 6 BUILD RECIPE: zone-keyed CSS values (~30 lines)
- Current zone's planned transition from the conviction table (~5 lines)
- The specific mechanism entries being deployed right now (~30-60 lines from catalog)
- The specific component pattern being implemented (~20-40 lines from components.css)
- The perception thresholds being checked (~15 lines from conventions-brief Section 2)
- Current soul constraints for the property being written (~10 lines from prohibitions)

**BACKGROUND CONTEXT (potentially retrievable, ~30-40%):**
- Conventions-brief sections not currently relevant (~400 lines)
- Mechanism catalog entries for mechanisms not being deployed (~900 lines)
- Component patterns not currently being used (~800 lines)
- Token values not currently referenced (~100 lines)

### Evidence: The 4/14 Sections Finding

The builder explicitly named **4 out of 14 conventions-brief sections** as influential:

1. **Section 4 (Multi-Coherence)** -- "the primary driver"
2. **Section 2 (Perception Physics)** -- "forced the most consequential override"
3. **Section 5 (Fractal Echo)** -- guided parametric variation
4. **Section 7 (Transition Grammar)** -- determined transition types

That's 4/14 sections. The other 10 sections (Identity, Richness, Unified Metaphor, CSS Vocabulary, Creative Authority, Quality Floor, Compositional Memory, Five Questions, Restraint List, Accessibility, Responsive Behavior, Token Compliance, Builder Warnings) were either:
- **Absorbed into behavioral default** (Identity constraints became automatic)
- **Effectively invisible** during active CSS generation
- **Redundant** with TC brief instructions

The conventions brief is 610 lines. The 4 influential sections total roughly 180 lines (Section 2: ~60 lines, Section 4: ~85 lines, Section 5: ~80 lines, Section 7: ~45 lines = ~270 lines, but much of that is examples/tables not directly actionable, so ~180 lines of decision-driving content). That's a **30% utilization rate** of the conventions brief, and **~5% of total reference input**.

## 3. "Information Present in Context" vs "Information the Model Is Actually Using"

These are fundamentally different things, and the gap between them is the core of the attention dilution problem.

### The Information-Behavior Gap

**Information present:** The prohibitions file contains 22 prohibitions across 419 lines. Every one is "in context."

**Information used:** The builder's CSS respects the 6 soul constraints (border-radius: 0, box-shadow: none, etc.) because these are dramatic, binary, and reinforced across multiple files. But does the builder use the 12 conditional prohibitions? The evidence suggests many are honored only when they happen to intersect with what the builder was already doing.

**The mechanism:** A transformer model doesn't "know" information in context the way a human knows a fact they've read. It has ACCESS to information through attention patterns during token generation. Whether that access produces behavioral influence depends on:

1. **Relevance activation:** Does the current generation step "query" for that information? Writing a border rule activates border-related context. Writing a padding rule does not activate border context, even though border rules are 3 lines away in the same file.

2. **Salience competition:** Even if activated, does the information win the attention competition? The builder's own generated CSS, being recent and highly coherent, is an extremely strong competitor. A subtle guideline from line 400 of the conventions brief that says "no stacked gaps above 120px" competes poorly against the momentum of the builder's current CSS pattern.

3. **Encoding depth:** Information that was processed early during a dedicated "reading" phase (the TC brief, read first) gets deeper encoding than information read later in a growing context. The builder's explicit instruction to read files "IN THIS ORDER" is an attempt to control encoding depth, but the mechanism catalog at position 4 of 7 is squarely in the attention valley.

### Evidence From This Project

The Gas Town builder's SC-10 violation is the perfect case study. The stacked gap at the Z3->Z4 boundary accumulated to ~150px. The builder's self-challenge (build log line 200) explicitly identified this contradiction with its own conviction statement. The information "no stacked gaps above 120px" was in Section 2 of the conventions brief -- one of the 4 sections the builder CITED as influential. And yet the violation happened anyway.

Why? Because the stacked gap threshold is a COMPOSITE measurement (section-bottom padding + divider margins + section-top padding). The builder set each INDIVIDUAL value within bounds (32px + checkpoint bar + 48px), but the sum violated the threshold. The conventions brief explains this (line 61: "Measure the total, not the parts"), but this explanatory sentence has near-zero salience during the moment the builder is writing `.zone-4 { padding-top: 48px; }`. At that moment, the builder is attending to its own zone-4 CSS pattern, the planned spatial values from its transition table, and the general directive for RESOLVING direction. The composite measurement rule is in context but not in working memory.

## 4. Theoretical Maximum Utilization of Context

### The Theoretical Ceiling

Based on the attention dynamics above, the theoretical maximum utilization for a 3,700-line input during an 800-1500 line CSS generation task is approximately **40-50%** of input lines having SOME influence on SOME generated token. This is not the same as all 40-50% being influential simultaneously -- it's the aggregate across the full generation run.

The breakdown:
- **~30% is inherently redundant or inapplicable.** The mechanism catalog has 18 mechanisms. A page deploys 14-15. The 3-4 unused mechanisms and their detailed CSS examples (~200 lines) are pure overhead. Similarly, components.css has patterns the builder will never use for this content.
- **~20-25% is absorbed into default behavior** rather than consulted as reference. Soul constraints, once read, become part of the model's generative policy. The builder doesn't re-attend to "border-radius: 0" when writing each rule -- it simply never generates border-radius values. This is UTILIZATION (the information shaped behavior) but not ATTENTION (the information is not actively queried).
- **~15-20% is in the "lost in the middle" zone** and has minimal influence despite being relevant. This is where the dilution is most costly -- relevant information that the model doesn't retrieve because it's buried.
- **~5-10% drives specific CSS decisions at specific moments** -- this is the "hot" utilization where a reference line directly shapes a generated token.

### A Key Distinction: Reading-Phase vs Generation-Phase Utilization

The builder has two phases: READING (consuming the input files) and GENERATING (writing HTML/CSS). Utilization dynamics are radically different:

**During reading:** The model processes each line with relatively uniform attention. The conventions brief's philosophical framing ("richness = semantic density x restraint x spatial confidence") is fully processed and understood. The model builds an internal representation.

**During generation:** That internal representation competes with the mounting pressure of its own output. The philosophical framing is no longer attended to AS TEXT -- it exists only as whatever influence it had on the internal representation built during reading. If the influence was shallow (understood but not deeply integrated), it fades. If deep (genuinely altered the model's approach to composition), it persists.

This is why the TC brief's BUILD RECIPE (Section 6) -- which is actionable, zone-keyed, with specific CSS values -- has higher generation-phase utilization than the conventions brief's philosophical sections. Recipes survive the reading-to-generation transition. Philosophy doesn't.

## 5. Is This Fundamental or Engineerable?

### What's Fundamental (Transformer Architecture)

1. **Quadratic attention dilution.** Self-attention distributes probability mass across all context positions. More context = less mass per position on average. This is inherent to softmax attention and won't change without architectural innovations.

2. **Generation-phase drift.** The model's own output inevitably competes with input for attention. This is not a bug -- it's how autoregressive generation maintains coherence. But it means long generation runs progressively de-weight input.

3. **Lost in the middle.** Primacy and recency biases in attention are well-documented across transformer architectures. Middle positions are structurally disadvantaged.

### What's Engineerable (Within Current Architecture)

1. **Input ordering.** Already partially exploited: TC brief first (primacy), prohibitions last (recency). But the mechanism catalog and components.css -- the builder's actual CSS vocabulary -- are in the attention valley. **ENGINEERABLE FIX:** Split reference files into "pre-read" (before generation) and "just-in-time" (inserted at relevant moments during generation).

2. **Compression and pre-computation.** The TC brief is already a compression mechanism: it pre-computes the "conversation" that the builder would need to have about content analysis. The conventions brief could undergo similar compression. Currently 610 lines; the builder effectively uses ~180 lines. A zone-keyed "builder cheat sheet" of 100 lines could capture 90% of the behavioral influence.

3. **Structured retrieval prompts.** Instead of giving the builder all reference files upfront, the orchestrator could inject context at decision points: "You are now at boundary Z2->Z3. Your planned direction is DEEPENING. Here are the relevant multi-coherence thresholds and the component patterns for dense zones: [50 lines of targeted context]." This is essentially RAG (retrieval-augmented generation) applied to the build process.

4. **Generation checkpoints.** The midpoint micro-gate (SKILL.md Section 3.1) is already a prototype. Expanding this to boundary-level checkpoints would force the builder to re-attend to input at each zone transition, counteracting generation-phase drift. The self-challenge mechanism in fix cycles (line 196-202 of the build log) demonstrates this works: the builder discovered its own violation when forced to re-read its conviction statement.

5. **Duplicate key information.** Instead of stating "stacked gaps <= 120px" once in Section 2 of the conventions brief, embed it in the TC brief's BUILD RECIPE for EACH boundary, embed it in the midpoint gate, and embed it in the self-check questions. Redundancy counteracts dilution. The cost is token overhead; the benefit is behavioral compliance.

### The Most Engineerable Intervention

The single highest-leverage change: **replace the monolithic 610-line conventions brief with a ~80-line zone-keyed recipe that is generated PER PAGE by the TC analyst.** The TC agent already reads the full conventions brief. Let the TC agent compress it into page-specific instructions:

```
ZONE 2 BUILD RECIPE:
- Background: #F0EBE3 (delta from Z1: 18 RGB -- PASS)
- Padding: 48px (Z1 was 64px -- DEEPENING)
- Font-size: body stays 16px, headings drop to 2rem (from 2.5rem)
- Border: 3px border-top #E83025 at boundary
- Components: bento grid (mechanism #15), 2-zone callouts
- Stacked gap budget: Z1 bottom (20px) + border (3px) + Z2 top (48px) = 71px (PASS, max 120px)
```

This shifts the conventions brief from "world model the builder must internalize" to "pre-computed values the builder deploys." The builder gets RECIPES, not PHILOSOPHY. The evidence from this project is overwhelming: recipes produce compliance; philosophy produces nice reflections but not CSS behavior.

### Summary

| Question | Answer |
|----------|--------|
| How does attention decay over 3,700 lines? | Not linear decay but relevance-gated retrieval, degraded by generation-phase competition from the builder's own output. Effective working memory is ~200-400 lines at any moment. |
| Actionable vs background? | ~5-10% drives specific CSS decisions at any moment. ~30% is the aggregate across the full build. ~50-60% is effectively invisible during generation. |
| Present vs used? | Vast gap. 4/14 conventions-brief sections cited as influential = 30% section utilization. The stacked-gap rule was in a "cited" section and STILL violated. |
| Maximum utilization? | ~40-50% of lines having SOME influence on SOME token, aggregated across full build. Simultaneous utilization is 5-10%. |
| Fundamental or engineerable? | Attention dilution is fundamental to transformers. But the IMPACT is highly engineerable: pre-compute zone-keyed recipes, inject context at decision points, checkpoint-force re-attention, use redundancy strategically. The pipeline already has prototypes of all four strategies. |
