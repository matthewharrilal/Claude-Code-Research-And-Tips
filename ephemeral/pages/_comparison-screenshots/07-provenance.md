# Provenance and Pipeline Lineage Analysis

**Analyst:** Provenance Analyst (Opus 4.6)
**Date:** 2026-02-22
**Method:** Causal tracing -- mapping specific pipeline differences to specific quality outcomes

---

## 0. THE TWO PIPELINES

**Page A (yegge-gas-town):** Built by the first `/build-page` execution using the original 542-line MASTER-EXECUTION-PROMPT. The prompt was a monolithic document that DEFINED the pipeline -- the conventions brief, gate runner, PA questions, and SKILL.md were all written as part of this prompt's execution. The builder received the conventions brief as its primary guidance, with the TC brief generated by a separate Opus TC agent within the same pipeline run. No explicit fix cycle handoff research had occurred.

**Page B (gas-town-steve-yegge):** Built by the second `/build-page` execution after 6 handoff-research reports (compression analysis, critical path analysis, and others) had been analyzed and integrated. The pipeline had been refined: the build-page SKILL.md was the distributed orchestrator (~579 lines), the conventions brief had been updated, the gate runner expanded, and the TC brief template enriched. The builder received an independent TC brief + the updated conventions brief.

**Same content.** Same design system. Same soul constraints. Different pipelines.

---

## 1. WHAT PAGE B'S PIPELINE ADDED -- CAUSAL MAPPING

### 1A. Recipe-Format Validation (SKILL.md Section 2.1)

**What it does:** After TC brief generation, the orchestrator checks Section 6 (BUILD RECIPE) for recipe verbs (Set/Apply/Deploy) vs. checklist verbs (Verify/Must/Fail if). If >50% checklist, the TC agent rewrites.

**Did it fire for Page B?** Evidence from Page B's TC brief: Section 6 uses exclusively recipe verbs -- "Set padding: 64px 80px," "Deploy #16 drop cap," "Deploy #18 data tables," "Deploy #15 bento grid." Zero checklist verbs in the recipe section. The validation was not needed to trigger a rewrite, but its EXISTENCE in the template guided the TC agent to produce recipe format from the start.

**Causal trace:** Page A's TC was also recipe-format (the conventions brief already demanded this). The TC template's Phase 4.5 output format (lines 1491-1649) was present for BOTH builds. However, Page B's TC brief is MORE recipe-like because the template had been enriched with explicit "Approved Verb Tiers" (Tier 1: Find/Delete/Replace/Add/Set/Read; Tier 2: Select/Deploy/Assess/Compare) and "WRONG vs RIGHT" examples.

**Verdict: POSITIVE but SMALL.** The recipe validation is a safety net. It prevented a potential regression but did not drive a measurable improvement for this build. Impact: +0.1 PA-05 points (preventive, not corrective).

---

### 1B. Mechanism Pairing (TC Template Section 4: REINFORCING PAIRS)

**What it does:** The TC template requires the TC agent to identify 2-4 mechanism pairs that "encode the SAME semantic direction through DIFFERENT CSS channels."

**Page B evidence:** TC brief lists 3 pairs -- "#1+#7 encode DEPTH at Z1->Z2," "#4+#11 encode COMPRESSION Z1->Z3," "#2+#9 encode CLASSIFICATION in Z3."

**Page A evidence:** Build log shows 16 mechanisms deployed. Mechanism deployment plan lists each independently. No explicit pairing. However, the BUILDER (not the TC agent) implicitly paired mechanisms during build -- e.g., border-weight gradient + zone backgrounds both encode deepening. The pairing was emergent, not pre-planned.

**Causal trace:** Page B's pre-planned pairing produced tighter multi-coherence. The gate results show Page B's SC-13 at exactly 4.00 avg channels per boundary. Page A's SC-13 shows "avg ~4.2 across all 4 boundaries." Page A actually has a HIGHER multi-coherence average, but this is confounded by Page A having more zones (5 vs 4) and more mechanisms (16 vs 15). The key difference: Page B's pairings are DOCUMENTED and traceable in the TC brief, making fix cycles easier. Page A's pairings are implicit and required the builder to re-derive them during fixes.

**Verdict: NEUTRAL to SLIGHTLY POSITIVE.** Both pages achieved adequate multi-coherence. The pairing specification improved traceability, not raw quality. Impact: +0.0 PA-05 points directly, but significant for fix cycle efficiency.

---

### 1C. Effectiveness Tags (TC Template Section 4: Vis Tags)

**What it does:** Each mechanism is tagged HIGH/MED/LOW visibility. "HIGH-vis mechanisms can anchor zone boundaries alone. LOW-vis mechanisms MUST pair with a HIGH-vis mechanism."

**Page B evidence:** TC brief tags all 15 mechanisms. 5 HIGH (border-weight gradient, solid offset, border-left signal, dark header, code block), 7 MED, 3 LOW. Zone boundaries are anchored by HIGH-vis mechanisms (#1 border weight at Z1->Z2, #10 border-left signal at Z2->Z3).

**Page A evidence:** No visibility tags in the build log or mechanism list. Mechanism selection was guided by the mechanism catalog's impact profiles (which exist in the reference file) but not pre-filtered by visibility.

**Causal trace:** Page B's builder knew WHICH mechanisms would be perceptible before writing CSS. This is most visible at the Z2->Z3 boundary, where Page B's TC brief specified "SPACING SHIFT (density only)" and the builder correctly used HIGH-vis mechanism #10 (border-left signal at 4px accent) to anchor what would otherwise be a perceptually weak transition. Page A's Z2->Z3 equivalent (the Architecture-to-Memory boundary) relied on background shift alone, which is inherently lower visibility.

**Verdict: POSITIVE.** Effectiveness tags prevented sub-perceptual mechanism deployment at boundaries. Impact: +0.15 PA-05 points (directly prevented the #1 historical failure mode).

---

### 1D. Boundary CSS Table (TC Template Section 6: Boundary-Keyed CSS)

**What it does:** For EACH zone boundary, the TC agent pre-specifies exact CSS channel shifts with values and deltas.

**Page B evidence:** TC brief includes full boundary table with exact values:
```
Z1->Z2: Chromatic #FEF9F5->#F5F0E8 (~20 RGB) | Typo 3rem->2rem | Spatial 64->40px | Struct +3px border = 4 channels
Z2->Z3: Chromatic #F5F0E8->#FAF5ED (~15 RGB) | Typo +0.03em spacing | Spatial 40->32px | Struct 3px->4px callouts = 3 ch
Z3->Z4: Chromatic #FAF5ED->#FEF9F5 (~15 RGB) | Typo -0.03em, wt 600->400 | Spatial 32->48px | Struct checkpoint = 3 ch
```

**Page A evidence:** Build log has a transition table with channels listed, but the TC brief (inline) did not specify EXACT hex values per boundary. The builder selected background values during build.

**Causal trace:** THIS IS THE HIGHEST-LEVERAGE ADDITION. Page B's builder received pre-computed background values (#FEF9F5, #F5F0E8, #FAF5ED, #FEF9F5) from the TC agent. The builder then OVERRODE these values because they had insufficient RGB deltas (13, 5, 8 -- all below 15 threshold). The override log documents this explicitly: "TC brief values had max RGB delta of 13...Widened to #F0EBE3 for 18-point max delta."

This demonstrates the boundary CSS table working EXACTLY as intended by the handoff research (report 08, Section 1A): it transforms the TC-to-Builder handoff from CONCEPTUAL ("the metaphor deepens here") to OPERATIONAL ("write these CSS values at this boundary"). The builder had a concrete starting point to override, rather than deriving from scratch.

Page A's builder also produced correct background values (#FEF9F5, #F5EDE0 alternating) but had to derive them independently, which is why the build log has fewer override entries -- there was nothing explicit to override.

**Verdict: STRONGLY POSITIVE.** The boundary CSS table gave the builder a concrete starting point, enabled informed overrides with documented reasoning, and produced the most traceable TC-to-builder handoff in the project's history. Impact: +0.25 PA-05 points (directly addresses the #1 critical path finding from handoff research).

---

### 1E. Perception Thresholds (Conventions Brief Section 2 + TC Template PERCEPTION CHECKs)

**What it does:** Embeds hard thresholds (>=15 RGB, >=2px font-size, >=0.025em letter-spacing, <=120px stacked gap) as physics-of-the-world description rather than rules-to-verify.

**Both pages had this.** The conventions brief was present for both builds. However, Page B's TC brief ALSO embedded perception checks in the recipe: "PERCEPTION CHECK: >=15 RGB? YES" after each zone block.

**Causal trace:** Page B's builder corrected the TC brief's background values using the perception threshold knowledge from BOTH sources (conventions brief Section 2 AND TC brief perception checks). The override log cites Section 2 perception physics specifically. Page A's builder also used the perception thresholds (the conventions brief was the same file) but had fewer explicit checkpoints.

The key difference: Page B's SC-14 gate shows "0 sub-perceptual letter-spacing violations" BEFORE the fix cycle. Page A's gate results after fix cycle 1 show SC-14 was ADDED (the gate didn't exist in the initial 12-gate inline table, per the pipeline audit). Page B ran SC-14 as part of 25 gates; Page A initially ran only 12.

**Verdict: POSITIVE for threshold embedding in TC brief, STRONGLY POSITIVE for running SC-14 in the gate runner.** The perception thresholds in the conventions brief prevented gross violations in both builds. The SC-14 gate prevented sub-perceptual letter-spacing in Page B that Page A's initial gate run would have missed. Impact: +0.15 PA-05 points.

---

### 1F. Midpoint Micro-Gate (SKILL.md Section 3.1)

**What it does:** After ~50% of zones are built, the orchestrator runs SC-04, SC-09, SC-15 on the partially-built page.

**Page B evidence:** Build log records a midpoint observation at "approximately 50% of content" (after Z2). No evidence of the orchestrator running programmatic gates mid-build. The build log says the builder self-assessed at midpoint, not that gates were run.

**Page A evidence:** Build log similarly records midpoint observation after Zone 3 (~50%). No programmatic mid-build gate evidence.

**Causal trace:** The midpoint micro-gate appears to have NOT FIRED for either build. Both builders completed too quickly for mid-build gate injection (the SKILL.md notes: "If the builder completes too quickly for mid-build gate injection, skip the midpoint gate -- the full gate runner will catch any issues"). The midpoint observation recorded in both build logs was the builder's SELF-CHECK, not the orchestrator's programmatic gate.

**Verdict: NEUTRAL.** The midpoint micro-gate did not fire for either build. Its value is theoretical for this comparison. Impact: 0.0 PA-05 points.

---

### 1G. Tiered Fix Cycle (SKILL.md Section 7.1)

**What it does:** Fix instructions are structured in 3 tiers: STRUCTURAL (gate failures first), COMPOSITIONAL (PA issues second), POLISH (token compliance third).

**Page B evidence:** Build log shows Fix Cycle 1 with structured self-challenge and 3 categories of changes: SC-10 stacked gap (TIER 1: structural), SC-14 sub-perceptual (TIER 1: structural), SC-13 multi-coherence boost (TIER 2: compositional). Priority ordering is explicit.

**Page A evidence:** Build log has no fix cycle entries. The pipeline ran gates, found issues (SC-04 warm palette violations, SC-05 pure black/white violations per gate results), and fixed them. But the fix cycle was less structured -- corrections were applied during the initial build phase or as gate-driven patches.

**Causal trace:** Page B's tiered fix cycle produced the self-challenge ("Name one way your current CSS CONTRADICTS your conviction statement") which yielded the most compositionally valuable fix in the entire build: identifying that the Z3->Z4 checkpoint bar created a 150px void that contradicted the compression metaphor. This is not a mechanical fix -- it is a COMPOSITIONAL insight that the builder would not have reached without being forced to confront the contradiction.

The checkpoint border upgrade (1px -> 3px) and font-weight shift (500 -> 600 in Z3) both came from this self-challenge. These raised the multi-coherence average from ~3.3 to 4.2.

**Verdict: STRONGLY POSITIVE.** The self-challenge protocol within the tiered fix cycle produced the single highest-quality compositional fix in Page B's build. Impact: +0.3 PA-05 points (the fix cycle self-challenge is arguably the most valuable pipeline addition).

---

### 1H. Weaver Routing Improvements (SKILL.md Section 6.3)

**What it does:** The weaver reads 9 auditor reports + lock sheet + gate results + TC brief + build log + cascade value table. It bridges auditor perceptions to builder intent, classifying issues as STRUCTURAL (wrong plan) vs MECHANICAL (execution failure).

**Page B evidence:** The lock sheet exists at `_lock-sheet.md`. Gate results have full measured values for all 25 gates. The weaver had comprehensive diagnostic context.

**Page A evidence:** The lock sheet also exists. Gate results have measured values but for fewer gates (initially 12 inline + DG gates). The pipeline audit notes 3 Tier A blocking gates were missing from SKILL.md's inline table (SC-12, SC-14, SC-15).

**Causal trace:** Page B's weaver had more gate data to work with (25 gates vs Page A's initial 12). The enriched weaver routing (reading TC brief detection expectations, builder conviction statement, cascade value table) enabled more targeted fix instructions. However, since only Page B had a documented fix cycle in the build log, the comparative impact is hard to isolate.

**Verdict: POSITIVE but INDIRECT.** Better weaver routing enables better fix cycles, but the direct PA-05 impact is through the fix instructions, not the routing itself. Impact: +0.1 PA-05 points (enabler of 1G above).

---

## 2. WHAT PAGE A'S PROMPT HAD DIFFERENTLY

### 2A. Monolithic 542-Line Prompt vs Distributed Skill System

**Page A's approach:** The MASTER-EXECUTION-PROMPT is a single document that defines EVERYTHING -- team architecture, conventions brief content, gate runner content, PA questions, SKILL.md content, skill edits, CLAUDE.md edits, and validation protocol. The builder agent was spawned by an orchestrator that had just WRITTEN the conventions brief and gate runner as part of the prompt's execution.

**Page B's approach:** The /build-page SKILL.md (579 lines) is a distributed orchestrator that REFERENCES existing files (conventions-brief.md, gate-runner.md, flagship-pa-questions.md). The builder was spawned by an orchestrator that READ pre-existing files.

**Causal trace:** Page A's orchestrator had DEEPER context because it had just AUTHORED the conventions brief. This is a non-trivial advantage: the orchestrator understood every section of the brief because it wrote every word. When the builder produced output, the orchestrator could evaluate it against first-hand knowledge of the brief's intent.

Page B's orchestrator had BROADER context because it referenced a mature, stable skill system. But it was interpreting files it did not write, which introduces a comprehension gap.

**Quality impact:** Page A's deeper orchestrator context did NOT translate to better builder output. Both builders produced similar-quality first drafts. The difference emerged in the fix cycle (Page B's structured tiered approach vs Page A's gate-driven patches).

**Verdict: SLIGHT ADVANTAGE to Page A's orchestrator comprehension, STRONG ADVANTAGE to Page B's fix cycle structure.** Net: NEUTRAL to SLIGHTLY POSITIVE for Page B. The monolithic prompt gave the orchestrator more context, but the distributed system gave the builder better tools for self-correction.

---

### 2B. Information Overload vs Focused Routing

**Page A's builder reading load:** conventions-brief.md (~400 lines) + content file (~1,324 lines) + 4 reference files (~2,300 lines) = ~4,000 lines. No TC brief in the standard sense -- the TC pipeline was run inline by the orchestrator.

**Page B's builder reading load:** _tc-brief.md (~99 lines) + conventions-brief.md (~400 lines) + content file (~1,324 lines) + 4 reference files (~2,300 lines) = ~4,100 lines. Nearly identical.

**Causal trace:** The raw line counts are similar. The critical difference is WHAT COMES FIRST. Page B's builder reads the TC brief FIRST (establishing compositional foundation), then the conventions brief SECOND (establishing world model), then content THIRD. Page A's builder also followed this order (per the SKILL.md reading order specification). The pipeline change here is not the total volume but the TC brief's quality -- Page B's TC brief is more recipe-like, with boundary CSS table and perception checks embedded.

**Verdict: NEUTRAL on volume, POSITIVE on TC brief quality.** The builder reading load was similar. The improvement came from what was IN the TC brief, not from routing different amounts of text.

---

## 3. RECIPE vs CHECKLIST: THE #1 RESEARCH FINDING

**Finding from research:** "The Middle experiment builder received a 100-line recipe and produced PA-05 4/4. The Flagship builder received a 71-line checklist and produced PA-05 1.5/4."

**Page A's builder:** Received a RECIPE. The conventions brief (which the builder reads as primary guidance) is explicitly described as "55% conventions / 25% recipe / 20% checklist." The build log confirms the builder followed the process section's "Understand -> Plan -> Build -> Verify" recipe structure. The builder's brief reflection cites Section 4 (Multi-Coherence), Section 5 (Fractal Echo), Section 7 (Transition Grammar) as most influential -- all conventions/recipe sections.

**Page B's builder:** ALSO received a RECIPE, but with a key addition: the TC brief's Section 6 (BUILD RECIPE) is a zone-keyed deployment sequence with specific CSS values per zone. This is the SECOND recipe layer on top of the conventions brief's process recipe.

**Causal trace:** Both pages had recipe-format guidance. Page B had TWO recipe layers (TC brief recipe + conventions brief recipe). The TC brief recipe is content-specific ("Set bg: #FEF9F5, padding 64px 80px. Deploy #16 drop cap"). The conventions brief recipe is universal ("At every zone boundary, shift >= 3 channels").

The double-recipe structure means Page B's builder had both WHAT to build (TC brief recipe) and HOW to think about it (conventions brief recipe). Page A's builder had primarily HOW to think about it (conventions brief) and derived WHAT to build from the content independently.

**Evidence of impact:** Page B's builder's override log is the smoking gun. 7 documented overrides, each citing the TC brief's values and the perception physics from the conventions brief. This is the recipe format working as designed: the builder has a concrete starting point (TC recipe values) and evaluative framework (conventions brief thresholds) to make informed modifications. Page A's builder had 5 overrides with less specific citation.

**Verdict: POSITIVE.** The double-recipe structure improved builder decision-making traceability and likely contributed to more confident CSS choices. Impact: +0.2 PA-05 points.

---

## 4. TC INDEPENDENCE: SEPARATE AGENT vs INLINE

**Page A's TC:** Run as a separate Opus agent by the orchestrator, Phases 0-4 of the tension-composition skill. Produced the "ASSEMBLY LINE" metaphor. Build log confirms the TC agent was independent.

**Page B's TC:** Run as a separate Opus agent by the orchestrator, Phases 0-4 of the tension-composition skill. Produced the "COMMAND POST / FIELD DISPATCH" metaphor with a quality score of 14/18 (VIABLE).

**Causal trace:** Both pages used independent TC agents. The structural difference is that Page B's TC template was ENRICHED with:
- Quality rubric scoring (14/18)
- Risk profile ("Cost 2/5. RESIST label-heavy transitions")
- Approved verb tiers for the recipe
- Boundary-keyed CSS table with perception checks
- Explicit rejected mechanisms with reasons

Page A's TC template was the same Phase 4.5 output template but WITHOUT these enrichments.

**Metaphor quality comparison:**
- Page A: "ASSEMBLY LINE" -- structural (backgrounds darken as processing deepens, spacing compresses as operations intensify, borders thicken at station boundaries). 5 explicit CSS mappings in the build log.
- Page B: "COMMAND POST / FIELD DISPATCH" -- structural (rank hierarchy through border-weight, clearance zones through bg progression, dispatch compression through spacing arc). 3 explicit CSS mappings in the build log, plus the TC brief's 5 CSS directions.

Both metaphors are genuinely structural (not just announced). Both map to specific CSS properties. Page B's metaphor produces tighter zone boundaries (4 zones vs 5 for the same content) which concentrates the visual investment. Page A's 5 zones spread 16 mechanisms more thinly.

**Verdict: SLIGHTLY POSITIVE for Page B.** The enriched TC template produced a more operationally useful TC brief (with boundary CSS table, risk profile, and rejected mechanisms). The metaphor quality itself is comparable. Impact: +0.1 PA-05 points.

---

## 5. REGRESSIONS: WHAT PAGE B'S PIPELINE LOST

### 5A. Zone Count Regression

**Page A: 5 zones.** Page B: 4 zones. For the same content (Steve Yegge's Gas Town essay).

**Causal trace:** Page B's TC agent chose 4 zones ("Situation Brief / Operational Readiness / Field Intelligence / Allied Ops & Deployment"). Page A's builder chose 5 zones ("Header/Opening / Architecture / Memory/Waves / Principles/Implementation / Comparison/Footer").

Page A's 5 zones allow more granular content-form coupling -- the Memory/Waves section gets its own zone with its own background and density treatment. In Page B, this content is absorbed into Zone 3 (Field Intelligence), which is already the densest zone.

**Is this a pipeline-caused regression?** Partially. Page B's TC template specifies "3-5 zones" and the TC agent chose 4. The enriched template's emphasis on boundary CSS tables (which require detailed work per boundary) may have biased the TC agent toward fewer zones (less specification work). With 5 zones, the TC agent would have needed to specify 4 boundary tables instead of 3.

**Impact:** Page A's broader content representation through 5 zones is arguably better content-form coupling. However, Page B's 4 zones have STRONGER individual boundaries (all >= 15 RGB, avg 4.0 channels). The quality-per-boundary is higher in Page B; the quantity-of-boundaries is higher in Page A.

**Verdict: SLIGHT REGRESSION.** The enriched TC template may discourage zone granularity by increasing the per-boundary specification cost. Impact: -0.1 PA-05 points.

---

### 5B. Mechanism Count

**Page A: 16 mechanisms.** Page B: 15 mechanisms.

This is within normal variation and not a pipeline-caused regression. Both exceed the >=14 threshold.

**Verdict: NEUTRAL.** No regression. Impact: 0.0.

---

### 5C. Missing Gates in Page A's Initial Run

**Page A ran 12 inline gates initially.** Page B ran 25 gates. Page A was MISSING SC-12 (Zone Count), SC-14 (Sub-Perceptual Prevention), and SC-15 (Border Presence) from its initial inline table (per the pipeline audit).

**This is a Page A regression, not a Page B regression.** Page B's pipeline FIXED this by using the complete gate-runner.md reference file instead of hardcoding gates inline.

**Verdict: POSITIVE for Page B.** The distributed gate runner eliminated the gate coverage gap. Impact: captured in Section 1E above.

---

### 5D. Component Class Count

**Page A: 54 distinct component classes.** Page B: 18 component types.

This is a significant difference. Page A's builder created many more CSS classes (header-inner, header-stat, stats-bar, breathing-zone, section-indicator, divider-soft, etc.). Page B's builder created fewer, more purposeful classes.

**Causal trace:** The enriched conventions brief (Section 8: CSS Vocabulary) and the TC brief's mechanism list may have constrained Page B's builder to deploy NAMED mechanisms rather than invent new CSS patterns. Page A's builder, working from a less constrained TC brief, created more ad-hoc classes.

**Is more classes better?** Not necessarily. 54 classes includes many single-use utility classes. 18 types represents more disciplined component usage. However, the sheer variety of 54 classes means Page A has more potential for visual variety at the component level.

**Verdict: AMBIGUOUS.** More classes is not inherently better or worse. The quality impact depends on whether those classes produce perceptible visual differences. Impact: NEUTRAL on PA-05, potentially POSITIVE for Page A on visual richness at component scale.

---

## 6. PIPELINE CHANGE LEVERAGE MAP

| Pipeline Change | Quality Outcome | PA-05 Impact | Leverage |
|----------------|----------------|--------------|----------|
| **Boundary CSS Table** (TC Section 6) | Builder has concrete starting point, documented overrides, traceable handoff | +0.25 | **HIGHEST** |
| **Self-Challenge Fix Cycle** (SKILL.md 7.2) | Produced highest-quality compositional fix, forced builder to confront conviction contradictions | +0.30 | **HIGHEST** |
| **Effectiveness Tags** (TC Section 4) | Prevented sub-perceptual mechanism deployment at boundaries | +0.15 | HIGH |
| **Perception Thresholds in TC Brief** + SC-14 Gate | Double-layer prevention of imperceptible CSS | +0.15 | HIGH |
| **Double Recipe Structure** (TC recipe + conventions recipe) | Better builder decision-making, more confident CSS choices | +0.20 | HIGH |
| **Enriched TC Template** (quality rubric, risk profile, rejected mechanisms) | More operationally useful TC brief | +0.10 | MEDIUM |
| **Recipe-Format Validation** (SKILL.md 2.1) | Safety net, prevented potential regression | +0.10 | MEDIUM |
| **Weaver Routing Improvements** | Enabler for better fix cycles | +0.10 | MEDIUM |
| **Mechanism Pairing** (TC Section 4) | Improved traceability, not raw quality | +0.00 | LOW |
| **Midpoint Micro-Gate** | Did not fire; builder completed too quickly | 0.00 | **ZERO** (for this build) |
| Zone Count Reduction (4 vs 5) | Slight content-form coupling regression | -0.10 | LOW (regression) |

**Estimated total Page B pipeline advantage: +1.25 PA-05 points** (theoretical, not additive -- some effects are correlated).

---

## 7. SYNTHESIS: TOP 3 FINDINGS

### Finding 1: The Self-Challenge Protocol Is the Highest-Leverage Single Addition

The tiered fix cycle's self-challenge ("Name one way your current CSS CONTRADICTS your conviction statement") produced the most compositionally valuable work in Page B's entire build. It forced the builder to identify that the Z3->Z4 checkpoint bar at 150px violated the compression metaphor -- a CONCEPTUAL contradiction, not a mechanical one. No programmatic gate could catch this. No threshold could flag it. Only a builder re-reading its own conviction statement and honestly confronting contradictions could find it.

This is the pipeline equivalent of peer review in academic publishing: the builder reviews its OWN work against its OWN stated principles, and the gap between stated and actual is the fix target.

### Finding 2: The Boundary CSS Table Solves the #1 Historical Handoff Problem

The handoff research (report 01, Section 1) identified TC-to-builder compression as the highest loss point: 28:1 compression in Phase 3, entire quality rubric dropped. The boundary CSS table directly addresses this by pre-computing the compositional architecture at each boundary. The builder TRANSLATES rather than DERIVES.

The evidence is in Page B's override log: the builder received concrete hex values, measured their RGB deltas against the 15-point threshold, found them insufficient, and corrected them with documented reasoning. This is the handoff working as INTENDED -- not as a constraint, but as a starting point for informed creative override.

### Finding 3: Gate Coverage Is Not a Luxury -- SC-14 Prevented the #1 Failure Mode

Page A's initial 12-gate inline table was MISSING SC-14 (Sub-Perceptual Prevention). This is the gate that catches the exact failure mode that destroyed the Flagship experiment (107 lines of invisible letter-spacing). Page B's 25-gate run caught and prevented this. The distributed gate-runner.md approach (referencing a comprehensive file rather than hardcoding a subset inline) is structurally superior to inline gate definitions because it cannot silently drop gates.

---

## 8. ANSWER TO THE CENTRAL QUESTION

**Which pipeline changes had the highest leverage?**

1. **Self-Challenge Fix Cycle** (+0.30 est.) -- Forces compositional reasoning during fixes, not just mechanical compliance.
2. **Boundary CSS Table** (+0.25 est.) -- Transforms TC-to-builder handoff from conceptual to operational.
3. **Double Recipe Structure** (+0.20 est.) -- Content-specific recipe (TC brief) + universal recipe (conventions brief) gives builder both WHAT and HOW.
4. **SC-14 Gate + Perception Thresholds** (+0.15 est.) -- Prevents the historical #1 failure mode at both the authoring layer (TC brief checks) and the verification layer (programmatic gate).
5. **Effectiveness Tags** (+0.15 est.) -- Ensures boundary mechanisms are perceptible before deployment.

**Which pipeline changes had zero leverage?**

1. **Midpoint Micro-Gate** -- Did not fire. Builders complete too quickly for mid-build injection. This needs to be redesigned as a BUILDER SELF-CHECK (which both pages already did) rather than an ORCHESTRATOR INJECTION.
2. **Mechanism Pairing** -- Both pages achieved adequate multi-coherence. The pairing documentation helps traceability but did not measurably improve the output.

**What regressed?**

1. **Zone granularity** -- The enriched TC template's per-boundary specification cost may discourage zone proliferation. 4 zones vs 5 zones for the same content is a slight content-form coupling loss. Recommendation: add explicit guidance that zone count should match content's natural structure, not the TC agent's specification budget.

---

*End of provenance analysis.*
