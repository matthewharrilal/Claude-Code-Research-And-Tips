# PA Quality Analysis — yegge-gas-town-2026-02-25

**Scope:** Both PA rounds (initial + REFINE). 9 auditors + integrative + weaver per round.
**Protocol:** Pipeline v3 — 9-auditor Mode 4, 69 questions, PA-05 cross-validation, Tier 5 scoring.

---

## 1. Protocol Compliance

**Overall: HIGH.** Both rounds achieved 100% manifest completion (69/69 questions answered per round). All 9 auditors wrote experiential passes in both rounds. All cross-validations executed (F→DESIGNED, G→COHERENT, C/E/H→PROPORTIONATE, B→POLISHED). Completion manifests present in all 20 reports (10 initial + 10 REFINE).

**Deviations found:**
- Auditor A was respawned (v2) in the initial round — reason not documented in tracker
- No 1024px viewport captured (DPR limitation documented in tracker as ENV)
- Initial round: auditor file naming inconsistency (`p3b-integrative.md` not `p3b-pa-integrative.md`)
- REFINE round screenshots reduced from 53 to 15 — acceptable per protocol (targeted recapture)

---

## 2. Auditor Quality Variation

**Initial round:** Dramatic quality spread. All 9 auditors converged on the same catastrophic finding (dark zone invisibility at viewport level), but analytical depth varied significantly:
- **Strongest:** C (spatial), D (flow), I (adversarial) — quantified findings, provided measurements, cited specific scroll positions
- **Adequate:** A, B, F, G, H — answered all questions with evidence but less analytical rigor
- **Integrative:** Strong gestalt synthesis, identified the "two-page problem" pattern others missed

**REFINE round:** Quality equalized dramatically. With the visibility defect resolved, all 9 auditors produced substantive analysis with evidence citations. Standout quality:
- **A:** PA-05 score 3.5/4 with detailed sub-criteria reasoning across 4 pages
- **F:** Three-level rhythm analysis (macro/meso/micro) — the most analytically sophisticated report
- **G:** Metaphor analysis without text labels (PA-44) — genuine fresh-eyes methodology
- **D:** 7-property transition count at Z2-Z3 boundary — strongest quantitative evidence

**Finding: Initial-round auditor quality is degraded by catastrophic defects.** When 19/22 viewports are blank, auditors can only describe the blank — analytical differentiation collapses. The REFINE round proved all 9 auditors are capable of high-quality work when given reviewable content.

---

## 3. Question Coverage

**All 69 questions answered in both rounds.** No gaps. Question assignment distribution:
- A: 9q, B: 8q+XV, C: 10q+XV, D: 11q, E: 7q+XV, F: 5q+XV, G: 8q+XV, H: 5q+XV, I: 6q
- Cross-validations added 5-6 additional assessments across B/C/E/F/G/H

**Tier 5 questions (PA-60 through PA-68):** All 9 answered in REFINE round. Initial round did not formally score Tier 5 (the catastrophic defect made scoring meaningless). REFINE scored 9/9 YES.

**Question quality observation:** PA-50 (consecutive blank viewports) was the single most diagnostic question in the initial round — it quantified the catastrophe as "19 consecutive blank viewports." In the REFINE round, the same question scored 0 consecutive blank viewports. This 19→0 delta is the clearest measure of REFINE effectiveness.

---

## 4. Cross-Validation Accuracy

**REFINE round cross-validation results:**

| Sub-criterion | Primary (A) | Cross-validator | Agreement |
|---|---|---|---|
| DESIGNED | PASS | F: PASS | AGREE |
| COHERENT | PASS | G: PASS | AGREE |
| PROPORTIONATE | CONDITIONAL | C: PASS, E: PASS, H: CONDITIONAL | 3/4 PASS, weaver resolved to PASS |
| POLISHED | PASS | B: CONDITIONAL | 1/2 PASS, weaver resolved to PASS with advisory |

Cross-validation worked as designed: independent assessments converged or identified genuine disagreements. The PROPORTIONATE disagreement (A: CONDITIONAL vs C/E: PASS) was resolved by the weaver noting that A's concern (two breathing gaps) was addressed by C's analysis (gaps have labeled dividers = structural, not accidental). The POLISHED disagreement (A: PASS vs B: CONDITIONAL) was resolved by noting B's concern was footer text — supplementary metadata conventionally smaller.

**Initial round:** Cross-validation was less informative because all auditors agreed on the dominant failure (visibility). The protocol's value emerges when the page is borderline, not catastrophically broken.

---

## 5. Integrative Auditor Value

**Initial round integrative report:** HIGH VALUE. Identified cross-cutting patterns invisible to individual auditors:
- "Two-Page Problem" — named the structural failure
- "Every Section Opens Same Way" — pattern monotony
- "Callout Box Monoculture" — mechanism fatigue
- Emotional arc mapping (AUTHORITY → DREAD → ABANDONMENT → RESIGNATION)

**REFINE round integrative report:** HIGH VALUE but different character. With the page working, the integrative identified:
- Dark zone relentlessness (60-70% of scroll height is dark) — flagged by 6/10 auditors but only the integrative named it as "starts as atmosphere and becomes endurance"
- Nav rail functionally invisible — only integrative + H caught this
- Content-to-chrome ratio as a strength — unique observation

**Finding:** The integrative auditor adds most value when the page works (borderline assessment). When catastrophically broken, individual auditors all converge on the same finding and the integrative adds less incremental insight.

---

## 6. Weaver Protocol Compliance

**Both rounds: COMPLIANT.** All 8 required weaver outputs present in both diagnostic reports:
1. Experiential Anchor (before reading auditors)
2. Manifest Verification (all auditors complete)
3. PA-05 Score (with cross-validation resolution)
4. Tier 5 Score (initial: not scored due to defect; REFINE: 9/9)
5. Top-5 Fixes with classification
6. Fix-Type Summary (MECHANICAL/STRUCTURAL/COMPOSITIONAL)
7. Emotional Arc Synthesis (4 registers scored)
8. Ship Decision (initial: REFINE; REFINE: SHIP WITH FIXES)

**Artistic impressions:** Both rounds produced distinctive, non-formulaic artistic writing. The initial-round artistic ("The floor falls away... nineteen screens of nothing") was the single most useful diagnostic artifact of the initial round — it communicated the severity of the defect more effectively than any quantitative score. The REFINE artistic was warmer but less dramatic (appropriate given the improved page).

**Weaver scoring calibration:** Initial PA-05 2.0/4 (REFINE verdict). REFINE PA-05 3.5/4 (SHIP WITH FIXES). The +1.5 delta is the largest single-cycle improvement in pipeline history. Weaver correctly identified that the initial page's compositional logic was sound but invisible (REFINE, not REBUILD), and that the REFINE page had execution-level issues (SHIP WITH FIXES, not SHIP).

---

## 7. Experiential Pass Effectiveness

**The experiential pass drove the initial round's most important finding.** All 9 auditors identified the dark zone invisibility during their experiential pass — BEFORE answering analytical questions. The experiential pass operates as an early-warning system: catastrophic defects surface in Step 0 and frame all subsequent analysis.

**REFINE round experiential passes** were more analytically varied:
- A identified the long dark zone as "fatigue" (nuanced, not catastrophic)
- C immediately noted confident spatial rhythm
- E spotted the nav rail on right edge
- G registered "industrial, authoritative" personality
- I noted "does not feel like a template"

**Finding:** The experiential pass is most valuable as a gatekeeper — it catches show-stoppers before granular analysis begins. When the page works, experiential passes produce useful but non-critical first impressions.

---

## 8. PA-05 Scoring Calibration

| Cycle | PA-05 | DESIGNED | COHERENT | PROPORTIONATE | POLISHED |
|---|---|---|---|---|---|
| Initial | 2.0/4 | CONDITIONAL FAIL | CONDITIONAL FAIL | FAIL | FAIL |
| REFINE | 3.5/4 | PASS | PASS | PASS (resolved) | PASS (with advisory) |

The 2.0→3.5 trajectory is calibrated correctly. The initial page had sound compositional logic (CONDITIONAL on DESIGNED/COHERENT, not outright FAIL) but catastrophic execution (FAIL on PROPORTIONATE/POLISHED). The REFINE page fixed execution and retained composition. The sub-criteria captured this accurately.

**Calibration concern:** 3.5/4 is described as "CEILING/FLAGSHIP boundary" by the weaver. Given that 6/10 auditors flagged dark zone fatigue and the page has 3 MECHANICAL + 2 STRUCTURAL fixes, 3.5/4 feels slightly generous. A score of 3.25/4 might better reflect the state. However, per protocol the score is computed from sub-criteria (4 PASS = 3.5-4.0), so the weaver's 3.5 is defensible.

---

## 9. Screenshot Quality

**Initial round: 53 screenshots** (1440px: 24 + zone element captures, 768px: 22). Multiple DPR-affected dark captures (z3-start, z4-start, z4-content, z5-element, z5-resolution, threshold-z2-z3, footer, nav-rail). Element-level captures (z1-z5 at full height) proved content existed but was invisible at viewport scroll resolution.

**REFINE round: 15 screenshots** (1440px: 9, 768px: 6). Same DPR issues persisted for some targeted shots. Content was fully visible in zone-level captures.

**DPR 0.667 impact:** Persistent across both rounds. Physical capture was 960x600 for 1440x900 CSS viewport. This caused all auditors to note "some screenshots are dark — DPR issue" and spend analytical effort distinguishing capture artifacts from page defects. H and C both correctly identified this as a capture limitation, not a page bug.

**Finding:** The screenshot pre-capture pattern (lead takes all screenshots before spawning auditors) worked perfectly — zero Playwright contention across 18 parallel auditor agents (9 per round). However, the persistent DPR issue degrades auditor confidence in dark-zone regions and should be resolved at the MCP Playwright level if possible.

---

## 10. Protocol Improvement Suggestions

**P0: Require REFINE-round screenshot parity.** The REFINE round used only 15 screenshots vs 53 initial. While acceptable per protocol, auditors in the REFINE round frequently noted "I cannot verify this region due to missing screenshots." Capture at least the same zone-level set.

**P1: Add dark-zone visibility pre-check.** Before spawning 9 auditors ($), run a single-agent visibility scan: can viewport-level screenshots show content? If not, fix before PA deployment. The entire initial PA round (9 agents + integrative + weaver) produced a single finding (dark = invisible) that a 1-agent pre-check would have caught.

**P1: Document auditor respawns in tracker.** Auditor A was respawned (v2) with no reason captured. Respawn reasons are diagnostic gold — they reveal agent failures, context issues, or brief ambiguities.

**P2: Consider tiered PA deployment.** Deploy 3 auditors first (A: impression, C: spatial, I: adversarial). If all 3 agree on a catastrophic defect, skip the remaining 6 and go directly to REFINE. This saves 6 agent-spawns when the page has show-stopping defects.

**P2: Increase footer/attribution minimum text size in gates.** Both B (PA-02, PA-08) and A flagged small footer text. This is a mechanical check (font-size >= 12px) that belongs in the gate runner, not in 9 auditors' reports.

**P3: Add Tier 5 to initial round.** The initial round did not formally score Tier 5 due to the defect. Even when a page has major defects, Tier 5 questions about metaphor persistence (PA-68) and compositional voice (PA-65) could reveal whether the compositional logic is sound — useful signal for REFINE vs REBUILD decisions.
